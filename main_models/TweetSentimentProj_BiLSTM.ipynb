{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MaMNQ0uvcwb",
        "outputId": "9b98dcc7-125e-401c-8483-604d0aa183a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp38-cp38-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 16.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNOfdOLzjqVu"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "from sklearn import metrics\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchtext.legacy\n",
        "from torchtext.legacy import data\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torch.nn import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXjE5WL3mSxM",
        "outputId": "ad8e6b06-c387-4db2-bda2-ccb461e4492b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_utils='/content/drive/My Drive/NLP'\n",
        "sys.path.append(path_to_utils)"
      ],
      "metadata": {
        "id": "7SUrmHWemS4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(path_to_utils)\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0COq13xb9b-",
        "outputId": "2f93fdf4-afea-49f1-d713-4308409892d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1qJ8h8Q6C6t_FWn4R8pQeH813twKX9HgP/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#params can act as config file here\n",
        "\n",
        "params={\"Network\": {\"seed\": 1},\n",
        "        \"display_stats_freq\": 200,\n",
        "        \"network_save_freq\": 1,\n",
        "        \"postreply_data_path\": \"./\",\n",
        "        #\"input_data_path\": \"./data/datasets/semeval_message_level/\",\n",
        "        #\"train_file_name\": \"training_data.txt\",\n",
        "        #\"test_file_name\": \"test_data.txt\",\n",
        "        #\"reply_file_name\": \"data_post_reply.csv\",\n",
        "        #\"reply_with_label_file_name\": \"data_post_reply_withlabel.csv\",\n",
        "        \"final_data_post_reply_file_name\": \"final_data_post_reply.csv\",\n",
        "        \"training_post_reply_file_name\": \"obtained_train.csv\", #obtained_train.csv, provided_train.csv, obtained_train_clean.csv, provided_train_clean.csv\n",
        "        #\"philipp_data\": \"philipp_data.csv\",\n",
        "        #\"philipp_with_label_file_name\": \"philipp_withlabel.csv\",\n",
        "        #\"philipp_final_post_reply_file_name\": \"philipp_final.csv\",\n",
        "        \"final_test_post_reply_file_name\": \"test_w_text.csv\",\n",
        "        #\"data_format\": \"tsv\",\n",
        "        \"reply_data_format\": \"csv\",\n",
        "        \"pretrained_embedding\": \"glove.twitter.27B.200d\",\n",
        "        \"tokenizer\": \"spacy\",\n",
        "        \"network_output_path\": \"./models/\",\n",
        "        #\"output_data_path\": \"./data/output_data/\",\n",
        "        #\"tb_logs_path\": \"./data/tensor_board_logs/\",\n",
        "        #\"checkpoint_name\": \"checkpoint.tar\",\n",
        "        \"trained_model_name\": \"LSTM_model_obt.pth\"\n",
        "        }"
      ],
      "metadata": {
        "id": "iS1gTkUnfxVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class Mode(Enum):\n",
        "    '''\n",
        "    Class Enumerating the 3 modes of operation of the network.\n",
        "    This is used while loading datasets\n",
        "    '''\n",
        "    TRAIN = 0\n",
        "    VALID = 1\n",
        "    TEST = 2\n",
        "    PREDICTION = 3\n",
        "    REPLYPREDICTION = 4"
      ],
      "metadata": {
        "id": "ngfurp0uhMhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class data_provider_PostReply():\n",
        "    '''\n",
        "    Packed padded sequences\n",
        "    Tokenizer: spacy\n",
        "    '''\n",
        "    def __init__(self, params, batch_size=1, split_ratio=0.8, max_vocab_size=25000, mode=Mode.TRAIN, model_mode='RNN', seed=1): #cfg_path\n",
        "        '''\n",
        "        Args:\n",
        "            cfg_path (string): #deprecated for first pass\n",
        "                Config file path of the experiment\n",
        "\n",
        "            params\n",
        "            max_vocab_size (int):\n",
        "                The number of unique words in our training set is usually over 100,000,\n",
        "                which means that our one-hot vectors will have over 100,000 dimensions! SLOW TRAINIG!\n",
        "                We only take the top max_vocab_size most common words.\n",
        "            split_ratio (float):\n",
        "                train-valid splitting\n",
        "            mode (enumeration Mode):\n",
        "                Nature of operation to be done with the data.\n",
        "                Possible inputs are Mode.PREDICTION, Mode.TRAIN, Mode.VALID, Mode.TEST\n",
        "                Default value: Mode.TRAIN\n",
        "        '''\n",
        "        #params = read_config(cfg_path)\n",
        "        #self.cfg_path = cfg_path\n",
        "        self.mode = mode\n",
        "        self.seed = seed\n",
        "        self.split_ratio = split_ratio\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.dataset_path = params['postreply_data_path']\n",
        "        self.train_file_name = params['training_post_reply_file_name']\n",
        "        self.test_file_name = params['final_test_post_reply_file_name']\n",
        "        self.data_format = params['reply_data_format']\n",
        "        self.pretrained_embedding = params['pretrained_embedding']\n",
        "        self.tokenizer = params['tokenizer']\n",
        "        self.batch_size = batch_size\n",
        "        self.model_mode = model_mode\n",
        "\n",
        "\n",
        "    def data_loader(self):\n",
        "        '''\n",
        "        :include_lengths: Packed padded sequences: will make our RNN only process the non-padded elements of our sequence,\n",
        "            and for any padded element the `output` will be a zero tensor.\n",
        "            Note: padding is done by adding <pad> (not zero!)\n",
        "        :tokenize: the \"tokenization\" (the act of splitting the string into discrete \"tokens\") should be done using the spaCy tokenizer.\n",
        "        '''\n",
        "        if self.model_mode == 'RNN':\n",
        "            #Packed padded sequences\n",
        "            TEXT = data.Field(tokenize=self.tokenizer, include_lengths=True)  # For saving the length of sentences\n",
        "        if self.model_mode == 'CNN':\n",
        "            TEXT = data.Field(tokenize=self.tokenizer, batch_first=True)  # batch dimension is the firs dimension here.\n",
        "        LABEL = data.LabelField()\n",
        "\n",
        "        fields = [('label', LABEL), ('id', None), ('text', TEXT)]\n",
        "\n",
        "        train_data, test_data = data.TabularDataset.splits(\n",
        "            path=self.dataset_path,\n",
        "            train=self.train_file_name,\n",
        "            test=self.test_file_name,\n",
        "            format=self.data_format,\n",
        "            fields=fields,\n",
        "            skip_header=True)\n",
        "\n",
        "        #print(train_data)\n",
        "\n",
        "        # validation data\n",
        "        if self.split_ratio == 1:\n",
        "            valid_data = None\n",
        "        else:\n",
        "            train_data, valid_data = train_data.split(random_state=random.seed(self.seed), split_ratio=self.split_ratio)\n",
        "\n",
        "        # create the vocabulary only on the training set!!!\n",
        "        # vectors: instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors.\n",
        "        # initialize words in your vocabulary but not in your pre-trained embeddings to Gaussian\n",
        "        TEXT.build_vocab(train_data, max_size=self.max_vocab_size,\n",
        "                         vectors=self.pretrained_embedding, unk_init=torch.Tensor.normal_)\n",
        "        # TEXT.build_vocab(train_data, max_size=self.max_vocab_size)\n",
        "\n",
        "        LABEL.build_vocab(train_data)\n",
        "\n",
        "        labels = LABEL.vocab.itos\n",
        "        vocab_idx = TEXT.vocab.stoi\n",
        "\n",
        "        vocab_size = len(TEXT.vocab)\n",
        "        pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "        # the indices of the padding token <pad> and <unk> in the vocabulary\n",
        "        PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "        UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "        # What do we do with words that appear in examples but we have cut from the vocabulary?\n",
        "        # We replace them with a special unknown or <unk> token.\n",
        "\n",
        "\n",
        "        # for packed padded sequences all of the tensors within a batch need to be sorted by their lengths\n",
        "        if self.split_ratio == 1:\n",
        "            valid_iterator = None\n",
        "            train_iterator, test_iterator = data.BucketIterator.splits((\n",
        "                train_data, test_data), batch_size=self.batch_size,\n",
        "                sort_within_batch=True, sort_key=lambda x: len(x.text))\n",
        "        else:\n",
        "            train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((\n",
        "                train_data, valid_data, test_data), batch_size=self.batch_size,\n",
        "                sort_within_batch=True, sort_key=lambda x: len(x.text))\n",
        "\n",
        "        # finding the weights of each label\n",
        "        data_for_weight = pd.read_csv(os.path.join(self.dataset_path, self.train_file_name))\n",
        "        pos_counter = 0\n",
        "        neg_counter = 0\n",
        "        neut_counter = 0\n",
        "        for i in range(len(data_for_weight['label'])):\n",
        "            if (data_for_weight['label'][i] == 'positive'):\n",
        "                pos_counter += 1\n",
        "            if (data_for_weight['label'][i] == 'negative'):\n",
        "                neg_counter += 1\n",
        "            if (data_for_weight['label'][i] == 'neutral'):\n",
        "                neut_counter += 1\n",
        "        overall = neut_counter + pos_counter + neg_counter\n",
        "        neut_weight = overall/neut_counter\n",
        "        neg_weight = overall/neg_counter\n",
        "        pos_weight = overall/pos_counter\n",
        "        if labels == ['neutral', 'negative', 'positive']:\n",
        "            weights = torch.Tensor([neut_weight, neg_weight, pos_weight])\n",
        "        elif labels == ['neutral', 'positive', 'negative']:\n",
        "            weights = torch.Tensor([neut_weight, pos_weight, neg_weight])\n",
        "        elif labels == ['negative', 'neutral', 'positive']:\n",
        "            weights = torch.Tensor([neg_weight, neut_weight, pos_weight])\n",
        "        elif labels == ['negative', 'positive', 'neutral']:\n",
        "            weights = torch.Tensor([neg_weight, pos_weight, neut_weight])\n",
        "        elif labels == ['positive', 'negative', 'neutral']:\n",
        "            weights = torch.Tensor([pos_weight, neg_weight, neut_weight])\n",
        "        elif labels == ['positive', 'neutral', 'negative']:\n",
        "            weights = torch.Tensor([pos_weight, neut_weight, neg_weight])\n",
        "\n",
        "        if self.mode == Mode.TEST:\n",
        "            return test_iterator\n",
        "        elif self.mode == Mode.PREDICTION:\n",
        "            return labels, vocab_idx, vocab_size, PAD_IDX, UNK_IDX, pretrained_embeddings, labels\n",
        "        else:\n",
        "            return train_iterator, valid_iterator, vocab_size, PAD_IDX, UNK_IDX, pretrained_embeddings, weights, labels"
      ],
      "metadata": {
        "id": "giF66QlEexod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "class Training:\n",
        "    '''\n",
        "    This class represents training process.\n",
        "    '''\n",
        "    def __init__(self, params, num_epochs=10, RESUME=False, model_mode='RNN', torch_seed=None): #cfg_path\n",
        "        '''\n",
        "        :cfg_path (string): path of the experiment config file\n",
        "        :torch_seed (int): Seed used for random generators in PyTorch functions\n",
        "        '''\n",
        "        self.params = params\n",
        "        #self.cfg_path = cfg_path\n",
        "        self.RESUME = RESUME\n",
        "        self.model_mode = model_mode\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "        if RESUME == False:\n",
        "            self.model_info = self.params['Network']\n",
        "            self.model_info['seed'] = torch_seed or self.model_info['seed']\n",
        "            self.epoch = 0\n",
        "            self.num_epochs = num_epochs\n",
        "            self.best_loss = float('inf')\n",
        "            if 'trained_time' in self.model_info:\n",
        "                self.raise_training_complete_exception()\n",
        "            self.setup_cuda()\n",
        "            #self.writer = SummaryWriter(log_dir=os.path.join(self.params['tb_logs_path']))\n",
        "\n",
        "\n",
        "    def setup_cuda(self, cuda_device_id=0):\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cudnn.fastest = True\n",
        "            torch.cuda.set_device(cuda_device_id)\n",
        "            self.device = torch.device('cuda')\n",
        "            torch.cuda.manual_seed_all(self.model_info['seed'])\n",
        "            torch.manual_seed(self.model_info['seed'])\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "\n",
        "    def setup_model(self, model, optimiser, optimiser_params, loss_function, weight):\n",
        "\n",
        "        total_param_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f'Total # of model\\'s trainable parameters: {total_param_num:,}')\n",
        "        print('----------------------------------------------------\\n')\n",
        "\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimiser = optimiser(self.model.parameters(), **optimiser_params)\n",
        "        # self.loss_function = loss_function()\n",
        "        self.loss_function = loss_function(weight=weight.to(self.device))\n",
        "\n",
        "        if 'retrain' in self.model_info and self.model_info['retrain']==True:\n",
        "            self.load_pretrained_model()\n",
        "\n",
        "        # Saves the model, optimiser,loss function name for writing to config file\n",
        "        self.model_info['total_param_num'] = total_param_num\n",
        "        self.model_info['optimiser'] = optimiser.__name__\n",
        "        self.model_info['loss_function'] = loss_function.__name__\n",
        "        self.model_info['optimiser_params'] = optimiser_params\n",
        "        self.params['Network']=self.model_info\n",
        "        #write_config(self.params, self.cfg_path,sort_keys=True)\n",
        "\n",
        "\n",
        "    def load_checkpoint(self, model, optimiser, optimiser_params, loss_function, weight):\n",
        "\n",
        "        checkpoint = torch.load(self.params['network_output_path'] + '/' + self.params['checkpoint_name'])\n",
        "        self.device = None\n",
        "        self.model_info = checkpoint['model_info']\n",
        "        self.setup_cuda()\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimiser = optimiser(self.model.parameters(), **optimiser_params)\n",
        "        self.loss_function = loss_function(weight=weight.to(self.device))\n",
        "\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimiser.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.epoch = checkpoint['epoch']\n",
        "        self.loss_function = checkpoint['loss']\n",
        "        self.best_loss = checkpoint['best_loss']\n",
        "        #self.writer = SummaryWriter(log_dir=os.path.join(self.params['tb_logs_path']), purge_step=self.epoch + 1)\n",
        "\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "    def execute_training(self, train_loader, valid_loader=None, batch_size=1):\n",
        "        '''\n",
        "        Executes training by running training and validation at each epoch\n",
        "        '''\n",
        "        self.params = params #read_config(self.cfg_path)\n",
        "\n",
        "        total_start_time = time.time()\n",
        "\n",
        "        if self.RESUME == False:\n",
        "            # Checks if already trained\n",
        "            if 'trained_time' in self.model_info:\n",
        "                self.raise_training_complete_exception\n",
        "\n",
        "            self.model_info = self.params['Network']\n",
        "            self.model_info['num_epoch'] = self.num_epochs or self.model_info['num_epoch']\n",
        "\n",
        "        print('Starting time:' + str(datetime.datetime.now()) +'\\n')\n",
        "\n",
        "        for epoch in range(self.num_epochs - self.epoch):\n",
        "            self.epoch += 1\n",
        "            start_time = time.time()\n",
        "\n",
        "            print('Training (intermediate metrics):')\n",
        "            train_loss, train_acc, train_F1, train_recall, train_precision = self.train_epoch(train_loader, batch_size)\n",
        "\n",
        "            if valid_loader:\n",
        "                print('\\nValidation (intermediate metrics):')\n",
        "                valid_loss, valid_acc, valid_F1, valid_recall, valid_precision = self.valid_epoch(valid_loader, batch_size)\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
        "            total_mins, total_secs = self.epoch_time(total_start_time, end_time)\n",
        "\n",
        "            # Writes to the tensorboard after number of steps specified.\n",
        "            #if valid_loader:\n",
        "            #    self.calculate_tb_stats(train_loss, train_F1, train_recall, train_precision, train_acc,\n",
        "            #                            valid_loss, valid_F1, valid_recall, valid_precision, valid_acc)\n",
        "            #else:\n",
        "            #    self.calculate_tb_stats(train_loss, train_F1, train_recall, train_precision, train_acc)\n",
        "\n",
        "            # Saving the model\n",
        "            if valid_loader:\n",
        "                if valid_loss < self.best_loss:\n",
        "                    self.best_loss = valid_loss\n",
        "                    torch.save(self.model.state_dict(), self.params['network_output_path'] + '/' + self.params['trained_model_name'])\n",
        "            else:\n",
        "                if train_loss < self.best_loss:\n",
        "                    self.best_loss = train_loss\n",
        "                    torch.save(self.model.state_dict(), self.params['network_output_path'] + '/' + self.params['trained_model_name'])\n",
        "\n",
        "            # saving the model based on epoch, checkpoint\n",
        "            #self.savings()\n",
        "\n",
        "            # Print accuracy, F1, and loss after each epoch\n",
        "            print('\\n---------------------------------------------------------------')\n",
        "            print(f'Epoch: {self.epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | '\n",
        "                  f'Total Time so far: {total_mins}m {total_secs}s')\n",
        "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train F1: {train_F1:.3f}')\n",
        "            if valid_loader:\n",
        "                print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}% |  Val. F1: {valid_F1:.3f}')\n",
        "            print('---------------------------------------------------------------\\n')\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, batch_size):\n",
        "        '''\n",
        "        Train using one single iteration of all messages (epoch) in dataset\n",
        "        '''\n",
        "        print(\"Epoch [{}/{}]\".format(self.epoch, self.model_info['num_epoch']))\n",
        "        self.model.train()\n",
        "        previous_idx = 0\n",
        "\n",
        "        # initializing the loss list\n",
        "        batch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # initializing the caches\n",
        "        logits_cache = torch.from_numpy(np.zeros((len(train_loader) * batch_size, 3)))\n",
        "        max_preds_cache = torch.from_numpy(np.zeros((len(train_loader) * batch_size, 1)))\n",
        "        labels_cache = torch.from_numpy(np.zeros(len(train_loader) * batch_size))\n",
        "\n",
        "        for idx, batch in enumerate(train_loader):\n",
        "            if self.model_mode == \"RNN\":\n",
        "                message, message_lengths = batch.text\n",
        "            if self.model_mode == \"CNN\":\n",
        "                message = batch.text\n",
        "            label = batch.label\n",
        "            message = message.long()\n",
        "            label = label.long()\n",
        "            message = message.to(self.device)\n",
        "            label = label.to(self.device)\n",
        "\n",
        "            self.optimiser.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    output = self.model(message, message_lengths).squeeze(1)\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    output = self.model(message).squeeze(1)\n",
        "\n",
        "                # Loss\n",
        "                loss = self.loss_function(output, label)\n",
        "                batch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimiser.step()\n",
        "\n",
        "                # Prints loss statistics after number of steps specified.\n",
        "                if (idx + 1)%self.params['display_stats_freq'] == 0:\n",
        "                    print('Epoch {:02} | Batch {:03}-{:03} | Train loss: {:.3f}'.\n",
        "                          format(self.epoch, previous_idx, idx, batch_loss / batch_count))\n",
        "                    previous_idx = idx + 1\n",
        "                    batch_loss = 0\n",
        "                    batch_count = 0\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        # average=None gives individual scores for each class\n",
        "        # here we only care about the average of positive class and negative class\n",
        "        epoch_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_f1_score = (epoch_f1_score[1] + epoch_f1_score[2]) / 2\n",
        "        epoch_precision = (epoch_precision[1] + epoch_precision[2]) / 2\n",
        "        epoch_recall = (epoch_recall[1] + epoch_recall[2]) / 2\n",
        "        labels_cache = labels_cache.long()\n",
        "        logits_cache = logits_cache.float()\n",
        "\n",
        "        # Loss\n",
        "        loss = self.loss_function(logits_cache.to(self.device), labels_cache.to(self.device))\n",
        "        epoch_loss = loss.item()\n",
        "\n",
        "        return epoch_loss, epoch_accuracy, epoch_f1_score, epoch_precision, epoch_recall\n",
        "\n",
        "\n",
        "    def valid_epoch(self, valid_loader, batch_size):\n",
        "        '''Test (validation) model after an epoch and calculate loss on valid dataset'''\n",
        "        print(\"Epoch [{}/{}]\".format(self.epoch, self.model_info['num_epoch']))\n",
        "        self.model.eval()\n",
        "        previous_idx = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # initializing the loss list\n",
        "            batch_loss = 0\n",
        "            batch_count = 0\n",
        "\n",
        "            # initializing the caches\n",
        "            logits_cache = torch.from_numpy(np.zeros((len(valid_loader) * batch_size, 3)))\n",
        "            max_preds_cache = torch.from_numpy(np.zeros((len(valid_loader) * batch_size, 1)))\n",
        "            labels_cache = torch.from_numpy(np.zeros(len(valid_loader) * batch_size))\n",
        "\n",
        "            for idx, batch in enumerate(valid_loader):\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    message, message_lengths = batch.text\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    message = batch.text\n",
        "                label = batch.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    output = self.model(message, message_lengths).squeeze(1)\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    output = self.model(message).squeeze(1)\n",
        "\n",
        "                # Loss\n",
        "                loss = self.loss_function(output, label)\n",
        "                batch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "                # Prints loss statistics after number of steps specified.\n",
        "                if (idx + 1)%self.params['display_stats_freq'] == 0:\n",
        "                    print('Epoch {:02} | Batch {:03}-{:03} | Val. loss: {:.3f}'.\n",
        "                          format(self.epoch, previous_idx, idx, batch_loss / batch_count))\n",
        "                    previous_idx = idx + 1\n",
        "                    batch_loss = 0\n",
        "                    batch_count = 0\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        epoch_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_f1_score = (epoch_f1_score[1] + epoch_f1_score[2]) / 2\n",
        "        epoch_precision = (epoch_precision[1] + epoch_precision[2]) / 2\n",
        "        epoch_recall = (epoch_recall[1] + epoch_recall[2]) / 2\n",
        "        labels_cache = labels_cache.long()\n",
        "        logits_cache = logits_cache.float()\n",
        "\n",
        "        # Loss\n",
        "        loss = self.loss_function(logits_cache.to(self.device), labels_cache.to(self.device))\n",
        "        epoch_loss = loss.item()\n",
        "\n",
        "        self.model.train()\n",
        "        return epoch_loss, epoch_accuracy, epoch_f1_score, epoch_precision, epoch_recall\n",
        "\n"
      ],
      "metadata": {
        "id": "nc3DXbxSlaAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "\n",
        "\n",
        "class biLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embeddings=None, embedding_dim=100, hidden_dim=256, output_dim=3, pad_idx=1, unk_idx=0):\n",
        "        '''\n",
        "        :pad_idx: the index of the padding token <pad> in the vocabulary\n",
        "        :num_layers: number of biLSTMs stacked on top of each other\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        # replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "        self.embedding.weight.data.copy_(embeddings)\n",
        "        # these are irrelevant for determining sentiment:\n",
        "        self.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "        self.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2,\n",
        "                           bidirectional=True, dropout=0.5)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        # Note: never use dropout on the input or output layers (text or fc in this case),\n",
        "        # you only ever want to use dropout on intermediate layers.\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        '''\n",
        "        In some frameworks you must feed the initial hidden state, $h_0$, into the RNN,\n",
        "        however in PyTorch, if no initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
        "        :nn.utils.rnn.pack_padded_sequence: This will cause our RNN to only process the non-padded elements of our sequence.\n",
        "        '''\n",
        "        # text : [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded : [sent len, batch size, emb dim]\n",
        "\n",
        "        # pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        # output (packed_output) is the concatenation of the hidden state from every time step\n",
        "        # hidden is simply the final hidden state.\n",
        "        # hidden : [num layers * num directions, batch size, hid dim]\n",
        "        # cell : [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "        # unpack sequence [not needed, only for demonstration]\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # output : [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "\n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        # hidden : [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(hidden)"
      ],
      "metadata": {
        "id": "1AOGsXO6mS8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1d(nn.Module):\n",
        "    def __init__(self, vocab_size, embeddings, embedding_dim=200,\n",
        "                 conv_out_ch=200, filter_sizes=[3,4,5], output_dim=3, pad_idx=1, unk_idx=0):\n",
        "        '''\n",
        "        :pad_idx: the index of the padding token <pad> in the vocabulary\n",
        "        :conv_out_ch: number of the different kernels.\n",
        "        :filter_sizes: a list of different kernel sizes we use here.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        # replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "        self.embedding.weight.data.copy_(embeddings)\n",
        "        # these are irrelevant for determining sentiment:\n",
        "        self.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "        self.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=conv_out_ch,\n",
        "                      kernel_size=fs) for fs in filter_sizes])\n",
        "\n",
        "        self.fc = nn.Linear(len(filter_sizes) * conv_out_ch, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text = [batch size, sent len]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent len, emb dim]\n",
        "\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        # embedded = [batch size, emb dim, sent len]\n",
        "\n",
        "        # pad if the length of the sentence is less than the kernel size\n",
        "        if embedded.shape[2] < 5:\n",
        "            dif = 5 - embedded.shape[2]\n",
        "            embedded = F.pad(embedded, (0, dif), \"constant\", 0)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        # pooled_n = [batch size, n_filters]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "udPhdZzR7e4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_train_postreply():\n",
        "    '''\n",
        "    Main function for training + validation of the second part of the project:\n",
        "    Sentiment analysis of the Post-Replies.\n",
        "    '''\n",
        "    # if we are resuming training on a model\n",
        "    RESUME = False\n",
        "\n",
        "    # Hyper-parameters\n",
        "    NUM_EPOCH = 200\n",
        "    LOSS_FUNCTION = CrossEntropyLoss\n",
        "    OPTIMIZER = optim.Adam\n",
        "    BATCH_SIZE = 256\n",
        "    MAX_VOCAB_SIZE = 100000 #750000 #max_vocab_size: takes the 100,000 most frequent words as the vocab\n",
        "    lr = 9e-5\n",
        "    optimiser_params = {'lr': lr, 'weight_decay': 1e-4}\n",
        "    EMBEDDING_DIM = 200\n",
        "    HIDDEN_DIM = 300\n",
        "    OUTPUT_DIM = 3\n",
        "    MODEL_MODE = \"RNN\" # \"RNN\" or \"CNN\"\n",
        "    conv_out_ch = 200  # for the CNN model:\n",
        "    filter_sizes = [3, 4, 5]  # for the CNN model:\n",
        "    SPLIT_RATIO = 0.9 # ratio of the train set, 1.0 means 100% training, 0% valid data\n",
        "    EXPERIMENT_NAME = \"new_october_CNN\"\n",
        "\n",
        "    #if RESUME == True:\n",
        "    #    params = open_experiment(EXPERIMENT_NAME)\n",
        "    #else:\n",
        "    #    params = create_experiment(EXPERIMENT_NAME)\n",
        "    #cfg_path = params[\"cfg_path\"]\n",
        "\n",
        "    # Prepare data\n",
        "    data_handler = data_provider_PostReply(params=params, batch_size=BATCH_SIZE, split_ratio=SPLIT_RATIO,\n",
        "                                           max_vocab_size=MAX_VOCAB_SIZE, mode=Mode.TRAIN, model_mode=MODEL_MODE)\n",
        "    train_iterator, valid_iterator, vocab_size, PAD_IDX, UNK_IDX, pretrained_embeddings, weights, classes = data_handler.data_loader()\n",
        "\n",
        "    if SPLIT_RATIO == 1:\n",
        "        total_valid_tweets = 0\n",
        "    else:\n",
        "        total_valid_tweets = BATCH_SIZE * len(valid_iterator)\n",
        "    total_train_tweets = BATCH_SIZE * len(train_iterator)\n",
        "    print(f'\\nSummary:\\n----------------------------------------------------')\n",
        "    print(f'Total # of Training tweets: {total_train_tweets:,}')\n",
        "    print(f'Total # of Valid. tweets:   {total_valid_tweets:,}')\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Training(params, num_epochs=NUM_EPOCH, RESUME=RESUME, model_mode=MODEL_MODE)\n",
        "\n",
        "    if MODEL_MODE == \"RNN\":\n",
        "        MODEL = biLSTM(vocab_size=vocab_size, embeddings=pretrained_embeddings, embedding_dim=EMBEDDING_DIM,\n",
        "                       hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX)\n",
        "    elif MODEL_MODE == \"CNN\":\n",
        "        MODEL = CNN1d(vocab_size=vocab_size, embeddings=pretrained_embeddings, embedding_dim=EMBEDDING_DIM,\n",
        "                       conv_out_ch=conv_out_ch, filter_sizes=filter_sizes, output_dim=OUTPUT_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX)\n",
        "\n",
        "    if RESUME == True:\n",
        "        trainer.load_checkpoint(model=MODEL, optimiser=OPTIMIZER,\n",
        "                        optimiser_params=optimiser_params, loss_function=LOSS_FUNCTION, weight=weights)\n",
        "    else:\n",
        "        trainer.setup_model(model=MODEL, optimiser=OPTIMIZER,\n",
        "                        optimiser_params=optimiser_params, loss_function=LOSS_FUNCTION, weight=weights)\n",
        "        # writes the params to config file\n",
        "        #params = read_config(cfg_path)\n",
        "        params['Network']['vocab_size'] = vocab_size\n",
        "        params['Network']['PAD_IDX'] = PAD_IDX\n",
        "        params['Network']['UNK_IDX'] = UNK_IDX\n",
        "        params['Network']['classes'] = classes\n",
        "        params['Network']['SPLIT_RATIO'] = SPLIT_RATIO\n",
        "        params['Network']['MAX_VOCAB_SIZE'] = MAX_VOCAB_SIZE\n",
        "        params['Network']['HIDDEN_DIM'] = HIDDEN_DIM\n",
        "        params['Network']['EMBEDDING_DIM'] = EMBEDDING_DIM\n",
        "        params['Network']['conv_out_ch'] = conv_out_ch\n",
        "        params['Network']['MODEL_MODE'] = MODEL_MODE\n",
        "        params['total_train_tweets'] = total_train_tweets\n",
        "        params['total_valid_tweets'] = total_valid_tweets\n",
        "        #write_config(params, cfg_path, sort_keys=True)\n",
        "\n",
        "    trainer.execute_training(train_loader=train_iterator, valid_loader=valid_iterator, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "E2HJpeoSmTB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_train_postreply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uXWcUzgp2rF",
        "outputId": "cdbfc422-eceb-4153-ca5f-5393233a3fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "----------------------------------------------------\n",
            "Total # of Training tweets: 24,064\n",
            "Total # of Valid. tweets:   2,816\n",
            "Total # of model's trainable parameters: 18,486,203\n",
            "----------------------------------------------------\n",
            "\n",
            "Starting time:2022-12-04 15:38:43.047332\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [1/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [1/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 01 | Epoch Time: 0m 7s | Total Time so far: 0m 7s\n",
            "\tTrain Loss: 1.090 | Train Acc: 38.35% | Train F1: 0.360\n",
            "\t Val. Loss: 1.072 |  Val. Acc: 41.05% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [2/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [2/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 02 | Epoch Time: 0m 7s | Total Time so far: 0m 15s\n",
            "\tTrain Loss: 1.041 | Train Acc: 39.32% | Train F1: 0.463\n",
            "\t Val. Loss: 1.002 |  Val. Acc: 44.46% |  Val. F1: 0.513\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [3/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [3/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 03 | Epoch Time: 0m 7s | Total Time so far: 0m 22s\n",
            "\tTrain Loss: 1.010 | Train Acc: 42.03% | Train F1: 0.497\n",
            "\t Val. Loss: 1.001 |  Val. Acc: 45.67% |  Val. F1: 0.524\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [4/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [4/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 04 | Epoch Time: 0m 7s | Total Time so far: 0m 30s\n",
            "\tTrain Loss: 1.006 | Train Acc: 42.70% | Train F1: 0.496\n",
            "\t Val. Loss: 1.005 |  Val. Acc: 45.03% |  Val. F1: 0.525\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [5/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [5/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 05 | Epoch Time: 0m 7s | Total Time so far: 0m 38s\n",
            "\tTrain Loss: 1.001 | Train Acc: 43.08% | Train F1: 0.504\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 45.95% |  Val. F1: 0.525\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [6/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [6/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 06 | Epoch Time: 0m 7s | Total Time so far: 0m 46s\n",
            "\tTrain Loss: 0.999 | Train Acc: 43.35% | Train F1: 0.507\n",
            "\t Val. Loss: 0.999 |  Val. Acc: 45.99% |  Val. F1: 0.524\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [7/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [7/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 07 | Epoch Time: 0m 7s | Total Time so far: 0m 53s\n",
            "\tTrain Loss: 1.000 | Train Acc: 43.51% | Train F1: 0.504\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 47.16% |  Val. F1: 0.525\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [8/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [8/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 08 | Epoch Time: 0m 7s | Total Time so far: 1m 1s\n",
            "\tTrain Loss: 0.994 | Train Acc: 44.26% | Train F1: 0.509\n",
            "\t Val. Loss: 0.996 |  Val. Acc: 45.42% |  Val. F1: 0.528\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [9/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [9/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 09 | Epoch Time: 0m 7s | Total Time so far: 1m 9s\n",
            "\tTrain Loss: 0.994 | Train Acc: 44.11% | Train F1: 0.511\n",
            "\t Val. Loss: 1.004 |  Val. Acc: 47.55% |  Val. F1: 0.516\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [10/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [10/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 10 | Epoch Time: 0m 7s | Total Time so far: 1m 17s\n",
            "\tTrain Loss: 0.991 | Train Acc: 44.65% | Train F1: 0.510\n",
            "\t Val. Loss: 0.997 |  Val. Acc: 46.13% |  Val. F1: 0.529\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [11/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [11/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 11 | Epoch Time: 0m 7s | Total Time so far: 1m 24s\n",
            "\tTrain Loss: 0.989 | Train Acc: 44.80% | Train F1: 0.508\n",
            "\t Val. Loss: 1.004 |  Val. Acc: 45.67% |  Val. F1: 0.527\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [12/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [12/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 12 | Epoch Time: 0m 7s | Total Time so far: 1m 32s\n",
            "\tTrain Loss: 0.984 | Train Acc: 45.24% | Train F1: 0.513\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 48.01% |  Val. F1: 0.529\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [13/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [13/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 13 | Epoch Time: 0m 7s | Total Time so far: 1m 39s\n",
            "\tTrain Loss: 0.983 | Train Acc: 45.95% | Train F1: 0.514\n",
            "\t Val. Loss: 0.994 |  Val. Acc: 47.98% |  Val. F1: 0.528\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [14/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [14/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 14 | Epoch Time: 0m 7s | Total Time so far: 1m 47s\n",
            "\tTrain Loss: 0.983 | Train Acc: 45.87% | Train F1: 0.508\n",
            "\t Val. Loss: 0.987 |  Val. Acc: 47.30% |  Val. F1: 0.519\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [15/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [15/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 15 | Epoch Time: 0m 7s | Total Time so far: 1m 55s\n",
            "\tTrain Loss: 0.978 | Train Acc: 46.56% | Train F1: 0.516\n",
            "\t Val. Loss: 0.999 |  Val. Acc: 46.98% |  Val. F1: 0.527\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [16/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [16/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 16 | Epoch Time: 0m 7s | Total Time so far: 2m 2s\n",
            "\tTrain Loss: 0.981 | Train Acc: 46.52% | Train F1: 0.508\n",
            "\t Val. Loss: 0.994 |  Val. Acc: 48.26% |  Val. F1: 0.527\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [17/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [17/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 17 | Epoch Time: 0m 7s | Total Time so far: 2m 10s\n",
            "\tTrain Loss: 0.976 | Train Acc: 46.75% | Train F1: 0.513\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 47.09% |  Val. F1: 0.525\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [18/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [18/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 18 | Epoch Time: 0m 7s | Total Time so far: 2m 17s\n",
            "\tTrain Loss: 0.972 | Train Acc: 47.33% | Train F1: 0.519\n",
            "\t Val. Loss: 0.993 |  Val. Acc: 47.90% |  Val. F1: 0.523\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [19/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [19/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 19 | Epoch Time: 0m 7s | Total Time so far: 2m 25s\n",
            "\tTrain Loss: 0.973 | Train Acc: 47.35% | Train F1: 0.519\n",
            "\t Val. Loss: 0.994 |  Val. Acc: 48.12% |  Val. F1: 0.524\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [20/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [20/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 20 | Epoch Time: 0m 7s | Total Time so far: 2m 32s\n",
            "\tTrain Loss: 0.968 | Train Acc: 47.69% | Train F1: 0.521\n",
            "\t Val. Loss: 1.004 |  Val. Acc: 46.34% |  Val. F1: 0.518\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [21/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [21/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 21 | Epoch Time: 0m 7s | Total Time so far: 2m 40s\n",
            "\tTrain Loss: 0.969 | Train Acc: 47.88% | Train F1: 0.521\n",
            "\t Val. Loss: 0.996 |  Val. Acc: 48.26% |  Val. F1: 0.513\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [22/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [22/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 22 | Epoch Time: 0m 7s | Total Time so far: 2m 47s\n",
            "\tTrain Loss: 0.962 | Train Acc: 48.67% | Train F1: 0.524\n",
            "\t Val. Loss: 1.014 |  Val. Acc: 46.09% |  Val. F1: 0.520\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [23/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [23/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 23 | Epoch Time: 0m 7s | Total Time so far: 2m 55s\n",
            "\tTrain Loss: 0.963 | Train Acc: 48.38% | Train F1: 0.522\n",
            "\t Val. Loss: 1.034 |  Val. Acc: 47.30% |  Val. F1: 0.507\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [24/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [24/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 24 | Epoch Time: 0m 7s | Total Time so far: 3m 2s\n",
            "\tTrain Loss: 0.960 | Train Acc: 48.86% | Train F1: 0.525\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 47.59% |  Val. F1: 0.519\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [25/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [25/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 25 | Epoch Time: 0m 7s | Total Time so far: 3m 10s\n",
            "\tTrain Loss: 0.955 | Train Acc: 48.73% | Train F1: 0.530\n",
            "\t Val. Loss: 1.023 |  Val. Acc: 45.81% |  Val. F1: 0.518\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [26/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [26/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 26 | Epoch Time: 0m 7s | Total Time so far: 3m 17s\n",
            "\tTrain Loss: 0.956 | Train Acc: 48.63% | Train F1: 0.526\n",
            "\t Val. Loss: 1.019 |  Val. Acc: 46.02% |  Val. F1: 0.520\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [27/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [27/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 27 | Epoch Time: 0m 7s | Total Time so far: 3m 25s\n",
            "\tTrain Loss: 0.953 | Train Acc: 49.85% | Train F1: 0.533\n",
            "\t Val. Loss: 0.994 |  Val. Acc: 48.08% |  Val. F1: 0.519\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [28/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [28/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 28 | Epoch Time: 0m 7s | Total Time so far: 3m 32s\n",
            "\tTrain Loss: 0.950 | Train Acc: 49.55% | Train F1: 0.535\n",
            "\t Val. Loss: 1.009 |  Val. Acc: 47.59% |  Val. F1: 0.520\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [29/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [29/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 29 | Epoch Time: 0m 7s | Total Time so far: 3m 40s\n",
            "\tTrain Loss: 0.947 | Train Acc: 48.96% | Train F1: 0.527\n",
            "\t Val. Loss: 1.014 |  Val. Acc: 46.91% |  Val. F1: 0.519\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [30/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [30/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 30 | Epoch Time: 0m 7s | Total Time so far: 3m 47s\n",
            "\tTrain Loss: 0.944 | Train Acc: 50.05% | Train F1: 0.537\n",
            "\t Val. Loss: 1.019 |  Val. Acc: 50.21% |  Val. F1: 0.517\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [31/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [31/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 31 | Epoch Time: 0m 7s | Total Time so far: 3m 55s\n",
            "\tTrain Loss: 0.941 | Train Acc: 50.43% | Train F1: 0.538\n",
            "\t Val. Loss: 1.002 |  Val. Acc: 49.64% |  Val. F1: 0.516\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [32/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [32/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 32 | Epoch Time: 0m 7s | Total Time so far: 4m 2s\n",
            "\tTrain Loss: 0.940 | Train Acc: 50.44% | Train F1: 0.538\n",
            "\t Val. Loss: 1.017 |  Val. Acc: 49.36% |  Val. F1: 0.508\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [33/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [33/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 33 | Epoch Time: 0m 7s | Total Time so far: 4m 10s\n",
            "\tTrain Loss: 0.937 | Train Acc: 50.69% | Train F1: 0.539\n",
            "\t Val. Loss: 1.025 |  Val. Acc: 48.33% |  Val. F1: 0.515\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [34/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [34/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 34 | Epoch Time: 0m 7s | Total Time so far: 4m 17s\n",
            "\tTrain Loss: 0.935 | Train Acc: 51.00% | Train F1: 0.544\n",
            "\t Val. Loss: 1.025 |  Val. Acc: 48.69% |  Val. F1: 0.517\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [35/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [35/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 35 | Epoch Time: 0m 7s | Total Time so far: 4m 25s\n",
            "\tTrain Loss: 0.933 | Train Acc: 51.22% | Train F1: 0.545\n",
            "\t Val. Loss: 1.043 |  Val. Acc: 45.85% |  Val. F1: 0.512\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [36/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [36/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 36 | Epoch Time: 0m 7s | Total Time so far: 4m 32s\n",
            "\tTrain Loss: 0.926 | Train Acc: 51.80% | Train F1: 0.551\n",
            "\t Val. Loss: 1.003 |  Val. Acc: 49.68% |  Val. F1: 0.517\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [37/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [37/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 37 | Epoch Time: 0m 7s | Total Time so far: 4m 40s\n",
            "\tTrain Loss: 0.925 | Train Acc: 51.55% | Train F1: 0.552\n",
            "\t Val. Loss: 1.049 |  Val. Acc: 48.65% |  Val. F1: 0.494\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [38/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [38/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 38 | Epoch Time: 0m 7s | Total Time so far: 4m 47s\n",
            "\tTrain Loss: 0.919 | Train Acc: 51.88% | Train F1: 0.553\n",
            "\t Val. Loss: 1.077 |  Val. Acc: 46.91% |  Val. F1: 0.480\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [39/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [39/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 39 | Epoch Time: 0m 7s | Total Time so far: 4m 55s\n",
            "\tTrain Loss: 0.916 | Train Acc: 52.48% | Train F1: 0.555\n",
            "\t Val. Loss: 1.054 |  Val. Acc: 48.79% |  Val. F1: 0.505\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [40/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [40/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 40 | Epoch Time: 0m 7s | Total Time so far: 5m 2s\n",
            "\tTrain Loss: 0.917 | Train Acc: 52.31% | Train F1: 0.552\n",
            "\t Val. Loss: 1.034 |  Val. Acc: 47.55% |  Val. F1: 0.518\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [41/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [41/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 41 | Epoch Time: 0m 7s | Total Time so far: 5m 9s\n",
            "\tTrain Loss: 0.912 | Train Acc: 52.72% | Train F1: 0.557\n",
            "\t Val. Loss: 1.005 |  Val. Acc: 48.40% |  Val. F1: 0.513\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [42/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [42/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 42 | Epoch Time: 0m 7s | Total Time so far: 5m 17s\n",
            "\tTrain Loss: 0.909 | Train Acc: 52.85% | Train F1: 0.561\n",
            "\t Val. Loss: 1.082 |  Val. Acc: 45.88% |  Val. F1: 0.499\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [43/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [43/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 43 | Epoch Time: 0m 7s | Total Time so far: 5m 24s\n",
            "\tTrain Loss: 0.897 | Train Acc: 53.67% | Train F1: 0.567\n",
            "\t Val. Loss: 1.076 |  Val. Acc: 48.26% |  Val. F1: 0.500\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [44/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [44/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 44 | Epoch Time: 0m 7s | Total Time so far: 5m 32s\n",
            "\tTrain Loss: 0.898 | Train Acc: 53.95% | Train F1: 0.568\n",
            "\t Val. Loss: 1.052 |  Val. Acc: 49.33% |  Val. F1: 0.499\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [45/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [45/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 45 | Epoch Time: 0m 7s | Total Time so far: 5m 39s\n",
            "\tTrain Loss: 0.893 | Train Acc: 53.62% | Train F1: 0.567\n",
            "\t Val. Loss: 1.059 |  Val. Acc: 48.01% |  Val. F1: 0.495\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [46/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [46/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 46 | Epoch Time: 0m 7s | Total Time so far: 5m 47s\n",
            "\tTrain Loss: 0.895 | Train Acc: 54.13% | Train F1: 0.569\n",
            "\t Val. Loss: 1.049 |  Val. Acc: 48.54% |  Val. F1: 0.508\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [47/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [47/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 47 | Epoch Time: 0m 7s | Total Time so far: 5m 54s\n",
            "\tTrain Loss: 0.885 | Train Acc: 54.59% | Train F1: 0.577\n",
            "\t Val. Loss: 1.050 |  Val. Acc: 48.86% |  Val. F1: 0.510\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [48/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [48/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 48 | Epoch Time: 0m 7s | Total Time so far: 6m 2s\n",
            "\tTrain Loss: 0.879 | Train Acc: 54.77% | Train F1: 0.578\n",
            "\t Val. Loss: 1.085 |  Val. Acc: 47.48% |  Val. F1: 0.494\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [49/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [49/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 49 | Epoch Time: 0m 7s | Total Time so far: 6m 9s\n",
            "\tTrain Loss: 0.878 | Train Acc: 54.95% | Train F1: 0.580\n",
            "\t Val. Loss: 1.123 |  Val. Acc: 48.30% |  Val. F1: 0.472\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [50/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [50/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 50 | Epoch Time: 0m 7s | Total Time so far: 6m 17s\n",
            "\tTrain Loss: 0.878 | Train Acc: 54.93% | Train F1: 0.579\n",
            "\t Val. Loss: 1.076 |  Val. Acc: 48.12% |  Val. F1: 0.485\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [51/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [51/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 51 | Epoch Time: 0m 7s | Total Time so far: 6m 24s\n",
            "\tTrain Loss: 0.870 | Train Acc: 55.40% | Train F1: 0.583\n",
            "\t Val. Loss: 1.027 |  Val. Acc: 49.72% |  Val. F1: 0.505\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [52/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [52/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 52 | Epoch Time: 0m 7s | Total Time so far: 6m 32s\n",
            "\tTrain Loss: 0.865 | Train Acc: 56.06% | Train F1: 0.591\n",
            "\t Val. Loss: 1.075 |  Val. Acc: 47.37% |  Val. F1: 0.503\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [53/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [53/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 53 | Epoch Time: 0m 7s | Total Time so far: 6m 39s\n",
            "\tTrain Loss: 0.859 | Train Acc: 56.20% | Train F1: 0.591\n",
            "\t Val. Loss: 1.111 |  Val. Acc: 45.85% |  Val. F1: 0.488\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [54/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [54/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 54 | Epoch Time: 0m 7s | Total Time so far: 6m 47s\n",
            "\tTrain Loss: 0.853 | Train Acc: 56.31% | Train F1: 0.593\n",
            "\t Val. Loss: 1.100 |  Val. Acc: 48.79% |  Val. F1: 0.485\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [55/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [55/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 55 | Epoch Time: 0m 7s | Total Time so far: 6m 54s\n",
            "\tTrain Loss: 0.846 | Train Acc: 57.42% | Train F1: 0.601\n",
            "\t Val. Loss: 1.093 |  Val. Acc: 48.08% |  Val. F1: 0.486\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [56/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [56/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 56 | Epoch Time: 0m 7s | Total Time so far: 7m 2s\n",
            "\tTrain Loss: 0.839 | Train Acc: 57.33% | Train F1: 0.604\n",
            "\t Val. Loss: 1.035 |  Val. Acc: 50.71% |  Val. F1: 0.496\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [57/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [57/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 57 | Epoch Time: 0m 7s | Total Time so far: 7m 9s\n",
            "\tTrain Loss: 0.840 | Train Acc: 57.42% | Train F1: 0.605\n",
            "\t Val. Loss: 1.155 |  Val. Acc: 46.31% |  Val. F1: 0.488\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [58/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [58/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 58 | Epoch Time: 0m 7s | Total Time so far: 7m 17s\n",
            "\tTrain Loss: 0.830 | Train Acc: 57.82% | Train F1: 0.610\n",
            "\t Val. Loss: 1.099 |  Val. Acc: 47.80% |  Val. F1: 0.497\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [59/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [59/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 59 | Epoch Time: 0m 7s | Total Time so far: 7m 24s\n",
            "\tTrain Loss: 0.824 | Train Acc: 58.07% | Train F1: 0.613\n",
            "\t Val. Loss: 1.121 |  Val. Acc: 46.80% |  Val. F1: 0.502\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [60/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [60/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 60 | Epoch Time: 0m 7s | Total Time so far: 7m 32s\n",
            "\tTrain Loss: 0.815 | Train Acc: 58.34% | Train F1: 0.614\n",
            "\t Val. Loss: 1.127 |  Val. Acc: 47.37% |  Val. F1: 0.497\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [61/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [61/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 61 | Epoch Time: 0m 7s | Total Time so far: 7m 40s\n",
            "\tTrain Loss: 0.817 | Train Acc: 59.04% | Train F1: 0.619\n",
            "\t Val. Loss: 1.160 |  Val. Acc: 45.95% |  Val. F1: 0.469\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [62/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [62/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 62 | Epoch Time: 0m 7s | Total Time so far: 7m 47s\n",
            "\tTrain Loss: 0.810 | Train Acc: 58.98% | Train F1: 0.621\n",
            "\t Val. Loss: 1.137 |  Val. Acc: 47.37% |  Val. F1: 0.491\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [63/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [63/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 63 | Epoch Time: 0m 7s | Total Time so far: 7m 55s\n",
            "\tTrain Loss: 0.802 | Train Acc: 59.14% | Train F1: 0.624\n",
            "\t Val. Loss: 1.262 |  Val. Acc: 46.45% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [64/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [64/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 64 | Epoch Time: 0m 7s | Total Time so far: 8m 2s\n",
            "\tTrain Loss: 0.802 | Train Acc: 59.81% | Train F1: 0.625\n",
            "\t Val. Loss: 1.052 |  Val. Acc: 50.60% |  Val. F1: 0.506\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [65/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [65/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 65 | Epoch Time: 0m 7s | Total Time so far: 8m 9s\n",
            "\tTrain Loss: 0.796 | Train Acc: 60.04% | Train F1: 0.629\n",
            "\t Val. Loss: 1.087 |  Val. Acc: 50.53% |  Val. F1: 0.458\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [66/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [66/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 66 | Epoch Time: 0m 7s | Total Time so far: 8m 17s\n",
            "\tTrain Loss: 0.792 | Train Acc: 60.35% | Train F1: 0.631\n",
            "\t Val. Loss: 1.097 |  Val. Acc: 49.54% |  Val. F1: 0.500\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [67/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [67/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 67 | Epoch Time: 0m 7s | Total Time so far: 8m 24s\n",
            "\tTrain Loss: 0.779 | Train Acc: 61.05% | Train F1: 0.641\n",
            "\t Val. Loss: 1.152 |  Val. Acc: 49.36% |  Val. F1: 0.477\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [68/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [68/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 68 | Epoch Time: 0m 7s | Total Time so far: 8m 32s\n",
            "\tTrain Loss: 0.782 | Train Acc: 61.07% | Train F1: 0.639\n",
            "\t Val. Loss: 1.131 |  Val. Acc: 49.22% |  Val. F1: 0.495\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [69/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [69/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 69 | Epoch Time: 0m 7s | Total Time so far: 8m 39s\n",
            "\tTrain Loss: 0.773 | Train Acc: 61.44% | Train F1: 0.642\n",
            "\t Val. Loss: 1.211 |  Val. Acc: 48.08% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [70/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [70/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 70 | Epoch Time: 0m 7s | Total Time so far: 8m 47s\n",
            "\tTrain Loss: 0.769 | Train Acc: 61.56% | Train F1: 0.645\n",
            "\t Val. Loss: 1.140 |  Val. Acc: 50.00% |  Val. F1: 0.476\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [71/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [71/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 71 | Epoch Time: 0m 7s | Total Time so far: 8m 54s\n",
            "\tTrain Loss: 0.763 | Train Acc: 62.08% | Train F1: 0.650\n",
            "\t Val. Loss: 1.108 |  Val. Acc: 49.57% |  Val. F1: 0.504\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [72/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [72/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 72 | Epoch Time: 0m 7s | Total Time so far: 9m 1s\n",
            "\tTrain Loss: 0.752 | Train Acc: 62.86% | Train F1: 0.656\n",
            "\t Val. Loss: 1.152 |  Val. Acc: 49.82% |  Val. F1: 0.481\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [73/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [73/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 73 | Epoch Time: 0m 7s | Total Time so far: 9m 9s\n",
            "\tTrain Loss: 0.750 | Train Acc: 62.52% | Train F1: 0.655\n",
            "\t Val. Loss: 1.201 |  Val. Acc: 47.23% |  Val. F1: 0.477\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [74/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [74/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 74 | Epoch Time: 0m 7s | Total Time so far: 9m 16s\n",
            "\tTrain Loss: 0.746 | Train Acc: 62.71% | Train F1: 0.655\n",
            "\t Val. Loss: 1.167 |  Val. Acc: 48.93% |  Val. F1: 0.493\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [75/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [75/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 75 | Epoch Time: 0m 7s | Total Time so far: 9m 24s\n",
            "\tTrain Loss: 0.741 | Train Acc: 63.33% | Train F1: 0.660\n",
            "\t Val. Loss: 1.244 |  Val. Acc: 47.87% |  Val. F1: 0.484\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [76/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [76/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 76 | Epoch Time: 0m 7s | Total Time so far: 9m 31s\n",
            "\tTrain Loss: 0.741 | Train Acc: 63.35% | Train F1: 0.660\n",
            "\t Val. Loss: 1.368 |  Val. Acc: 47.83% |  Val. F1: 0.448\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [77/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [77/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 77 | Epoch Time: 0m 7s | Total Time so far: 9m 39s\n",
            "\tTrain Loss: 0.733 | Train Acc: 63.37% | Train F1: 0.662\n",
            "\t Val. Loss: 1.155 |  Val. Acc: 49.54% |  Val. F1: 0.498\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [78/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [78/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 78 | Epoch Time: 0m 7s | Total Time so far: 9m 46s\n",
            "\tTrain Loss: 0.727 | Train Acc: 64.35% | Train F1: 0.670\n",
            "\t Val. Loss: 1.256 |  Val. Acc: 48.05% |  Val. F1: 0.471\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [79/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [79/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 79 | Epoch Time: 0m 7s | Total Time so far: 9m 53s\n",
            "\tTrain Loss: 0.718 | Train Acc: 64.68% | Train F1: 0.672\n",
            "\t Val. Loss: 1.191 |  Val. Acc: 48.58% |  Val. F1: 0.492\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [80/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [80/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 80 | Epoch Time: 0m 7s | Total Time so far: 10m 1s\n",
            "\tTrain Loss: 0.712 | Train Acc: 65.36% | Train F1: 0.679\n",
            "\t Val. Loss: 1.176 |  Val. Acc: 49.25% |  Val. F1: 0.496\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [81/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [81/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 81 | Epoch Time: 0m 7s | Total Time so far: 10m 8s\n",
            "\tTrain Loss: 0.713 | Train Acc: 64.77% | Train F1: 0.676\n",
            "\t Val. Loss: 1.205 |  Val. Acc: 49.93% |  Val. F1: 0.488\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [82/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [82/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 82 | Epoch Time: 0m 7s | Total Time so far: 10m 16s\n",
            "\tTrain Loss: 0.703 | Train Acc: 65.33% | Train F1: 0.680\n",
            "\t Val. Loss: 1.275 |  Val. Acc: 48.86% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [83/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [83/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 83 | Epoch Time: 0m 7s | Total Time so far: 10m 23s\n",
            "\tTrain Loss: 0.701 | Train Acc: 65.70% | Train F1: 0.683\n",
            "\t Val. Loss: 1.170 |  Val. Acc: 49.15% |  Val. F1: 0.498\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [84/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [84/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 84 | Epoch Time: 0m 7s | Total Time so far: 10m 30s\n",
            "\tTrain Loss: 0.700 | Train Acc: 65.74% | Train F1: 0.684\n",
            "\t Val. Loss: 1.167 |  Val. Acc: 49.68% |  Val. F1: 0.504\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [85/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [85/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 85 | Epoch Time: 0m 7s | Total Time so far: 10m 38s\n",
            "\tTrain Loss: 0.693 | Train Acc: 65.75% | Train F1: 0.683\n",
            "\t Val. Loss: 1.548 |  Val. Acc: 48.47% |  Val. F1: 0.430\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [86/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [86/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 86 | Epoch Time: 0m 7s | Total Time so far: 10m 45s\n",
            "\tTrain Loss: 0.690 | Train Acc: 66.38% | Train F1: 0.687\n",
            "\t Val. Loss: 1.279 |  Val. Acc: 49.18% |  Val. F1: 0.478\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [87/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [87/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 87 | Epoch Time: 0m 7s | Total Time so far: 10m 53s\n",
            "\tTrain Loss: 0.686 | Train Acc: 66.49% | Train F1: 0.691\n",
            "\t Val. Loss: 1.214 |  Val. Acc: 49.11% |  Val. F1: 0.477\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [88/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [88/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 88 | Epoch Time: 0m 7s | Total Time so far: 11m 0s\n",
            "\tTrain Loss: 0.680 | Train Acc: 67.15% | Train F1: 0.696\n",
            "\t Val. Loss: 1.205 |  Val. Acc: 49.25% |  Val. F1: 0.501\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [89/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [89/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 89 | Epoch Time: 0m 7s | Total Time so far: 11m 8s\n",
            "\tTrain Loss: 0.671 | Train Acc: 67.42% | Train F1: 0.698\n",
            "\t Val. Loss: 1.292 |  Val. Acc: 50.36% |  Val. F1: 0.463\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [90/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [90/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 90 | Epoch Time: 0m 7s | Total Time so far: 11m 15s\n",
            "\tTrain Loss: 0.669 | Train Acc: 67.38% | Train F1: 0.699\n",
            "\t Val. Loss: 1.332 |  Val. Acc: 49.01% |  Val. F1: 0.456\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [91/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [91/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 91 | Epoch Time: 0m 7s | Total Time so far: 11m 22s\n",
            "\tTrain Loss: 0.663 | Train Acc: 67.77% | Train F1: 0.705\n",
            "\t Val. Loss: 1.283 |  Val. Acc: 49.25% |  Val. F1: 0.473\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [92/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [92/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 92 | Epoch Time: 0m 7s | Total Time so far: 11m 30s\n",
            "\tTrain Loss: 0.658 | Train Acc: 68.11% | Train F1: 0.707\n",
            "\t Val. Loss: 1.209 |  Val. Acc: 50.14% |  Val. F1: 0.484\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [93/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [93/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 93 | Epoch Time: 0m 7s | Total Time so far: 11m 37s\n",
            "\tTrain Loss: 0.658 | Train Acc: 67.85% | Train F1: 0.704\n",
            "\t Val. Loss: 1.342 |  Val. Acc: 48.76% |  Val. F1: 0.461\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [94/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [94/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 94 | Epoch Time: 0m 7s | Total Time so far: 11m 45s\n",
            "\tTrain Loss: 0.647 | Train Acc: 68.40% | Train F1: 0.707\n",
            "\t Val. Loss: 1.245 |  Val. Acc: 49.36% |  Val. F1: 0.496\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [95/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [95/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 95 | Epoch Time: 0m 7s | Total Time so far: 11m 52s\n",
            "\tTrain Loss: 0.645 | Train Acc: 69.01% | Train F1: 0.712\n",
            "\t Val. Loss: 1.305 |  Val. Acc: 49.79% |  Val. F1: 0.464\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [96/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [96/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 96 | Epoch Time: 0m 7s | Total Time so far: 12m 0s\n",
            "\tTrain Loss: 0.637 | Train Acc: 69.17% | Train F1: 0.714\n",
            "\t Val. Loss: 1.278 |  Val. Acc: 50.04% |  Val. F1: 0.488\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [97/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [97/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 97 | Epoch Time: 0m 7s | Total Time so far: 12m 7s\n",
            "\tTrain Loss: 0.635 | Train Acc: 69.51% | Train F1: 0.717\n",
            "\t Val. Loss: 1.310 |  Val. Acc: 48.15% |  Val. F1: 0.503\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [98/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [98/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 98 | Epoch Time: 0m 7s | Total Time so far: 12m 15s\n",
            "\tTrain Loss: 0.628 | Train Acc: 69.61% | Train F1: 0.720\n",
            "\t Val. Loss: 1.237 |  Val. Acc: 50.82% |  Val. F1: 0.490\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [99/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [99/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 99 | Epoch Time: 0m 7s | Total Time so far: 12m 22s\n",
            "\tTrain Loss: 0.629 | Train Acc: 69.71% | Train F1: 0.720\n",
            "\t Val. Loss: 1.386 |  Val. Acc: 48.86% |  Val. F1: 0.470\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [100/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [100/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 100 | Epoch Time: 0m 7s | Total Time so far: 12m 30s\n",
            "\tTrain Loss: 0.622 | Train Acc: 69.86% | Train F1: 0.723\n",
            "\t Val. Loss: 1.277 |  Val. Acc: 49.25% |  Val. F1: 0.480\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [101/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [101/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 101 | Epoch Time: 0m 7s | Total Time so far: 12m 37s\n",
            "\tTrain Loss: 0.620 | Train Acc: 70.77% | Train F1: 0.729\n",
            "\t Val. Loss: 1.225 |  Val. Acc: 50.36% |  Val. F1: 0.490\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [102/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [102/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 102 | Epoch Time: 0m 7s | Total Time so far: 12m 45s\n",
            "\tTrain Loss: 0.610 | Train Acc: 70.96% | Train F1: 0.731\n",
            "\t Val. Loss: 1.361 |  Val. Acc: 49.25% |  Val. F1: 0.481\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [103/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [103/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 103 | Epoch Time: 0m 7s | Total Time so far: 12m 52s\n",
            "\tTrain Loss: 0.598 | Train Acc: 71.52% | Train F1: 0.735\n",
            "\t Val. Loss: 1.487 |  Val. Acc: 48.93% |  Val. F1: 0.456\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [104/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [104/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 104 | Epoch Time: 0m 7s | Total Time so far: 13m 0s\n",
            "\tTrain Loss: 0.602 | Train Acc: 71.23% | Train F1: 0.733\n",
            "\t Val. Loss: 1.441 |  Val. Acc: 49.86% |  Val. F1: 0.452\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [105/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [105/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 105 | Epoch Time: 0m 7s | Total Time so far: 13m 7s\n",
            "\tTrain Loss: 0.598 | Train Acc: 71.83% | Train F1: 0.739\n",
            "\t Val. Loss: 1.288 |  Val. Acc: 50.18% |  Val. F1: 0.486\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [106/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [106/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 106 | Epoch Time: 0m 7s | Total Time so far: 13m 14s\n",
            "\tTrain Loss: 0.587 | Train Acc: 72.50% | Train F1: 0.746\n",
            "\t Val. Loss: 1.389 |  Val. Acc: 49.68% |  Val. F1: 0.491\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [107/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [107/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 107 | Epoch Time: 0m 7s | Total Time so far: 13m 22s\n",
            "\tTrain Loss: 0.593 | Train Acc: 71.72% | Train F1: 0.737\n",
            "\t Val. Loss: 1.346 |  Val. Acc: 49.75% |  Val. F1: 0.465\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [108/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [108/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 108 | Epoch Time: 0m 7s | Total Time so far: 13m 29s\n",
            "\tTrain Loss: 0.588 | Train Acc: 72.19% | Train F1: 0.741\n",
            "\t Val. Loss: 1.194 |  Val. Acc: 49.33% |  Val. F1: 0.483\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [109/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [109/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 109 | Epoch Time: 0m 7s | Total Time so far: 13m 37s\n",
            "\tTrain Loss: 0.591 | Train Acc: 72.07% | Train F1: 0.740\n",
            "\t Val. Loss: 1.451 |  Val. Acc: 50.18% |  Val. F1: 0.458\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [110/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [110/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 110 | Epoch Time: 0m 7s | Total Time so far: 13m 44s\n",
            "\tTrain Loss: 0.572 | Train Acc: 72.94% | Train F1: 0.749\n",
            "\t Val. Loss: 1.328 |  Val. Acc: 51.17% |  Val. F1: 0.462\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [111/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [111/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 111 | Epoch Time: 0m 7s | Total Time so far: 13m 52s\n",
            "\tTrain Loss: 0.564 | Train Acc: 73.62% | Train F1: 0.755\n",
            "\t Val. Loss: 1.408 |  Val. Acc: 47.16% |  Val. F1: 0.466\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [112/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [112/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 112 | Epoch Time: 0m 7s | Total Time so far: 13m 59s\n",
            "\tTrain Loss: 0.562 | Train Acc: 73.54% | Train F1: 0.756\n",
            "\t Val. Loss: 1.376 |  Val. Acc: 50.57% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [113/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [113/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 113 | Epoch Time: 0m 7s | Total Time so far: 14m 7s\n",
            "\tTrain Loss: 0.558 | Train Acc: 73.83% | Train F1: 0.757\n",
            "\t Val. Loss: 1.427 |  Val. Acc: 49.08% |  Val. F1: 0.471\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [114/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [114/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 114 | Epoch Time: 0m 7s | Total Time so far: 14m 14s\n",
            "\tTrain Loss: 0.561 | Train Acc: 73.86% | Train F1: 0.755\n",
            "\t Val. Loss: 1.432 |  Val. Acc: 48.30% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [115/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [115/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 115 | Epoch Time: 0m 7s | Total Time so far: 14m 21s\n",
            "\tTrain Loss: 0.550 | Train Acc: 73.97% | Train F1: 0.758\n",
            "\t Val. Loss: 1.442 |  Val. Acc: 49.61% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [116/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [116/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 116 | Epoch Time: 0m 7s | Total Time so far: 14m 29s\n",
            "\tTrain Loss: 0.537 | Train Acc: 74.98% | Train F1: 0.767\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 49.08% |  Val. F1: 0.452\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [117/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [117/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 117 | Epoch Time: 0m 7s | Total Time so far: 14m 36s\n",
            "\tTrain Loss: 0.541 | Train Acc: 74.99% | Train F1: 0.768\n",
            "\t Val. Loss: 1.384 |  Val. Acc: 48.97% |  Val. F1: 0.479\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [118/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [118/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 118 | Epoch Time: 0m 7s | Total Time so far: 14m 44s\n",
            "\tTrain Loss: 0.540 | Train Acc: 75.10% | Train F1: 0.768\n",
            "\t Val. Loss: 1.511 |  Val. Acc: 49.75% |  Val. F1: 0.467\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [119/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [119/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 119 | Epoch Time: 0m 7s | Total Time so far: 14m 51s\n",
            "\tTrain Loss: 0.536 | Train Acc: 75.08% | Train F1: 0.768\n",
            "\t Val. Loss: 1.551 |  Val. Acc: 48.90% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [120/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [120/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 120 | Epoch Time: 0m 7s | Total Time so far: 14m 59s\n",
            "\tTrain Loss: 0.531 | Train Acc: 75.74% | Train F1: 0.774\n",
            "\t Val. Loss: 1.482 |  Val. Acc: 49.33% |  Val. F1: 0.466\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [121/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [121/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 121 | Epoch Time: 0m 7s | Total Time so far: 15m 6s\n",
            "\tTrain Loss: 0.529 | Train Acc: 75.56% | Train F1: 0.771\n",
            "\t Val. Loss: 1.387 |  Val. Acc: 51.03% |  Val. F1: 0.480\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [122/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [122/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 122 | Epoch Time: 0m 7s | Total Time so far: 15m 14s\n",
            "\tTrain Loss: 0.519 | Train Acc: 75.63% | Train F1: 0.775\n",
            "\t Val. Loss: 1.508 |  Val. Acc: 49.36% |  Val. F1: 0.460\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [123/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [123/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 123 | Epoch Time: 0m 7s | Total Time so far: 15m 21s\n",
            "\tTrain Loss: 0.520 | Train Acc: 75.89% | Train F1: 0.774\n",
            "\t Val. Loss: 1.408 |  Val. Acc: 50.39% |  Val. F1: 0.469\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [124/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [124/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 124 | Epoch Time: 0m 7s | Total Time so far: 15m 28s\n",
            "\tTrain Loss: 0.511 | Train Acc: 76.35% | Train F1: 0.780\n",
            "\t Val. Loss: 1.505 |  Val. Acc: 49.01% |  Val. F1: 0.457\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [125/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [125/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 125 | Epoch Time: 0m 7s | Total Time so far: 15m 36s\n",
            "\tTrain Loss: 0.502 | Train Acc: 76.87% | Train F1: 0.785\n",
            "\t Val. Loss: 1.516 |  Val. Acc: 48.62% |  Val. F1: 0.456\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [126/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [126/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 126 | Epoch Time: 0m 7s | Total Time so far: 15m 43s\n",
            "\tTrain Loss: 0.494 | Train Acc: 77.13% | Train F1: 0.787\n",
            "\t Val. Loss: 1.606 |  Val. Acc: 49.15% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [127/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [127/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 127 | Epoch Time: 0m 7s | Total Time so far: 15m 51s\n",
            "\tTrain Loss: 0.502 | Train Acc: 77.14% | Train F1: 0.785\n",
            "\t Val. Loss: 1.652 |  Val. Acc: 48.44% |  Val. F1: 0.419\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [128/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [128/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 128 | Epoch Time: 0m 7s | Total Time so far: 15m 58s\n",
            "\tTrain Loss: 0.498 | Train Acc: 77.10% | Train F1: 0.786\n",
            "\t Val. Loss: 1.588 |  Val. Acc: 48.97% |  Val. F1: 0.452\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [129/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [129/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 129 | Epoch Time: 0m 7s | Total Time so far: 16m 6s\n",
            "\tTrain Loss: 0.484 | Train Acc: 78.14% | Train F1: 0.795\n",
            "\t Val. Loss: 1.543 |  Val. Acc: 49.36% |  Val. F1: 0.479\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [130/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [130/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 130 | Epoch Time: 0m 7s | Total Time so far: 16m 13s\n",
            "\tTrain Loss: 0.478 | Train Acc: 78.03% | Train F1: 0.795\n",
            "\t Val. Loss: 1.608 |  Val. Acc: 49.40% |  Val. F1: 0.433\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [131/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [131/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 131 | Epoch Time: 0m 7s | Total Time so far: 16m 21s\n",
            "\tTrain Loss: 0.484 | Train Acc: 77.68% | Train F1: 0.790\n",
            "\t Val. Loss: 1.509 |  Val. Acc: 49.40% |  Val. F1: 0.485\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [132/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [132/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 132 | Epoch Time: 0m 7s | Total Time so far: 16m 28s\n",
            "\tTrain Loss: 0.471 | Train Acc: 78.19% | Train F1: 0.797\n",
            "\t Val. Loss: 1.412 |  Val. Acc: 50.57% |  Val. F1: 0.473\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [133/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [133/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 133 | Epoch Time: 0m 7s | Total Time so far: 16m 35s\n",
            "\tTrain Loss: 0.469 | Train Acc: 78.97% | Train F1: 0.803\n",
            "\t Val. Loss: 1.594 |  Val. Acc: 48.97% |  Val. F1: 0.463\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [134/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [134/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 134 | Epoch Time: 0m 7s | Total Time so far: 16m 43s\n",
            "\tTrain Loss: 0.459 | Train Acc: 79.07% | Train F1: 0.804\n",
            "\t Val. Loss: 1.580 |  Val. Acc: 50.21% |  Val. F1: 0.471\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [135/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [135/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 135 | Epoch Time: 0m 7s | Total Time so far: 16m 50s\n",
            "\tTrain Loss: 0.460 | Train Acc: 79.10% | Train F1: 0.805\n",
            "\t Val. Loss: 1.593 |  Val. Acc: 49.61% |  Val. F1: 0.442\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [136/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [136/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 136 | Epoch Time: 0m 7s | Total Time so far: 16m 58s\n",
            "\tTrain Loss: 0.460 | Train Acc: 79.20% | Train F1: 0.805\n",
            "\t Val. Loss: 1.594 |  Val. Acc: 48.26% |  Val. F1: 0.452\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [137/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [137/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 137 | Epoch Time: 0m 7s | Total Time so far: 17m 5s\n",
            "\tTrain Loss: 0.447 | Train Acc: 79.90% | Train F1: 0.812\n",
            "\t Val. Loss: 1.717 |  Val. Acc: 47.41% |  Val. F1: 0.435\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [138/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [138/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 138 | Epoch Time: 0m 7s | Total Time so far: 17m 12s\n",
            "\tTrain Loss: 0.445 | Train Acc: 79.73% | Train F1: 0.811\n",
            "\t Val. Loss: 1.715 |  Val. Acc: 48.76% |  Val. F1: 0.418\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [139/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [139/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 139 | Epoch Time: 0m 7s | Total Time so far: 17m 20s\n",
            "\tTrain Loss: 0.445 | Train Acc: 79.86% | Train F1: 0.810\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 48.69% |  Val. F1: 0.462\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [140/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [140/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 140 | Epoch Time: 0m 7s | Total Time so far: 17m 28s\n",
            "\tTrain Loss: 0.432 | Train Acc: 80.37% | Train F1: 0.816\n",
            "\t Val. Loss: 1.779 |  Val. Acc: 48.44% |  Val. F1: 0.445\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [141/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [141/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 141 | Epoch Time: 0m 7s | Total Time so far: 17m 35s\n",
            "\tTrain Loss: 0.431 | Train Acc: 80.72% | Train F1: 0.819\n",
            "\t Val. Loss: 1.564 |  Val. Acc: 50.18% |  Val. F1: 0.475\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [142/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [142/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 142 | Epoch Time: 0m 7s | Total Time so far: 17m 42s\n",
            "\tTrain Loss: 0.426 | Train Acc: 80.99% | Train F1: 0.821\n",
            "\t Val. Loss: 1.723 |  Val. Acc: 49.79% |  Val. F1: 0.427\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [143/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [143/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 143 | Epoch Time: 0m 7s | Total Time so far: 17m 50s\n",
            "\tTrain Loss: 0.423 | Train Acc: 81.26% | Train F1: 0.823\n",
            "\t Val. Loss: 1.802 |  Val. Acc: 48.90% |  Val. F1: 0.438\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [144/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [144/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 144 | Epoch Time: 0m 7s | Total Time so far: 17m 57s\n",
            "\tTrain Loss: 0.425 | Train Acc: 81.01% | Train F1: 0.820\n",
            "\t Val. Loss: 1.706 |  Val. Acc: 48.33% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [145/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [145/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 145 | Epoch Time: 0m 7s | Total Time so far: 18m 5s\n",
            "\tTrain Loss: 0.412 | Train Acc: 81.64% | Train F1: 0.828\n",
            "\t Val. Loss: 1.740 |  Val. Acc: 49.57% |  Val. F1: 0.451\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [146/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [146/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 146 | Epoch Time: 0m 7s | Total Time so far: 18m 12s\n",
            "\tTrain Loss: 0.417 | Train Acc: 81.30% | Train F1: 0.823\n",
            "\t Val. Loss: 1.707 |  Val. Acc: 49.43% |  Val. F1: 0.448\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [147/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [147/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 147 | Epoch Time: 0m 7s | Total Time so far: 18m 20s\n",
            "\tTrain Loss: 0.407 | Train Acc: 81.91% | Train F1: 0.830\n",
            "\t Val. Loss: 1.692 |  Val. Acc: 49.04% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [148/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [148/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 148 | Epoch Time: 0m 7s | Total Time so far: 18m 27s\n",
            "\tTrain Loss: 0.401 | Train Acc: 82.36% | Train F1: 0.832\n",
            "\t Val. Loss: 1.771 |  Val. Acc: 48.86% |  Val. F1: 0.443\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [149/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [149/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 149 | Epoch Time: 0m 7s | Total Time so far: 18m 34s\n",
            "\tTrain Loss: 0.398 | Train Acc: 82.33% | Train F1: 0.834\n",
            "\t Val. Loss: 1.640 |  Val. Acc: 50.39% |  Val. F1: 0.488\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [150/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [150/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 150 | Epoch Time: 0m 7s | Total Time so far: 18m 42s\n",
            "\tTrain Loss: 0.391 | Train Acc: 82.88% | Train F1: 0.839\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 46.73% |  Val. F1: 0.412\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [151/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [151/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 151 | Epoch Time: 0m 7s | Total Time so far: 18m 49s\n",
            "\tTrain Loss: 0.400 | Train Acc: 82.62% | Train F1: 0.833\n",
            "\t Val. Loss: 1.696 |  Val. Acc: 49.93% |  Val. F1: 0.469\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [152/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [152/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 152 | Epoch Time: 0m 7s | Total Time so far: 18m 57s\n",
            "\tTrain Loss: 0.385 | Train Acc: 82.70% | Train F1: 0.838\n",
            "\t Val. Loss: 1.779 |  Val. Acc: 49.08% |  Val. F1: 0.473\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [153/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [153/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 153 | Epoch Time: 0m 7s | Total Time so far: 19m 4s\n",
            "\tTrain Loss: 0.380 | Train Acc: 83.02% | Train F1: 0.840\n",
            "\t Val. Loss: 1.730 |  Val. Acc: 50.64% |  Val. F1: 0.440\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [154/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [154/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 154 | Epoch Time: 0m 7s | Total Time so far: 19m 12s\n",
            "\tTrain Loss: 0.385 | Train Acc: 83.44% | Train F1: 0.843\n",
            "\t Val. Loss: 1.786 |  Val. Acc: 48.30% |  Val. F1: 0.445\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [155/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [155/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 155 | Epoch Time: 0m 7s | Total Time so far: 19m 19s\n",
            "\tTrain Loss: 0.377 | Train Acc: 83.54% | Train F1: 0.844\n",
            "\t Val. Loss: 1.742 |  Val. Acc: 50.14% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [156/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [156/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 156 | Epoch Time: 0m 7s | Total Time so far: 19m 26s\n",
            "\tTrain Loss: 0.370 | Train Acc: 84.02% | Train F1: 0.848\n",
            "\t Val. Loss: 1.683 |  Val. Acc: 50.07% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [157/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [157/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 157 | Epoch Time: 0m 7s | Total Time so far: 19m 34s\n",
            "\tTrain Loss: 0.366 | Train Acc: 84.38% | Train F1: 0.851\n",
            "\t Val. Loss: 1.857 |  Val. Acc: 47.69% |  Val. F1: 0.436\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [158/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [158/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 158 | Epoch Time: 0m 7s | Total Time so far: 19m 41s\n",
            "\tTrain Loss: 0.358 | Train Acc: 84.59% | Train F1: 0.853\n",
            "\t Val. Loss: 1.809 |  Val. Acc: 48.76% |  Val. F1: 0.424\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [159/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [159/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 159 | Epoch Time: 0m 7s | Total Time so far: 19m 48s\n",
            "\tTrain Loss: 0.358 | Train Acc: 84.41% | Train F1: 0.852\n",
            "\t Val. Loss: 1.887 |  Val. Acc: 49.11% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [160/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [160/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 160 | Epoch Time: 0m 7s | Total Time so far: 19m 56s\n",
            "\tTrain Loss: 0.356 | Train Acc: 84.49% | Train F1: 0.853\n",
            "\t Val. Loss: 1.896 |  Val. Acc: 49.18% |  Val. F1: 0.437\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [161/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [161/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 161 | Epoch Time: 0m 7s | Total Time so far: 20m 3s\n",
            "\tTrain Loss: 0.361 | Train Acc: 84.37% | Train F1: 0.852\n",
            "\t Val. Loss: 1.718 |  Val. Acc: 51.03% |  Val. F1: 0.475\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [162/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [162/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 162 | Epoch Time: 0m 7s | Total Time so far: 20m 11s\n",
            "\tTrain Loss: 0.349 | Train Acc: 84.78% | Train F1: 0.855\n",
            "\t Val. Loss: 2.127 |  Val. Acc: 47.66% |  Val. F1: 0.422\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [163/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [163/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 163 | Epoch Time: 0m 7s | Total Time so far: 20m 18s\n",
            "\tTrain Loss: 0.351 | Train Acc: 85.10% | Train F1: 0.857\n",
            "\t Val. Loss: 1.847 |  Val. Acc: 50.89% |  Val. F1: 0.463\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [164/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [164/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 164 | Epoch Time: 0m 7s | Total Time so far: 20m 25s\n",
            "\tTrain Loss: 0.338 | Train Acc: 85.24% | Train F1: 0.859\n",
            "\t Val. Loss: 1.872 |  Val. Acc: 49.25% |  Val. F1: 0.462\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [165/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [165/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 165 | Epoch Time: 0m 7s | Total Time so far: 20m 33s\n",
            "\tTrain Loss: 0.342 | Train Acc: 85.35% | Train F1: 0.859\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 49.18% |  Val. F1: 0.418\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [166/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [166/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 166 | Epoch Time: 0m 7s | Total Time so far: 20m 40s\n",
            "\tTrain Loss: 0.340 | Train Acc: 85.55% | Train F1: 0.861\n",
            "\t Val. Loss: 1.863 |  Val. Acc: 47.48% |  Val. F1: 0.463\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [167/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [167/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 167 | Epoch Time: 0m 7s | Total Time so far: 20m 48s\n",
            "\tTrain Loss: 0.331 | Train Acc: 85.80% | Train F1: 0.864\n",
            "\t Val. Loss: 2.041 |  Val. Acc: 47.98% |  Val. F1: 0.431\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [168/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [168/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 168 | Epoch Time: 0m 7s | Total Time so far: 20m 55s\n",
            "\tTrain Loss: 0.329 | Train Acc: 85.79% | Train F1: 0.863\n",
            "\t Val. Loss: 1.901 |  Val. Acc: 47.55% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [169/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [169/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 169 | Epoch Time: 0m 7s | Total Time so far: 21m 2s\n",
            "\tTrain Loss: 0.326 | Train Acc: 85.76% | Train F1: 0.864\n",
            "\t Val. Loss: 2.014 |  Val. Acc: 49.18% |  Val. F1: 0.389\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [170/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [170/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 170 | Epoch Time: 0m 7s | Total Time so far: 21m 10s\n",
            "\tTrain Loss: 0.316 | Train Acc: 86.56% | Train F1: 0.871\n",
            "\t Val. Loss: 1.807 |  Val. Acc: 49.75% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [171/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [171/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 171 | Epoch Time: 0m 7s | Total Time so far: 21m 17s\n",
            "\tTrain Loss: 0.315 | Train Acc: 86.40% | Train F1: 0.869\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 49.82% |  Val. F1: 0.429\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [172/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [172/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 172 | Epoch Time: 0m 7s | Total Time so far: 21m 25s\n",
            "\tTrain Loss: 0.313 | Train Acc: 86.42% | Train F1: 0.870\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 48.79% |  Val. F1: 0.458\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [173/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [173/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 173 | Epoch Time: 0m 7s | Total Time so far: 21m 32s\n",
            "\tTrain Loss: 0.311 | Train Acc: 86.63% | Train F1: 0.872\n",
            "\t Val. Loss: 2.056 |  Val. Acc: 49.68% |  Val. F1: 0.417\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [174/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [174/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 174 | Epoch Time: 0m 7s | Total Time so far: 21m 40s\n",
            "\tTrain Loss: 0.302 | Train Acc: 87.11% | Train F1: 0.877\n",
            "\t Val. Loss: 2.061 |  Val. Acc: 49.43% |  Val. F1: 0.425\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [175/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [175/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 175 | Epoch Time: 0m 7s | Total Time so far: 21m 47s\n",
            "\tTrain Loss: 0.309 | Train Acc: 86.77% | Train F1: 0.873\n",
            "\t Val. Loss: 1.853 |  Val. Acc: 50.32% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [176/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [176/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 176 | Epoch Time: 0m 7s | Total Time so far: 21m 54s\n",
            "\tTrain Loss: 0.297 | Train Acc: 87.56% | Train F1: 0.880\n",
            "\t Val. Loss: 2.064 |  Val. Acc: 47.66% |  Val. F1: 0.446\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [177/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [177/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 177 | Epoch Time: 0m 7s | Total Time so far: 22m 2s\n",
            "\tTrain Loss: 0.293 | Train Acc: 87.77% | Train F1: 0.883\n",
            "\t Val. Loss: 2.018 |  Val. Acc: 49.11% |  Val. F1: 0.434\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [178/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [178/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 178 | Epoch Time: 0m 7s | Total Time so far: 22m 9s\n",
            "\tTrain Loss: 0.290 | Train Acc: 87.52% | Train F1: 0.880\n",
            "\t Val. Loss: 2.224 |  Val. Acc: 47.27% |  Val. F1: 0.427\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [179/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [179/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 179 | Epoch Time: 0m 7s | Total Time so far: 22m 17s\n",
            "\tTrain Loss: 0.301 | Train Acc: 87.33% | Train F1: 0.877\n",
            "\t Val. Loss: 1.869 |  Val. Acc: 51.14% |  Val. F1: 0.459\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [180/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [180/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 180 | Epoch Time: 0m 7s | Total Time so far: 22m 24s\n",
            "\tTrain Loss: 0.295 | Train Acc: 87.46% | Train F1: 0.879\n",
            "\t Val. Loss: 1.952 |  Val. Acc: 50.43% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [181/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [181/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 181 | Epoch Time: 0m 7s | Total Time so far: 22m 32s\n",
            "\tTrain Loss: 0.273 | Train Acc: 88.55% | Train F1: 0.890\n",
            "\t Val. Loss: 2.083 |  Val. Acc: 49.29% |  Val. F1: 0.471\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [182/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [182/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 182 | Epoch Time: 0m 7s | Total Time so far: 22m 39s\n",
            "\tTrain Loss: 0.270 | Train Acc: 88.77% | Train F1: 0.892\n",
            "\t Val. Loss: 2.126 |  Val. Acc: 50.14% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [183/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [183/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 183 | Epoch Time: 0m 7s | Total Time so far: 22m 47s\n",
            "\tTrain Loss: 0.278 | Train Acc: 88.46% | Train F1: 0.887\n",
            "\t Val. Loss: 2.220 |  Val. Acc: 48.65% |  Val. F1: 0.453\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [184/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [184/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 184 | Epoch Time: 0m 7s | Total Time so far: 22m 54s\n",
            "\tTrain Loss: 0.289 | Train Acc: 87.70% | Train F1: 0.880\n",
            "\t Val. Loss: 1.969 |  Val. Acc: 50.00% |  Val. F1: 0.438\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [185/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [185/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 185 | Epoch Time: 0m 7s | Total Time so far: 23m 2s\n",
            "\tTrain Loss: 0.259 | Train Acc: 89.31% | Train F1: 0.896\n",
            "\t Val. Loss: 2.072 |  Val. Acc: 50.89% |  Val. F1: 0.464\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [186/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [186/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 186 | Epoch Time: 0m 7s | Total Time so far: 23m 9s\n",
            "\tTrain Loss: 0.266 | Train Acc: 89.07% | Train F1: 0.895\n",
            "\t Val. Loss: 1.859 |  Val. Acc: 51.10% |  Val. F1: 0.466\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [187/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [187/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 187 | Epoch Time: 0m 7s | Total Time so far: 23m 16s\n",
            "\tTrain Loss: 0.260 | Train Acc: 89.44% | Train F1: 0.898\n",
            "\t Val. Loss: 2.151 |  Val. Acc: 49.15% |  Val. F1: 0.438\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [188/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [188/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 188 | Epoch Time: 0m 7s | Total Time so far: 23m 24s\n",
            "\tTrain Loss: 0.252 | Train Acc: 89.49% | Train F1: 0.898\n",
            "\t Val. Loss: 2.043 |  Val. Acc: 50.28% |  Val. F1: 0.456\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [189/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [189/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 189 | Epoch Time: 0m 7s | Total Time so far: 23m 31s\n",
            "\tTrain Loss: 0.253 | Train Acc: 89.49% | Train F1: 0.897\n",
            "\t Val. Loss: 2.167 |  Val. Acc: 49.50% |  Val. F1: 0.445\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [190/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [190/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 190 | Epoch Time: 0m 7s | Total Time so far: 23m 39s\n",
            "\tTrain Loss: 0.247 | Train Acc: 89.75% | Train F1: 0.901\n",
            "\t Val. Loss: 2.275 |  Val. Acc: 47.44% |  Val. F1: 0.413\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [191/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [191/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 191 | Epoch Time: 0m 7s | Total Time so far: 23m 46s\n",
            "\tTrain Loss: 0.247 | Train Acc: 90.12% | Train F1: 0.904\n",
            "\t Val. Loss: 2.144 |  Val. Acc: 50.60% |  Val. F1: 0.461\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [192/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [192/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 192 | Epoch Time: 0m 7s | Total Time so far: 23m 54s\n",
            "\tTrain Loss: 0.246 | Train Acc: 89.69% | Train F1: 0.899\n",
            "\t Val. Loss: 2.205 |  Val. Acc: 48.83% |  Val. F1: 0.439\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [193/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [193/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 193 | Epoch Time: 0m 7s | Total Time so far: 24m 1s\n",
            "\tTrain Loss: 0.243 | Train Acc: 90.09% | Train F1: 0.904\n",
            "\t Val. Loss: 2.296 |  Val. Acc: 49.68% |  Val. F1: 0.451\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [194/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [194/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 194 | Epoch Time: 0m 7s | Total Time so far: 24m 8s\n",
            "\tTrain Loss: 0.254 | Train Acc: 89.59% | Train F1: 0.898\n",
            "\t Val. Loss: 2.234 |  Val. Acc: 48.58% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [195/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [195/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 195 | Epoch Time: 0m 7s | Total Time so far: 24m 16s\n",
            "\tTrain Loss: 0.240 | Train Acc: 90.40% | Train F1: 0.905\n",
            "\t Val. Loss: 2.326 |  Val. Acc: 48.90% |  Val. F1: 0.414\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [196/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [196/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 196 | Epoch Time: 0m 7s | Total Time so far: 24m 23s\n",
            "\tTrain Loss: 0.236 | Train Acc: 90.34% | Train F1: 0.905\n",
            "\t Val. Loss: 2.183 |  Val. Acc: 49.86% |  Val. F1: 0.441\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [197/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [197/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 197 | Epoch Time: 0m 7s | Total Time so far: 24m 31s\n",
            "\tTrain Loss: 0.232 | Train Acc: 90.42% | Train F1: 0.907\n",
            "\t Val. Loss: 2.282 |  Val. Acc: 48.51% |  Val. F1: 0.427\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [198/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [198/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 198 | Epoch Time: 0m 7s | Total Time so far: 24m 38s\n",
            "\tTrain Loss: 0.225 | Train Acc: 90.83% | Train F1: 0.911\n",
            "\t Val. Loss: 2.217 |  Val. Acc: 48.19% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [199/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [199/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 199 | Epoch Time: 0m 7s | Total Time so far: 24m 45s\n",
            "\tTrain Loss: 0.230 | Train Acc: 90.40% | Train F1: 0.907\n",
            "\t Val. Loss: 2.278 |  Val. Acc: 48.79% |  Val. F1: 0.458\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [200/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [200/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 200 | Epoch Time: 0m 7s | Total Time so far: 24m 53s\n",
            "\tTrain Loss: 0.225 | Train Acc: 90.74% | Train F1: 0.909\n",
            "\t Val. Loss: 2.252 |  Val. Acc: 49.33% |  Val. F1: 0.430\n",
            "---------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFVYQc9gO8WP",
        "outputId": "193255ee-f1c8-46eb-fb32-302c9c3d1ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Network': {'seed': 1},\n",
              " 'display_stats_freq': 200,\n",
              " 'network_save_freq': 1,\n",
              " 'postreply_data_path': './',\n",
              " 'final_data_post_reply_file_name': 'final_data_post_reply.csv',\n",
              " 'training_post_reply_file_name': 'obtained_train.csv',\n",
              " 'final_test_post_reply_file_name': 'test_w_text.csv',\n",
              " 'reply_data_format': 'csv',\n",
              " 'pretrained_embedding': 'glove.twitter.27B.200d',\n",
              " 'tokenizer': 'spacy',\n",
              " 'network_output_path': './models/',\n",
              " 'trained_model_name': 'LSTM_model_obt.pth'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import ParamSpecArgs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "class Prediction:\n",
        "    '''\n",
        "    This class represents prediction (testing) process similar to the Training class.\n",
        "    '''\n",
        "    def __init__(self, params, classes, model_mode='RNN', cfg_path_RNN=None, cfg_path_CNN=None): #cfg_path\n",
        "        self.params = params\n",
        "        #if cfg_path_CNN:\n",
        "            #self.params_RNN = read_config(cfg_path_RNN)\n",
        "            #self.params_CNN = read_config(cfg_path_CNN)\n",
        "        #self.cfg_path = cfg_path\n",
        "        self.setup_cuda()\n",
        "        self.model_mode = model_mode\n",
        "        self.classes = classes\n",
        "\n",
        "    def setup_cuda(self, cuda_device_id=0):\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cudnn.fastest = True\n",
        "            torch.cuda.set_device(cuda_device_id)\n",
        "            self.device = torch.device('cuda')\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "    def setup_model(self, model, vocab_size, embeddings, embedding_dim,\n",
        "                    hidden_dim, pad_idx, unk_idx, model_file_name=None, epoch=19,\n",
        "                    conv_out_ch=200, filter_sizes=[3,4,5], model_c =CNN1d, model_r=biLSTM):\n",
        "        if model_file_name == None:\n",
        "            model_file_name = self.params['trained_model_name']\n",
        "        if self.model_mode == \"RNN\":\n",
        "            self.model_p = model(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 hidden_dim=hidden_dim, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "        elif self.model_mode == \"CNN\":\n",
        "            self.model_p = model(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 conv_out_ch=conv_out_ch, filter_sizes=filter_sizes, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "        elif self.model_mode == \"ensemble\":\n",
        "            model_file_name_c = self.params_CNN['trained_model_name']\n",
        "            model_file_name_r = self.params_RNN['trained_model_name']\n",
        "            self.model_cnn = model_c(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 conv_out_ch=conv_out_ch, filter_sizes=filter_sizes, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "            self.model_rnn = model_r(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 hidden_dim=hidden_dim, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "\n",
        "        # Loads model from model_file_name and default network_output_path\n",
        "        if self.model_mode == \"ensemble\":\n",
        "            # self.model_cnn.load_state_dict(torch.load(self.params_CNN['network_output_path'] + \"/\" + model_file_name_c))\n",
        "            self.model_cnn.load_state_dict(\n",
        "                torch.load(self.params_CNN['network_output_path'] + model_file_name_c)) #\"/epoch\" + str(19) + \"_\" + model_file_name_c))\n",
        "            # self.model_rnn.load_state_dict(torch.load(self.params_RNN['network_output_path'] + \"/\" + model_file_name_r))\n",
        "            self.model_rnn.load_state_dict(\n",
        "                torch.load(self.params_RNN['network_output_path'] + model_file_name_r)) #\"/epoch\" + str(43) + \"_\" + model_file_name_r))\n",
        "        else:\n",
        "            # self.model_p.load_state_dict(torch.load(self.params['network_output_path'] + \"/\" + model_file_name))\n",
        "            self.model_p.load_state_dict(torch.load(self.params['network_output_path'] + model_file_name)) #+ \"/epoch\" + str(epoch) + \"_\" + model_file_name))\n",
        "\n",
        "\n",
        "    def predict(self, test_loader, batch_size):\n",
        "        # Reads params to check if any params have been changed by user\n",
        "        #self.params = read_config(self.cfg_path)\n",
        "        self.model_p.eval()\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            # initializing the caches\n",
        "            logits_cache = torch.from_numpy(np.zeros((len(test_loader) * batch_size, 3)))\n",
        "            max_preds_cache = torch.from_numpy(np.zeros((len(test_loader) * batch_size, 1)))\n",
        "            labels_cache = torch.from_numpy(np.zeros(len(test_loader) * batch_size))\n",
        "\n",
        "            for idx, batch in enumerate(test_loader):\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    message, message_lengths = batch.text\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    message = batch.text\n",
        "                label = batch.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    output = self.model_p(message, message_lengths).squeeze(1)\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    output = self.model_p(message).squeeze(1)\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        # average=None gives individual scores for each class\n",
        "        # here we only care about the average of positive class and negative class\n",
        "        final_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_f1_score = (final_f1_score[1] + final_f1_score[2]) / 2\n",
        "        final_precision = (final_precision[1] + final_precision[2]) / 2\n",
        "        final_recall = (final_recall[1] + final_recall[2]) / 2\n",
        "        confusion_matrix = metrics.confusion_matrix(labels_cache, max_preds_cache, labels=[0,1,2])\n",
        "\n",
        "        end_time = time.time()\n",
        "        test_mins, test_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "        #for p,l in zip(max_preds_cache,labels_cache):\n",
        "          #print(l.item())\n",
        "\n",
        "        # Print the final evaluation metrics\n",
        "        print('\\n----------------------------------------------------------------------')\n",
        "        print(f'Testing | Testing Time: {test_mins}m {test_secs}s')\n",
        "        print(f'\\tAcc: {final_accuracy * 100:.2f}% | F1 score: {final_f1_score:.3f} | '\n",
        "              f'Recall: {final_recall:.3f} | Precision: {final_precision:.3f}')\n",
        "        print('----------------------------------------------------------------------\\n')\n",
        "        print(confusion_matrix)\n",
        "        self.plot_confusion_matrix(confusion_matrix, target_names=self.classes,title='Confusion matrix, without normalization')\n",
        "\n",
        "        return final_accuracy, final_f1_score\n",
        "\n",
        "\n",
        "    def predict_ensemble(self, test_iterator_RNN, test_iterator_CNN, batch_size):\n",
        "        \"prediction with ensembling CNN and RNN outputs by normal averaging\"\n",
        "\n",
        "        # Reads params to check if any params have been changed by user\n",
        "        #self.params = read_config(self.cfg_path)\n",
        "        self.model_cnn.eval()\n",
        "        self.model_rnn.eval()\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            # initializing the caches\n",
        "            logits_cache = torch.from_numpy(np.zeros((len(test_iterator_RNN) * batch_size, 3)))\n",
        "            max_preds_cache = torch.from_numpy(np.zeros((len(test_iterator_RNN) * batch_size, 1)))\n",
        "            labels_cache = torch.from_numpy(np.zeros(len(test_iterator_RNN) * batch_size))\n",
        "\n",
        "            for idx, (batch_RNN, batch_CNN) in enumerate(zip(test_iterator_RNN, test_iterator_CNN)):\n",
        "\n",
        "                # RNN part\n",
        "                message, message_lengths = batch_RNN.text\n",
        "                label = batch_RNN.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                output_RNN = self.model_rnn(message, message_lengths).squeeze(1)\n",
        "\n",
        "                #CNN part\n",
        "                message = batch_CNN.text\n",
        "                label = batch_CNN.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                output_CNN = self.model_cnn(message).squeeze(1)\n",
        "\n",
        "                output = (output_CNN + output_RNN) / 2\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        # average=None gives individual scores for each class\n",
        "        # here we only care about the average of positive class and negative class\n",
        "        final_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_f1_score = (final_f1_score[1] + final_f1_score[2]) / 2\n",
        "        final_precision = (final_precision[1] + final_precision[2]) / 2\n",
        "        final_recall = (final_recall[1] + final_recall[2]) / 2\n",
        "        confusion_matrix = metrics.confusion_matrix(labels_cache, max_preds_cache, labels=[0,1,2])\n",
        "\n",
        "        end_time = time.time()\n",
        "        test_mins, test_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "        # Print the final evaluation metrics\n",
        "        print('\\n----------------------------------------------------------------------')\n",
        "        print(f'Testing | Testing Time: {test_mins}m {test_secs}s')\n",
        "        print(f'\\tAcc: {final_accuracy * 100:.2f}% | F1 score: {final_f1_score:.3f} | '\n",
        "              f'Recall: {final_recall:.3f} | Precision: {final_precision:.3f}')\n",
        "        print('----------------------------------------------------------------------\\n')\n",
        "        print(confusion_matrix)\n",
        "        # self.plot_confusion_matrix(confusion_matrix, target_names=self.classes,\n",
        "        #                       title='Confusion matrix, without normalization')\n",
        "        return final_accuracy, final_f1_score\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(self, cm, target_names,\n",
        "                              title='Confusion matrix', cmap=None, normalize=False):\n",
        "        \"\"\"\n",
        "        given a sklearn confusion matrix (cm), make a nice plot\n",
        "        ---------\n",
        "        cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "        target_names: given classification classes such as [0, 1, 2]\n",
        "                      the class names, for example: ['high', 'medium', 'low']\n",
        "        cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                      plt.get_cmap('jet') or plt.cm.Blues\n",
        "        normalize:    If False, plot the raw numbers\n",
        "                      If True, plot the proportions\n",
        "        \"\"\"\n",
        "        accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "        misclass = 1 - accuracy\n",
        "\n",
        "        if cmap is None:\n",
        "            cmap = plt.get_cmap('Blues')\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "\n",
        "        if target_names is not None:\n",
        "            tick_marks = np.arange(len(target_names))\n",
        "            plt.xticks(tick_marks, target_names, rotation=45)\n",
        "            plt.yticks(tick_marks, target_names)\n",
        "\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            if normalize:\n",
        "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "            else:\n",
        "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label\\naccuracy={:0.2f}%; misclass={:0.2f}%'.format(accuracy*100, misclass*100))\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def manual_predict(self, labels, vocab_idx, phrase, min_len=4,\n",
        "                       tokenizer=spacy.load(\"en_core_web_sm\"), mode=None, prediction_mode='Manualpart1'):\n",
        "        '''\n",
        "        Manually predicts the polarity of the given sentence.\n",
        "        Possible polarities: 1.neutral, 2.positive, 3.negative\n",
        "        '''\n",
        "        #self.params = read_config(self.cfg_path)\n",
        "        self.model_p.eval()\n",
        "\n",
        "        tokenized = [tok.text for tok in tokenizer.tokenizer(phrase)]\n",
        "        if len(tokenized) < min_len:\n",
        "            tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "        indexed = [vocab_idx[t] for t in tokenized]\n",
        "        tensor = torch.LongTensor(indexed).to(self.device)\n",
        "        tensor = tensor.unsqueeze(1)\n",
        "        preds = self.model_p(tensor, torch.Tensor([tensor.shape[0]]))\n",
        "        max_preds = preds.argmax(dim=1)\n",
        "        if mode == Mode.REPLYPREDICTION:\n",
        "            return labels[max_preds.item()]\n",
        "\n",
        "        print('\\n\\t', '\"' + phrase + '\"')\n",
        "        print('-----------------------------------------')\n",
        "        if prediction_mode == 'Manualpart1':\n",
        "            print(f'\\t This is a {labels[max_preds.item()]} phrase!')\n",
        "        elif prediction_mode == 'Manualpart2':\n",
        "            print(f'\\t This phrase is likely to get {labels[max_preds.item()]} replies!')\n",
        "        print('-----------------------------------------')\n"
      ],
      "metadata": {
        "id": "2QRrf3AvSEBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_test_postreply():\n",
        "    '''Main function for testing of the second part of the project\n",
        "    Sentiment analysis of the Post-Replies.\n",
        "    '''\n",
        "    EXPERIMENT_NAME = 'new_october_CNN'\n",
        "    BATCH_SIZE = 1281\n",
        "\n",
        "    #params = open_experiment(EXPERIMENT_NAME)\n",
        "    #cfg_path = params['cfg_path']\n",
        "    vocab_size = params['Network']['vocab_size']\n",
        "    PAD_IDX = params['Network']['PAD_IDX']\n",
        "    UNK_IDX = params['Network']['UNK_IDX']\n",
        "    classes = params['Network']['classes']\n",
        "    MAX_VOCAB_SIZE = params['Network']['MAX_VOCAB_SIZE']\n",
        "    SPLIT_RATIO = params['Network']['SPLIT_RATIO']\n",
        "    EMBEDDING_DIM = params['Network']['EMBEDDING_DIM']\n",
        "    HIDDEN_DIM = params['Network']['HIDDEN_DIM']\n",
        "    conv_out_ch = params['Network']['conv_out_ch']\n",
        "    MODEL_MODE = params['Network']['MODEL_MODE']\n",
        "    pretrained_embeddings = torch.zeros((vocab_size, EMBEDDING_DIM))\n",
        "\n",
        "    # Prepare data\n",
        "    data_handler_test = data_provider_PostReply(params=params, batch_size=BATCH_SIZE, split_ratio=SPLIT_RATIO,\n",
        "                                         max_vocab_size=MAX_VOCAB_SIZE, mode=Mode.TEST, model_mode=MODEL_MODE)\n",
        "    test_iterator = data_handler_test.data_loader()\n",
        "    # Initialize predictor\n",
        "    predictor = Prediction(params, model_mode=MODEL_MODE, classes=classes) #cfg_path\n",
        "\n",
        "    if MODEL_MODE == \"RNN\":\n",
        "        MODEL = biLSTM\n",
        "    elif MODEL_MODE == \"CNN\":\n",
        "        MODEL = CNN1d\n",
        "\n",
        "    predictor.setup_model(model=MODEL, vocab_size=vocab_size, embeddings=pretrained_embeddings,\n",
        "                          embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX,\n",
        "                          conv_out_ch=conv_out_ch, filter_sizes=[3, 4, 5])\n",
        "    predictor.predict(test_iterator, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "s2GhLgkuxJ9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params={'Network': {'seed': 1,\n",
        "  'total_param_num': 18486203,\n",
        "  'optimiser': 'Adam',\n",
        "  'loss_function': 'CrossEntropyLoss',\n",
        "  'optimiser_params': {'lr': 9e-05, 'weight_decay': 0.0001},\n",
        "  'vocab_size': 88429,\n",
        "  'PAD_IDX': 1,\n",
        "  'UNK_IDX': 0,\n",
        "  'classes': ['neutral', 'negative', 'positive'],\n",
        "  'SPLIT_RATIO': 0.9,\n",
        "  'MAX_VOCAB_SIZE': 100000,\n",
        "  'HIDDEN_DIM': 300,\n",
        "  'EMBEDDING_DIM': 200,\n",
        "  'conv_out_ch': 200,\n",
        "  'MODEL_MODE': 'RNN',\n",
        "  'num_epoch': 200},\n",
        " 'display_stats_freq': 200,\n",
        " 'network_save_freq': 1,\n",
        " 'postreply_data_path': './',\n",
        " 'final_data_post_reply_file_name': 'final_data_post_reply.csv',\n",
        " 'training_post_reply_file_name': 'obtained_train.csv',\n",
        " 'final_test_post_reply_file_name': 'test_w_text.csv',\n",
        " 'reply_data_format': 'csv',\n",
        " 'pretrained_embedding': 'glove.twitter.27B.200d',\n",
        " 'tokenizer': 'spacy',\n",
        " 'network_output_path': './models/',\n",
        " 'trained_model_name': 'LSTM_model_obt.pth',\n",
        " 'total_train_tweets': 24064,\n",
        " 'total_valid_tweets': 2816}"
      ],
      "metadata": {
        "id": "8fqE38-lqKKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_test_postreply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "SSg3llgUhBiN",
        "outputId": "e914866c-26d7-445e-e796-6c5c599f9315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Testing | Testing Time: 0m 0s\n",
            "\tAcc: 58.86% | F1 score: 0.683 | Recall: 0.754 | Precision: 0.629\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[[ 69 226  81]\n",
            " [ 56 387  53]\n",
            " [ 43  68 298]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcJD5D5UrPiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}