{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0 #JS Edit\n",
        "# !pip install torchtext==0.13.1 #JS Edit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MaMNQ0uvcwb",
        "outputId": "7c575513-779b-4057-ed96-036e61202c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.10.0 in /usr/local/lib/python3.8/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install torchtext"
      ],
      "metadata": {
        "id": "X75-MU-IxZ_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNOfdOLzjqVu"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "from sklearn import metrics\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchtext.legacy #JS edit\n",
        "# import torchtext #JS edit\n",
        "from torchtext.legacy import data #JS edit\n",
        "# from torchtext import data #JS edit\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torch.nn import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfkjxA4yI2Di",
        "outputId": "70912291-fa64-44cc-a399-0c58870bce75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[K     |████████████████████████████████| 575 kB 26.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from shap) (1.21.6)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from shap) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap) (1.5.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "jLDdk8DTIu5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXjE5WL3mSxM",
        "outputId": "9f2be50e-c835-426e-c2be-ab048a4deb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_utils='/content/drive/My Drive/NLP'\n",
        "sys.path.append(path_to_utils)"
      ],
      "metadata": {
        "id": "7SUrmHWemS4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(path_to_utils)\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0COq13xb9b-",
        "outputId": "7a164a4a-2443-4743-8d9f-c09bfb0404d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1qJ8h8Q6C6t_FWn4R8pQeH813twKX9HgP/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#params can act as config file here\n",
        "\n",
        "params={\"Network\": {\"seed\": 1},\n",
        "        \"display_stats_freq\": 200,\n",
        "        \"network_save_freq\": 1,\n",
        "        \"postreply_data_path\": \"./\",\n",
        "        #\"input_data_path\": \"./data/datasets/semeval_message_level/\",\n",
        "        #\"train_file_name\": \"training_data.txt\",\n",
        "        #\"test_file_name\": \"test_data.txt\",\n",
        "        #\"reply_file_name\": \"data_post_reply.csv\",\n",
        "        #\"reply_with_label_file_name\": \"data_post_reply_withlabel.csv\",\n",
        "        \"final_data_post_reply_file_name\": \"final_data_post_reply.csv\",\n",
        "        \"training_post_reply_file_name\": \"obtained_train_clean.csv\", #obtained_train.csv, provided_train.csv, obtained_train_clean.csv, provided_train_clean.csv\n",
        "        #\"philipp_data\": \"philipp_data.csv\",\n",
        "        #\"philipp_with_label_file_name\": \"philipp_withlabel.csv\",\n",
        "        #\"philipp_final_post_reply_file_name\": \"philipp_final.csv\",\n",
        "        \"final_test_post_reply_file_name\": \"test_w_text.csv\",\n",
        "        #\"data_format\": \"tsv\",\n",
        "        \"reply_data_format\": \"csv\",\n",
        "        \"pretrained_embedding\": \"glove.twitter.27B.200d\",\n",
        "        \"tokenizer\": \"spacy\",\n",
        "        \"network_output_path\": \"./models/\",\n",
        "        #\"output_data_path\": \"./data/output_data/\",\n",
        "        #\"tb_logs_path\": \"./data/tensor_board_logs/\",\n",
        "        #\"checkpoint_name\": \"checkpoint.tar\",\n",
        "        \"trained_model_name\": \"LSTM_model_obt_cl.pth\"\n",
        "        }"
      ],
      "metadata": {
        "id": "iS1gTkUnfxVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class Mode(Enum):\n",
        "    '''\n",
        "    Class Enumerating the 3 modes of operation of the network.\n",
        "    This is used while loading datasets\n",
        "    '''\n",
        "    TRAIN = 0\n",
        "    VALID = 1\n",
        "    TEST = 2\n",
        "    PREDICTION = 3\n",
        "    REPLYPREDICTION = 4"
      ],
      "metadata": {
        "id": "ngfurp0uhMhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class data_provider_PostReply():\n",
        "    '''\n",
        "    Packed padded sequences\n",
        "    Tokenizer: spacy\n",
        "    '''\n",
        "    def __init__(self, params, batch_size=1, split_ratio=0.8, max_vocab_size=25000, mode=Mode.TRAIN, model_mode='RNN', seed=1): #cfg_path\n",
        "        '''\n",
        "        Args:\n",
        "            cfg_path (string): #deprecated for first pass\n",
        "                Config file path of the experiment\n",
        "\n",
        "            params\n",
        "            max_vocab_size (int):\n",
        "                The number of unique words in our training set is usually over 100,000,\n",
        "                which means that our one-hot vectors will have over 100,000 dimensions! SLOW TRAINIG!\n",
        "                We only take the top max_vocab_size most common words.\n",
        "            split_ratio (float):\n",
        "                train-valid splitting\n",
        "            mode (enumeration Mode):\n",
        "                Nature of operation to be done with the data.\n",
        "                Possible inputs are Mode.PREDICTION, Mode.TRAIN, Mode.VALID, Mode.TEST\n",
        "                Default value: Mode.TRAIN\n",
        "        '''\n",
        "        #params = read_config(cfg_path)\n",
        "        #self.cfg_path = cfg_path\n",
        "        self.mode = mode\n",
        "        self.seed = seed\n",
        "        self.split_ratio = split_ratio\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.dataset_path = params['postreply_data_path']\n",
        "        self.train_file_name = params['training_post_reply_file_name']\n",
        "        self.test_file_name = params['final_test_post_reply_file_name']\n",
        "        self.data_format = params['reply_data_format']\n",
        "        self.pretrained_embedding = params['pretrained_embedding']\n",
        "        self.tokenizer = params['tokenizer']\n",
        "        self.batch_size = batch_size\n",
        "        self.model_mode = model_mode\n",
        "\n",
        "\n",
        "    def data_loader(self):\n",
        "        '''\n",
        "        :include_lengths: Packed padded sequences: will make our RNN only process the non-padded elements of our sequence,\n",
        "            and for any padded element the `output` will be a zero tensor.\n",
        "            Note: padding is done by adding <pad> (not zero!)\n",
        "        :tokenize: the \"tokenization\" (the act of splitting the string into discrete \"tokens\") should be done using the spaCy tokenizer.\n",
        "        '''\n",
        "        if self.model_mode == 'RNN':\n",
        "            #Packed padded sequences\n",
        "            TEXT = data.Field(tokenize=self.tokenizer, include_lengths=True)  # For saving the length of sentences\n",
        "        if self.model_mode == 'CNN':\n",
        "            TEXT = data.Field(tokenize=self.tokenizer, batch_first=True)  # batch dimension is the firs dimension here.\n",
        "        LABEL = data.LabelField()\n",
        "\n",
        "        fields = [('label', LABEL), ('id', None), ('text', TEXT)]\n",
        "\n",
        "        train_data, test_data = data.TabularDataset.splits(\n",
        "            path=self.dataset_path,\n",
        "            train=self.train_file_name,\n",
        "            test=self.test_file_name,\n",
        "            format=self.data_format,\n",
        "            fields=fields,\n",
        "            skip_header=True)\n",
        "\n",
        "        #print(train_data)\n",
        "\n",
        "        # validation data\n",
        "        if self.split_ratio == 1:\n",
        "            valid_data = None\n",
        "        else:\n",
        "            train_data, valid_data = train_data.split(random_state=random.seed(self.seed), split_ratio=self.split_ratio)\n",
        "\n",
        "        # create the vocabulary only on the training set!!!\n",
        "        # vectors: instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors.\n",
        "        # initialize words in your vocabulary but not in your pre-trained embeddings to Gaussian\n",
        "        TEXT.build_vocab(train_data, max_size=self.max_vocab_size,\n",
        "                         vectors=self.pretrained_embedding, unk_init=torch.Tensor.normal_)\n",
        "        # TEXT.build_vocab(train_data, max_size=self.max_vocab_size)\n",
        "\n",
        "        LABEL.build_vocab(train_data)\n",
        "\n",
        "        labels = LABEL.vocab.itos\n",
        "        vocab_idx = TEXT.vocab.stoi\n",
        "\n",
        "        vocab_size = len(TEXT.vocab)\n",
        "        pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "        # the indices of the padding token <pad> and <unk> in the vocabulary\n",
        "        PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "        UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "        # What do we do with words that appear in examples but we have cut from the vocabulary?\n",
        "        # We replace them with a special unknown or <unk> token.\n",
        "\n",
        "\n",
        "        # for packed padded sequences all of the tensors within a batch need to be sorted by their lengths\n",
        "        if self.split_ratio == 1:\n",
        "            valid_iterator = None\n",
        "            train_iterator, test_iterator = data.BucketIterator.splits((\n",
        "                train_data, test_data), batch_size=self.batch_size,\n",
        "                sort_within_batch=True, sort_key=lambda x: len(x.text))\n",
        "        else:\n",
        "            train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((\n",
        "                train_data, valid_data, test_data), batch_size=self.batch_size,\n",
        "                sort_within_batch=True, sort_key=lambda x: len(x.text))\n",
        "\n",
        "        # finding the weights of each label\n",
        "        data_for_weight = pd.read_csv(os.path.join(self.dataset_path, self.train_file_name))\n",
        "        pos_counter = 0\n",
        "        neg_counter = 0\n",
        "        neut_counter = 0\n",
        "        for i in range(len(data_for_weight['label'])):\n",
        "            if (data_for_weight['label'][i] == 'positive'):\n",
        "                pos_counter += 1\n",
        "            if (data_for_weight['label'][i] == 'negative'):\n",
        "                neg_counter += 1\n",
        "            if (data_for_weight['label'][i] == 'neutral'):\n",
        "                neut_counter += 1\n",
        "        overall = neut_counter + pos_counter + neg_counter\n",
        "        neut_weight = overall/neut_counter\n",
        "        neg_weight = overall/neg_counter\n",
        "        pos_weight = overall/pos_counter\n",
        "        if labels == ['neutral', 'negative', 'positive']:\n",
        "            weights = torch.Tensor([neut_weight, neg_weight, pos_weight])\n",
        "        elif labels == ['neutral', 'positive', 'negative']:\n",
        "            weights = torch.Tensor([neut_weight, pos_weight, neg_weight])\n",
        "        elif labels == ['negative', 'neutral', 'positive']:\n",
        "            weights = torch.Tensor([neg_weight, neut_weight, pos_weight])\n",
        "        elif labels == ['negative', 'positive', 'neutral']:\n",
        "            weights = torch.Tensor([neg_weight, pos_weight, neut_weight])\n",
        "        elif labels == ['positive', 'negative', 'neutral']:\n",
        "            weights = torch.Tensor([pos_weight, neg_weight, neut_weight])\n",
        "        elif labels == ['positive', 'neutral', 'negative']:\n",
        "            weights = torch.Tensor([pos_weight, neut_weight, neg_weight])\n",
        "\n",
        "        if self.mode == Mode.TEST:\n",
        "            return test_iterator\n",
        "        elif self.mode == Mode.PREDICTION:\n",
        "            return labels, vocab_idx, vocab_size, PAD_IDX, UNK_IDX, pretrained_embeddings, labels\n",
        "        else:\n",
        "            return train_iterator, valid_iterator, vocab_size, PAD_IDX, UNK_IDX, pretrained_embeddings, weights, labels"
      ],
      "metadata": {
        "id": "giF66QlEexod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "class Training:\n",
        "    '''\n",
        "    This class represents training process.\n",
        "    '''\n",
        "    def __init__(self, params, num_epochs=10, RESUME=False, model_mode='RNN', torch_seed=None): #cfg_path\n",
        "        '''\n",
        "        :cfg_path (string): path of the experiment config file\n",
        "        :torch_seed (int): Seed used for random generators in PyTorch functions\n",
        "        '''\n",
        "        self.params = params\n",
        "        #self.cfg_path = cfg_path\n",
        "        self.RESUME = RESUME\n",
        "        self.model_mode = model_mode\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "        if RESUME == False:\n",
        "            self.model_info = self.params['Network']\n",
        "            self.model_info['seed'] = torch_seed or self.model_info['seed']\n",
        "            self.epoch = 0\n",
        "            self.num_epochs = num_epochs\n",
        "            self.best_loss = float('inf')\n",
        "            if 'trained_time' in self.model_info:\n",
        "                self.raise_training_complete_exception()\n",
        "            self.setup_cuda()\n",
        "            #self.writer = SummaryWriter(log_dir=os.path.join(self.params['tb_logs_path']))\n",
        "\n",
        "\n",
        "    def setup_cuda(self, cuda_device_id=0):\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cudnn.fastest = True\n",
        "            torch.cuda.set_device(cuda_device_id)\n",
        "            self.device = torch.device('cuda')\n",
        "            torch.cuda.manual_seed_all(self.model_info['seed'])\n",
        "            torch.manual_seed(self.model_info['seed'])\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "\n",
        "    def setup_model(self, model, optimiser, optimiser_params, loss_function, weight):\n",
        "\n",
        "        total_param_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f'Total # of model\\'s trainable parameters: {total_param_num:,}')\n",
        "        print('----------------------------------------------------\\n')\n",
        "\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimiser = optimiser(self.model.parameters(), **optimiser_params)\n",
        "        # self.loss_function = loss_function()\n",
        "        self.loss_function = loss_function(weight=weight.to(self.device))\n",
        "\n",
        "        if 'retrain' in self.model_info and self.model_info['retrain']==True:\n",
        "            self.load_pretrained_model()\n",
        "\n",
        "        # Saves the model, optimiser,loss function name for writing to config file\n",
        "        self.model_info['total_param_num'] = total_param_num\n",
        "        self.model_info['optimiser'] = optimiser.__name__\n",
        "        self.model_info['loss_function'] = loss_function.__name__\n",
        "        self.model_info['optimiser_params'] = optimiser_params\n",
        "        self.params['Network']=self.model_info\n",
        "        #write_config(self.params, self.cfg_path,sort_keys=True)\n",
        "\n",
        "\n",
        "    def load_checkpoint(self, model, optimiser, optimiser_params, loss_function, weight):\n",
        "\n",
        "        checkpoint = torch.load(self.params['network_output_path'] + '/' + self.params['checkpoint_name'])\n",
        "        self.device = None\n",
        "        self.model_info = checkpoint['model_info']\n",
        "        self.setup_cuda()\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimiser = optimiser(self.model.parameters(), **optimiser_params)\n",
        "        self.loss_function = loss_function(weight=weight.to(self.device))\n",
        "\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimiser.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.epoch = checkpoint['epoch']\n",
        "        self.loss_function = checkpoint['loss']\n",
        "        self.best_loss = checkpoint['best_loss']\n",
        "        #self.writer = SummaryWriter(log_dir=os.path.join(self.params['tb_logs_path']), purge_step=self.epoch + 1)\n",
        "\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "    def execute_training(self, train_loader, valid_loader=None, batch_size=1):\n",
        "        '''\n",
        "        Executes training by running training and validation at each epoch\n",
        "        '''\n",
        "        self.params = params #read_config(self.cfg_path)\n",
        "\n",
        "        total_start_time = time.time()\n",
        "\n",
        "        if self.RESUME == False:\n",
        "            # Checks if already trained\n",
        "            if 'trained_time' in self.model_info:\n",
        "                self.raise_training_complete_exception\n",
        "\n",
        "            self.model_info = self.params['Network']\n",
        "            self.model_info['num_epoch'] = self.num_epochs or self.model_info['num_epoch']\n",
        "\n",
        "        print('Starting time:' + str(datetime.datetime.now()) +'\\n')\n",
        "\n",
        "        for epoch in range(self.num_epochs - self.epoch):\n",
        "            self.epoch += 1\n",
        "            start_time = time.time()\n",
        "\n",
        "            print('Training (intermediate metrics):')\n",
        "            train_loss, train_acc, train_F1, train_recall, train_precision = self.train_epoch(train_loader, batch_size)\n",
        "\n",
        "            if valid_loader:\n",
        "                print('\\nValidation (intermediate metrics):')\n",
        "                valid_loss, valid_acc, valid_F1, valid_recall, valid_precision = self.valid_epoch(valid_loader, batch_size)\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
        "            total_mins, total_secs = self.epoch_time(total_start_time, end_time)\n",
        "\n",
        "            # Writes to the tensorboard after number of steps specified.\n",
        "            #if valid_loader:\n",
        "            #    self.calculate_tb_stats(train_loss, train_F1, train_recall, train_precision, train_acc,\n",
        "            #                            valid_loss, valid_F1, valid_recall, valid_precision, valid_acc)\n",
        "            #else:\n",
        "            #    self.calculate_tb_stats(train_loss, train_F1, train_recall, train_precision, train_acc)\n",
        "\n",
        "            # Saving the model\n",
        "            if valid_loader:\n",
        "                if valid_loss < self.best_loss:\n",
        "                    self.best_loss = valid_loss\n",
        "                    torch.save(self.model.state_dict(), self.params['network_output_path'] + '/' + self.params['trained_model_name'])\n",
        "            else:\n",
        "                if train_loss < self.best_loss:\n",
        "                    self.best_loss = train_loss\n",
        "                    torch.save(self.model.state_dict(), self.params['network_output_path'] + '/' + self.params['trained_model_name'])\n",
        "\n",
        "            # saving the model based on epoch, checkpoint\n",
        "            #self.savings()\n",
        "\n",
        "            # Print accuracy, F1, and loss after each epoch\n",
        "            print('\\n---------------------------------------------------------------')\n",
        "            print(f'Epoch: {self.epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | '\n",
        "                  f'Total Time so far: {total_mins}m {total_secs}s')\n",
        "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train F1: {train_F1:.3f}')\n",
        "            if valid_loader:\n",
        "                print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}% |  Val. F1: {valid_F1:.3f}')\n",
        "            print('---------------------------------------------------------------\\n')\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, batch_size):\n",
        "        '''\n",
        "        Train using one single iteration of all messages (epoch) in dataset\n",
        "        '''\n",
        "        print(\"Epoch [{}/{}]\".format(self.epoch, self.model_info['num_epoch']))\n",
        "        self.model.train()\n",
        "        previous_idx = 0\n",
        "\n",
        "        # initializing the loss list\n",
        "        batch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # initializing the caches\n",
        "        logits_cache = torch.from_numpy(np.zeros((len(train_loader) * batch_size, 3)))\n",
        "        max_preds_cache = torch.from_numpy(np.zeros((len(train_loader) * batch_size, 1)))\n",
        "        labels_cache = torch.from_numpy(np.zeros(len(train_loader) * batch_size))\n",
        "\n",
        "        for idx, batch in enumerate(train_loader):\n",
        "            if self.model_mode == \"RNN\":\n",
        "                message, message_lengths = batch.text\n",
        "            if self.model_mode == \"CNN\":\n",
        "                message = batch.text\n",
        "            label = batch.label\n",
        "            message = message.long()\n",
        "            label = label.long()\n",
        "            message = message.to(self.device)\n",
        "            label = label.to(self.device)\n",
        "\n",
        "            self.optimiser.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    output = self.model(message, message_lengths).squeeze(1)\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    output = self.model(message).squeeze(1)\n",
        "\n",
        "                # Loss\n",
        "                loss = self.loss_function(output, label)\n",
        "                batch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimiser.step()\n",
        "\n",
        "                # Prints loss statistics after number of steps specified.\n",
        "                if (idx + 1)%self.params['display_stats_freq'] == 0:\n",
        "                    print('Epoch {:02} | Batch {:03}-{:03} | Train loss: {:.3f}'.\n",
        "                          format(self.epoch, previous_idx, idx, batch_loss / batch_count))\n",
        "                    previous_idx = idx + 1\n",
        "                    batch_loss = 0\n",
        "                    batch_count = 0\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        # average=None gives individual scores for each class\n",
        "        # here we only care about the average of positive class and negative class\n",
        "        epoch_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_f1_score = (epoch_f1_score[1] + epoch_f1_score[2]) / 2\n",
        "        epoch_precision = (epoch_precision[1] + epoch_precision[2]) / 2\n",
        "        epoch_recall = (epoch_recall[1] + epoch_recall[2]) / 2\n",
        "        labels_cache = labels_cache.long()\n",
        "        logits_cache = logits_cache.float()\n",
        "\n",
        "        # Loss\n",
        "        loss = self.loss_function(logits_cache.to(self.device), labels_cache.to(self.device))\n",
        "        epoch_loss = loss.item()\n",
        "\n",
        "        return epoch_loss, epoch_accuracy, epoch_f1_score, epoch_precision, epoch_recall\n",
        "\n",
        "\n",
        "    def valid_epoch(self, valid_loader, batch_size):\n",
        "        '''Test (validation) model after an epoch and calculate loss on valid dataset'''\n",
        "        print(\"Epoch [{}/{}]\".format(self.epoch, self.model_info['num_epoch']))\n",
        "        self.model.eval()\n",
        "        previous_idx = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # initializing the loss list\n",
        "            batch_loss = 0\n",
        "            batch_count = 0\n",
        "\n",
        "            # initializing the caches\n",
        "            logits_cache = torch.from_numpy(np.zeros((len(valid_loader) * batch_size, 3)))\n",
        "            max_preds_cache = torch.from_numpy(np.zeros((len(valid_loader) * batch_size, 1)))\n",
        "            labels_cache = torch.from_numpy(np.zeros(len(valid_loader) * batch_size))\n",
        "\n",
        "            for idx, batch in enumerate(valid_loader):\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    message, message_lengths = batch.text\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    message = batch.text\n",
        "                label = batch.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    output = self.model(message, message_lengths).squeeze(1)\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    output = self.model(message).squeeze(1)\n",
        "\n",
        "                # Loss\n",
        "                loss = self.loss_function(output, label)\n",
        "                batch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "                # Prints loss statistics after number of steps specified.\n",
        "                if (idx + 1)%self.params['display_stats_freq'] == 0:\n",
        "                    print('Epoch {:02} | Batch {:03}-{:03} | Val. loss: {:.3f}'.\n",
        "                          format(self.epoch, previous_idx, idx, batch_loss / batch_count))\n",
        "                    previous_idx = idx + 1\n",
        "                    batch_loss = 0\n",
        "                    batch_count = 0\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        epoch_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        epoch_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        epoch_f1_score = (epoch_f1_score[1] + epoch_f1_score[2]) / 2\n",
        "        epoch_precision = (epoch_precision[1] + epoch_precision[2]) / 2\n",
        "        epoch_recall = (epoch_recall[1] + epoch_recall[2]) / 2\n",
        "        labels_cache = labels_cache.long()\n",
        "        logits_cache = logits_cache.float()\n",
        "\n",
        "        # Loss\n",
        "        loss = self.loss_function(logits_cache.to(self.device), labels_cache.to(self.device))\n",
        "        epoch_loss = loss.item()\n",
        "\n",
        "        self.model.train()\n",
        "        return epoch_loss, epoch_accuracy, epoch_f1_score, epoch_precision, epoch_recall\n",
        "\n"
      ],
      "metadata": {
        "id": "nc3DXbxSlaAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "\n",
        "\n",
        "class biLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embeddings=None, embedding_dim=100, hidden_dim=256, output_dim=3, pad_idx=1, unk_idx=0):\n",
        "        '''\n",
        "        :pad_idx: the index of the padding token <pad> in the vocabulary\n",
        "        :num_layers: number of biLSTMs stacked on top of each other\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        # replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "        self.embedding.weight.data.copy_(embeddings)\n",
        "        # these are irrelevant for determining sentiment:\n",
        "        self.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "        self.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2,\n",
        "                           bidirectional=True, dropout=0.5)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        # Note: never use dropout on the input or output layers (text or fc in this case),\n",
        "        # you only ever want to use dropout on intermediate layers.\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        '''\n",
        "        In some frameworks you must feed the initial hidden state, $h_0$, into the RNN,\n",
        "        however in PyTorch, if no initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
        "        :nn.utils.rnn.pack_padded_sequence: This will cause our RNN to only process the non-padded elements of our sequence.\n",
        "        '''\n",
        "        # text : [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded : [sent len, batch size, emb dim]\n",
        "\n",
        "        # pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        # output (packed_output) is the concatenation of the hidden state from every time step\n",
        "        # hidden is simply the final hidden state.\n",
        "        # hidden : [num layers * num directions, batch size, hid dim]\n",
        "        # cell : [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "        # unpack sequence [not needed, only for demonstration]\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # output : [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "\n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        # hidden : [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(hidden)"
      ],
      "metadata": {
        "id": "1AOGsXO6mS8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1d(nn.Module):\n",
        "    def __init__(self, vocab_size, embeddings, embedding_dim=200,\n",
        "                 conv_out_ch=200, filter_sizes=[3,4,5], output_dim=3, pad_idx=1, unk_idx=0):\n",
        "        '''\n",
        "        :pad_idx: the index of the padding token <pad> in the vocabulary\n",
        "        :conv_out_ch: number of the different kernels.\n",
        "        :filter_sizes: a list of different kernel sizes we use here.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        # replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "        self.embedding.weight.data.copy_(embeddings)\n",
        "        # these are irrelevant for determining sentiment:\n",
        "        self.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "        self.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=conv_out_ch,\n",
        "                      kernel_size=fs) for fs in filter_sizes])\n",
        "\n",
        "        self.fc = nn.Linear(len(filter_sizes) * conv_out_ch, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text = [batch size, sent len]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent len, emb dim]\n",
        "\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        # embedded = [batch size, emb dim, sent len]\n",
        "\n",
        "        # pad if the length of the sentence is less than the kernel size\n",
        "        if embedded.shape[2] < 5:\n",
        "            dif = 5 - embedded.shape[2]\n",
        "            embedded = F.pad(embedded, (0, dif), \"constant\", 0)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        # pooled_n = [batch size, n_filters]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "udPhdZzR7e4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_train_postreply():\n",
        "    '''\n",
        "    Main function for training + validation of the second part of the project:\n",
        "    Sentiment analysis of the Post-Replies.\n",
        "    '''\n",
        "    # if we are resuming training on a model\n",
        "    RESUME = False\n",
        "\n",
        "    # Hyper-parameters\n",
        "    NUM_EPOCH = 200\n",
        "    LOSS_FUNCTION = CrossEntropyLoss\n",
        "    OPTIMIZER = optim.Adam\n",
        "    BATCH_SIZE = 256\n",
        "    MAX_VOCAB_SIZE = 100000 #750000 #max_vocab_size: takes the 100,000 most frequent words as the vocab\n",
        "    lr = 9e-5\n",
        "    optimiser_params = {'lr': lr, 'weight_decay': 1e-4}\n",
        "    EMBEDDING_DIM = 200\n",
        "    HIDDEN_DIM = 300\n",
        "    OUTPUT_DIM = 3\n",
        "    MODEL_MODE = \"RNN\" # \"RNN\" or \"CNN\"\n",
        "    conv_out_ch = 200  # for the CNN model:\n",
        "    filter_sizes = [3, 4, 5]  # for the CNN model:\n",
        "    SPLIT_RATIO = 0.9 # ratio of the train set, 1.0 means 100% training, 0% valid data\n",
        "    EXPERIMENT_NAME = \"new_october_CNN\"\n",
        "\n",
        "    #if RESUME == True:\n",
        "    #    params = open_experiment(EXPERIMENT_NAME)\n",
        "    #else:\n",
        "    #    params = create_experiment(EXPERIMENT_NAME)\n",
        "    #cfg_path = params[\"cfg_path\"]\n",
        "\n",
        "    # Prepare data\n",
        "    data_handler = data_provider_PostReply(params=params, batch_size=BATCH_SIZE, split_ratio=SPLIT_RATIO,\n",
        "                                           max_vocab_size=MAX_VOCAB_SIZE, mode=Mode.TRAIN, model_mode=MODEL_MODE)\n",
        "    train_iterator, valid_iterator, vocab_size, PAD_IDX, UNK_IDX, pretrained_embeddings, weights, classes = data_handler.data_loader()\n",
        "\n",
        "    if SPLIT_RATIO == 1:\n",
        "        total_valid_tweets = 0\n",
        "    else:\n",
        "        total_valid_tweets = BATCH_SIZE * len(valid_iterator)\n",
        "    total_train_tweets = BATCH_SIZE * len(train_iterator)\n",
        "    print(f'\\nSummary:\\n----------------------------------------------------')\n",
        "    print(f'Total # of Training tweets: {total_train_tweets:,}')\n",
        "    print(f'Total # of Valid. tweets:   {total_valid_tweets:,}')\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Training(params, num_epochs=NUM_EPOCH, RESUME=RESUME, model_mode=MODEL_MODE)\n",
        "\n",
        "    if MODEL_MODE == \"RNN\":\n",
        "        MODEL = biLSTM(vocab_size=vocab_size, embeddings=pretrained_embeddings, embedding_dim=EMBEDDING_DIM,\n",
        "                       hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX)\n",
        "    elif MODEL_MODE == \"CNN\":\n",
        "        MODEL = CNN1d(vocab_size=vocab_size, embeddings=pretrained_embeddings, embedding_dim=EMBEDDING_DIM,\n",
        "                       conv_out_ch=conv_out_ch, filter_sizes=filter_sizes, output_dim=OUTPUT_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX)\n",
        "\n",
        "    if RESUME == True:\n",
        "        trainer.load_checkpoint(model=MODEL, optimiser=OPTIMIZER,\n",
        "                        optimiser_params=optimiser_params, loss_function=LOSS_FUNCTION, weight=weights)\n",
        "    else:\n",
        "        trainer.setup_model(model=MODEL, optimiser=OPTIMIZER,\n",
        "                        optimiser_params=optimiser_params, loss_function=LOSS_FUNCTION, weight=weights)\n",
        "        # writes the params to config file\n",
        "        #params = read_config(cfg_path)\n",
        "        params['Network']['vocab_size'] = vocab_size\n",
        "        params['Network']['PAD_IDX'] = PAD_IDX\n",
        "        params['Network']['UNK_IDX'] = UNK_IDX\n",
        "        params['Network']['classes'] = classes\n",
        "        params['Network']['SPLIT_RATIO'] = SPLIT_RATIO\n",
        "        params['Network']['MAX_VOCAB_SIZE'] = MAX_VOCAB_SIZE\n",
        "        params['Network']['HIDDEN_DIM'] = HIDDEN_DIM\n",
        "        params['Network']['EMBEDDING_DIM'] = EMBEDDING_DIM\n",
        "        params['Network']['conv_out_ch'] = conv_out_ch\n",
        "        params['Network']['MODEL_MODE'] = MODEL_MODE\n",
        "        params['total_train_tweets'] = total_train_tweets\n",
        "        params['total_valid_tweets'] = total_valid_tweets\n",
        "        #write_config(params, cfg_path, sort_keys=True)\n",
        "\n",
        "    trainer.execute_training(train_loader=train_iterator, valid_loader=valid_iterator, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "E2HJpeoSmTB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.KernelExplainer(main_train_postreply,training_post_reply_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "S78gH3xHzWXb",
        "outputId": "24e9c849-df6c-4cc0-cedf-565a39830ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-53d77ed56a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKernelExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_train_postreply\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_post_reply_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'training_post_reply_file_name' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer.shap_values(X_test,nsamples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "qYuavkfTzGwi",
        "outputId": "1a55fd29-aae5-4574-8a05-d0fbfc0e3875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d23a5e67c654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'explainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_train_postreply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uXWcUzgp2rF",
        "outputId": "dc623ac2-5d93-4870-b960-5a3be463e7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "----------------------------------------------------\n",
            "Total # of Training tweets: 24,064\n",
            "Total # of Valid. tweets:   2,816\n",
            "Total # of model's trainable parameters: 18,486,203\n",
            "----------------------------------------------------\n",
            "\n",
            "Starting time:2022-12-05 11:05:08.933615\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [1/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [1/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 01 | Epoch Time: 0m 7s | Total Time so far: 0m 7s\n",
            "\tTrain Loss: 1.091 | Train Acc: 38.53% | Train F1: 0.355\n",
            "\t Val. Loss: 1.074 |  Val. Acc: 41.73% |  Val. F1: 0.469\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [2/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [2/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 02 | Epoch Time: 0m 8s | Total Time so far: 0m 18s\n",
            "\tTrain Loss: 1.041 | Train Acc: 39.58% | Train F1: 0.466\n",
            "\t Val. Loss: 1.001 |  Val. Acc: 44.53% |  Val. F1: 0.513\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [3/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [3/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 03 | Epoch Time: 0m 7s | Total Time so far: 0m 26s\n",
            "\tTrain Loss: 1.011 | Train Acc: 41.91% | Train F1: 0.498\n",
            "\t Val. Loss: 1.003 |  Val. Acc: 45.67% |  Val. F1: 0.521\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [4/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [4/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 04 | Epoch Time: 0m 7s | Total Time so far: 0m 33s\n",
            "\tTrain Loss: 1.004 | Train Acc: 42.88% | Train F1: 0.500\n",
            "\t Val. Loss: 1.005 |  Val. Acc: 44.64% |  Val. F1: 0.518\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [5/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [5/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 05 | Epoch Time: 0m 7s | Total Time so far: 0m 41s\n",
            "\tTrain Loss: 1.002 | Train Acc: 42.61% | Train F1: 0.502\n",
            "\t Val. Loss: 0.997 |  Val. Acc: 46.06% |  Val. F1: 0.526\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [6/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [6/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 06 | Epoch Time: 0m 7s | Total Time so far: 0m 48s\n",
            "\tTrain Loss: 0.998 | Train Acc: 43.21% | Train F1: 0.507\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 45.81% |  Val. F1: 0.522\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [7/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [7/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 07 | Epoch Time: 0m 7s | Total Time so far: 0m 56s\n",
            "\tTrain Loss: 1.000 | Train Acc: 43.29% | Train F1: 0.505\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 46.59% |  Val. F1: 0.522\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [8/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [8/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 08 | Epoch Time: 0m 7s | Total Time so far: 1m 3s\n",
            "\tTrain Loss: 0.994 | Train Acc: 44.27% | Train F1: 0.510\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 44.82% |  Val. F1: 0.522\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [9/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [9/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 09 | Epoch Time: 0m 7s | Total Time so far: 1m 11s\n",
            "\tTrain Loss: 0.994 | Train Acc: 43.80% | Train F1: 0.510\n",
            "\t Val. Loss: 1.005 |  Val. Acc: 47.09% |  Val. F1: 0.514\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [10/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [10/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 10 | Epoch Time: 0m 7s | Total Time so far: 1m 18s\n",
            "\tTrain Loss: 0.990 | Train Acc: 44.54% | Train F1: 0.510\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 45.77% |  Val. F1: 0.524\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [11/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [11/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 11 | Epoch Time: 0m 7s | Total Time so far: 1m 25s\n",
            "\tTrain Loss: 0.990 | Train Acc: 45.00% | Train F1: 0.511\n",
            "\t Val. Loss: 1.005 |  Val. Acc: 45.31% |  Val. F1: 0.522\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [12/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [12/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 12 | Epoch Time: 0m 7s | Total Time so far: 1m 33s\n",
            "\tTrain Loss: 0.986 | Train Acc: 44.91% | Train F1: 0.513\n",
            "\t Val. Loss: 1.001 |  Val. Acc: 45.45% |  Val. F1: 0.514\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [13/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [13/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 13 | Epoch Time: 0m 7s | Total Time so far: 1m 40s\n",
            "\tTrain Loss: 0.984 | Train Acc: 45.80% | Train F1: 0.512\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 47.02% |  Val. F1: 0.520\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [14/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [14/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 14 | Epoch Time: 0m 7s | Total Time so far: 1m 48s\n",
            "\tTrain Loss: 0.984 | Train Acc: 45.98% | Train F1: 0.510\n",
            "\t Val. Loss: 0.988 |  Val. Acc: 48.44% |  Val. F1: 0.525\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [15/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [15/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 15 | Epoch Time: 0m 7s | Total Time so far: 1m 55s\n",
            "\tTrain Loss: 0.980 | Train Acc: 46.19% | Train F1: 0.514\n",
            "\t Val. Loss: 0.997 |  Val. Acc: 47.98% |  Val. F1: 0.528\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [16/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [16/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 16 | Epoch Time: 0m 7s | Total Time so far: 2m 3s\n",
            "\tTrain Loss: 0.979 | Train Acc: 46.42% | Train F1: 0.510\n",
            "\t Val. Loss: 0.996 |  Val. Acc: 47.73% |  Val. F1: 0.524\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [17/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [17/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 17 | Epoch Time: 0m 7s | Total Time so far: 2m 10s\n",
            "\tTrain Loss: 0.976 | Train Acc: 46.78% | Train F1: 0.515\n",
            "\t Val. Loss: 0.992 |  Val. Acc: 48.54% |  Val. F1: 0.526\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [18/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [18/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 18 | Epoch Time: 0m 7s | Total Time so far: 2m 18s\n",
            "\tTrain Loss: 0.971 | Train Acc: 47.31% | Train F1: 0.518\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 48.58% |  Val. F1: 0.523\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [19/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [19/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 19 | Epoch Time: 0m 7s | Total Time so far: 2m 25s\n",
            "\tTrain Loss: 0.973 | Train Acc: 47.15% | Train F1: 0.518\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 48.83% |  Val. F1: 0.524\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [20/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [20/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 20 | Epoch Time: 0m 7s | Total Time so far: 2m 32s\n",
            "\tTrain Loss: 0.970 | Train Acc: 47.60% | Train F1: 0.521\n",
            "\t Val. Loss: 1.007 |  Val. Acc: 46.45% |  Val. F1: 0.521\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [21/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [21/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 21 | Epoch Time: 0m 7s | Total Time so far: 2m 40s\n",
            "\tTrain Loss: 0.969 | Train Acc: 47.89% | Train F1: 0.519\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 48.58% |  Val. F1: 0.518\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [22/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [22/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 22 | Epoch Time: 0m 7s | Total Time so far: 2m 47s\n",
            "\tTrain Loss: 0.967 | Train Acc: 48.52% | Train F1: 0.522\n",
            "\t Val. Loss: 1.010 |  Val. Acc: 46.06% |  Val. F1: 0.520\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [23/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [23/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 23 | Epoch Time: 0m 7s | Total Time so far: 2m 55s\n",
            "\tTrain Loss: 0.964 | Train Acc: 47.96% | Train F1: 0.521\n",
            "\t Val. Loss: 1.028 |  Val. Acc: 46.63% |  Val. F1: 0.503\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [24/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [24/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 24 | Epoch Time: 0m 7s | Total Time so far: 3m 2s\n",
            "\tTrain Loss: 0.962 | Train Acc: 48.96% | Train F1: 0.525\n",
            "\t Val. Loss: 0.999 |  Val. Acc: 48.69% |  Val. F1: 0.522\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [25/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [25/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 25 | Epoch Time: 0m 7s | Total Time so far: 3m 10s\n",
            "\tTrain Loss: 0.957 | Train Acc: 48.55% | Train F1: 0.528\n",
            "\t Val. Loss: 1.022 |  Val. Acc: 45.88% |  Val. F1: 0.518\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [26/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [26/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 26 | Epoch Time: 0m 7s | Total Time so far: 3m 17s\n",
            "\tTrain Loss: 0.958 | Train Acc: 49.09% | Train F1: 0.529\n",
            "\t Val. Loss: 1.021 |  Val. Acc: 46.27% |  Val. F1: 0.521\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [27/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [27/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 27 | Epoch Time: 0m 7s | Total Time so far: 3m 24s\n",
            "\tTrain Loss: 0.954 | Train Acc: 49.51% | Train F1: 0.531\n",
            "\t Val. Loss: 0.993 |  Val. Acc: 49.04% |  Val. F1: 0.525\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [28/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [28/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 28 | Epoch Time: 0m 7s | Total Time so far: 3m 32s\n",
            "\tTrain Loss: 0.952 | Train Acc: 49.21% | Train F1: 0.532\n",
            "\t Val. Loss: 1.015 |  Val. Acc: 46.95% |  Val. F1: 0.516\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [29/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [29/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 29 | Epoch Time: 0m 7s | Total Time so far: 3m 39s\n",
            "\tTrain Loss: 0.948 | Train Acc: 49.70% | Train F1: 0.534\n",
            "\t Val. Loss: 1.010 |  Val. Acc: 46.88% |  Val. F1: 0.521\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [30/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [30/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 30 | Epoch Time: 0m 7s | Total Time so far: 3m 46s\n",
            "\tTrain Loss: 0.947 | Train Acc: 49.67% | Train F1: 0.534\n",
            "\t Val. Loss: 1.017 |  Val. Acc: 49.75% |  Val. F1: 0.505\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [31/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [31/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 31 | Epoch Time: 0m 7s | Total Time so far: 3m 54s\n",
            "\tTrain Loss: 0.944 | Train Acc: 50.14% | Train F1: 0.534\n",
            "\t Val. Loss: 1.000 |  Val. Acc: 49.64% |  Val. F1: 0.521\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [32/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [32/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 32 | Epoch Time: 0m 7s | Total Time so far: 4m 1s\n",
            "\tTrain Loss: 0.941 | Train Acc: 50.74% | Train F1: 0.540\n",
            "\t Val. Loss: 1.013 |  Val. Acc: 49.25% |  Val. F1: 0.507\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [33/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [33/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 33 | Epoch Time: 0m 7s | Total Time so far: 4m 9s\n",
            "\tTrain Loss: 0.941 | Train Acc: 50.69% | Train F1: 0.537\n",
            "\t Val. Loss: 1.017 |  Val. Acc: 47.80% |  Val. F1: 0.510\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [34/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [34/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 34 | Epoch Time: 0m 7s | Total Time so far: 4m 16s\n",
            "\tTrain Loss: 0.938 | Train Acc: 50.91% | Train F1: 0.541\n",
            "\t Val. Loss: 1.033 |  Val. Acc: 48.22% |  Val. F1: 0.506\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [35/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [35/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 35 | Epoch Time: 0m 7s | Total Time so far: 4m 23s\n",
            "\tTrain Loss: 0.936 | Train Acc: 51.23% | Train F1: 0.544\n",
            "\t Val. Loss: 1.047 |  Val. Acc: 45.21% |  Val. F1: 0.508\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [36/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [36/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 36 | Epoch Time: 0m 7s | Total Time so far: 4m 31s\n",
            "\tTrain Loss: 0.929 | Train Acc: 51.72% | Train F1: 0.551\n",
            "\t Val. Loss: 1.010 |  Val. Acc: 48.54% |  Val. F1: 0.512\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [37/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [37/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 37 | Epoch Time: 0m 7s | Total Time so far: 4m 38s\n",
            "\tTrain Loss: 0.925 | Train Acc: 51.73% | Train F1: 0.552\n",
            "\t Val. Loss: 1.040 |  Val. Acc: 48.54% |  Val. F1: 0.497\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [38/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [38/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 38 | Epoch Time: 0m 7s | Total Time so far: 4m 46s\n",
            "\tTrain Loss: 0.923 | Train Acc: 51.98% | Train F1: 0.552\n",
            "\t Val. Loss: 1.053 |  Val. Acc: 49.47% |  Val. F1: 0.485\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [39/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [39/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 39 | Epoch Time: 0m 7s | Total Time so far: 4m 53s\n",
            "\tTrain Loss: 0.920 | Train Acc: 52.46% | Train F1: 0.552\n",
            "\t Val. Loss: 1.043 |  Val. Acc: 49.01% |  Val. F1: 0.504\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [40/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [40/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 40 | Epoch Time: 0m 7s | Total Time so far: 5m 0s\n",
            "\tTrain Loss: 0.921 | Train Acc: 52.61% | Train F1: 0.554\n",
            "\t Val. Loss: 1.029 |  Val. Acc: 47.66% |  Val. F1: 0.511\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [41/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [41/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 41 | Epoch Time: 0m 7s | Total Time so far: 5m 8s\n",
            "\tTrain Loss: 0.914 | Train Acc: 52.67% | Train F1: 0.555\n",
            "\t Val. Loss: 1.013 |  Val. Acc: 48.54% |  Val. F1: 0.516\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [42/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [42/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 42 | Epoch Time: 0m 7s | Total Time so far: 5m 15s\n",
            "\tTrain Loss: 0.913 | Train Acc: 52.84% | Train F1: 0.559\n",
            "\t Val. Loss: 1.079 |  Val. Acc: 46.06% |  Val. F1: 0.495\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [43/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [43/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 43 | Epoch Time: 0m 7s | Total Time so far: 5m 22s\n",
            "\tTrain Loss: 0.905 | Train Acc: 53.26% | Train F1: 0.562\n",
            "\t Val. Loss: 1.062 |  Val. Acc: 48.19% |  Val. F1: 0.503\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [44/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [44/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 44 | Epoch Time: 0m 7s | Total Time so far: 5m 30s\n",
            "\tTrain Loss: 0.902 | Train Acc: 53.52% | Train F1: 0.567\n",
            "\t Val. Loss: 1.046 |  Val. Acc: 48.72% |  Val. F1: 0.491\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [45/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [45/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 45 | Epoch Time: 0m 7s | Total Time so far: 5m 37s\n",
            "\tTrain Loss: 0.898 | Train Acc: 53.69% | Train F1: 0.566\n",
            "\t Val. Loss: 1.074 |  Val. Acc: 47.69% |  Val. F1: 0.499\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [46/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [46/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 46 | Epoch Time: 0m 7s | Total Time so far: 5m 45s\n",
            "\tTrain Loss: 0.898 | Train Acc: 53.49% | Train F1: 0.566\n",
            "\t Val. Loss: 1.044 |  Val. Acc: 48.72% |  Val. F1: 0.507\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [47/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [47/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 47 | Epoch Time: 0m 7s | Total Time so far: 5m 52s\n",
            "\tTrain Loss: 0.891 | Train Acc: 54.27% | Train F1: 0.572\n",
            "\t Val. Loss: 1.069 |  Val. Acc: 48.90% |  Val. F1: 0.506\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [48/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [48/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 48 | Epoch Time: 0m 7s | Total Time so far: 5m 59s\n",
            "\tTrain Loss: 0.886 | Train Acc: 54.55% | Train F1: 0.575\n",
            "\t Val. Loss: 1.063 |  Val. Acc: 47.73% |  Val. F1: 0.494\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [49/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [49/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 49 | Epoch Time: 0m 7s | Total Time so far: 6m 7s\n",
            "\tTrain Loss: 0.881 | Train Acc: 54.68% | Train F1: 0.576\n",
            "\t Val. Loss: 1.114 |  Val. Acc: 48.90% |  Val. F1: 0.472\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [50/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [50/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 50 | Epoch Time: 0m 7s | Total Time so far: 6m 14s\n",
            "\tTrain Loss: 0.880 | Train Acc: 55.02% | Train F1: 0.579\n",
            "\t Val. Loss: 1.079 |  Val. Acc: 48.97% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [51/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [51/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 51 | Epoch Time: 0m 7s | Total Time so far: 6m 22s\n",
            "\tTrain Loss: 0.877 | Train Acc: 55.19% | Train F1: 0.582\n",
            "\t Val. Loss: 1.033 |  Val. Acc: 50.50% |  Val. F1: 0.476\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [52/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [52/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 52 | Epoch Time: 0m 7s | Total Time so far: 6m 29s\n",
            "\tTrain Loss: 0.872 | Train Acc: 55.32% | Train F1: 0.585\n",
            "\t Val. Loss: 1.082 |  Val. Acc: 47.87% |  Val. F1: 0.485\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [53/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [53/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 53 | Epoch Time: 0m 7s | Total Time so far: 6m 37s\n",
            "\tTrain Loss: 0.866 | Train Acc: 55.85% | Train F1: 0.588\n",
            "\t Val. Loss: 1.085 |  Val. Acc: 48.26% |  Val. F1: 0.482\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [54/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [54/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 54 | Epoch Time: 0m 7s | Total Time so far: 6m 44s\n",
            "\tTrain Loss: 0.857 | Train Acc: 56.40% | Train F1: 0.593\n",
            "\t Val. Loss: 1.103 |  Val. Acc: 48.97% |  Val. F1: 0.482\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [55/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [55/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 55 | Epoch Time: 0m 7s | Total Time so far: 6m 51s\n",
            "\tTrain Loss: 0.851 | Train Acc: 56.88% | Train F1: 0.597\n",
            "\t Val. Loss: 1.095 |  Val. Acc: 47.37% |  Val. F1: 0.486\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [56/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [56/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 56 | Epoch Time: 0m 7s | Total Time so far: 6m 59s\n",
            "\tTrain Loss: 0.849 | Train Acc: 56.76% | Train F1: 0.596\n",
            "\t Val. Loss: 1.039 |  Val. Acc: 50.89% |  Val. F1: 0.492\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [57/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [57/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 57 | Epoch Time: 0m 7s | Total Time so far: 7m 6s\n",
            "\tTrain Loss: 0.845 | Train Acc: 56.47% | Train F1: 0.598\n",
            "\t Val. Loss: 1.184 |  Val. Acc: 46.31% |  Val. F1: 0.477\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [58/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [58/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 58 | Epoch Time: 0m 7s | Total Time so far: 7m 13s\n",
            "\tTrain Loss: 0.837 | Train Acc: 57.60% | Train F1: 0.607\n",
            "\t Val. Loss: 1.065 |  Val. Acc: 50.21% |  Val. F1: 0.487\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [59/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [59/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 59 | Epoch Time: 0m 7s | Total Time so far: 7m 21s\n",
            "\tTrain Loss: 0.834 | Train Acc: 57.95% | Train F1: 0.607\n",
            "\t Val. Loss: 1.075 |  Val. Acc: 48.51% |  Val. F1: 0.497\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [60/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [60/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 60 | Epoch Time: 0m 7s | Total Time so far: 7m 28s\n",
            "\tTrain Loss: 0.821 | Train Acc: 58.80% | Train F1: 0.616\n",
            "\t Val. Loss: 1.178 |  Val. Acc: 47.41% |  Val. F1: 0.469\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [61/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [61/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 61 | Epoch Time: 0m 7s | Total Time so far: 7m 36s\n",
            "\tTrain Loss: 0.818 | Train Acc: 58.88% | Train F1: 0.619\n",
            "\t Val. Loss: 1.146 |  Val. Acc: 47.87% |  Val. F1: 0.470\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [62/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [62/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 62 | Epoch Time: 0m 7s | Total Time so far: 7m 43s\n",
            "\tTrain Loss: 0.812 | Train Acc: 58.98% | Train F1: 0.621\n",
            "\t Val. Loss: 1.143 |  Val. Acc: 48.79% |  Val. F1: 0.483\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [63/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [63/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 63 | Epoch Time: 0m 7s | Total Time so far: 7m 50s\n",
            "\tTrain Loss: 0.805 | Train Acc: 59.18% | Train F1: 0.623\n",
            "\t Val. Loss: 1.167 |  Val. Acc: 47.80% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [64/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [64/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 64 | Epoch Time: 0m 7s | Total Time so far: 7m 58s\n",
            "\tTrain Loss: 0.810 | Train Acc: 59.37% | Train F1: 0.620\n",
            "\t Val. Loss: 1.090 |  Val. Acc: 48.69% |  Val. F1: 0.500\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [65/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [65/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 65 | Epoch Time: 0m 7s | Total Time so far: 8m 5s\n",
            "\tTrain Loss: 0.804 | Train Acc: 59.44% | Train F1: 0.626\n",
            "\t Val. Loss: 1.171 |  Val. Acc: 49.18% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [66/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [66/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 66 | Epoch Time: 0m 7s | Total Time so far: 8m 13s\n",
            "\tTrain Loss: 0.801 | Train Acc: 59.61% | Train F1: 0.627\n",
            "\t Val. Loss: 1.112 |  Val. Acc: 50.14% |  Val. F1: 0.479\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [67/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [67/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 67 | Epoch Time: 0m 7s | Total Time so far: 8m 20s\n",
            "\tTrain Loss: 0.785 | Train Acc: 60.48% | Train F1: 0.636\n",
            "\t Val. Loss: 1.077 |  Val. Acc: 50.78% |  Val. F1: 0.489\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [68/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [68/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 68 | Epoch Time: 0m 7s | Total Time so far: 8m 27s\n",
            "\tTrain Loss: 0.787 | Train Acc: 60.40% | Train F1: 0.633\n",
            "\t Val. Loss: 1.225 |  Val. Acc: 47.34% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [69/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [69/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 69 | Epoch Time: 0m 7s | Total Time so far: 8m 35s\n",
            "\tTrain Loss: 0.773 | Train Acc: 61.70% | Train F1: 0.645\n",
            "\t Val. Loss: 1.218 |  Val. Acc: 47.05% |  Val. F1: 0.432\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [70/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [70/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 70 | Epoch Time: 0m 7s | Total Time so far: 8m 42s\n",
            "\tTrain Loss: 0.783 | Train Acc: 60.62% | Train F1: 0.637\n",
            "\t Val. Loss: 1.158 |  Val. Acc: 50.36% |  Val. F1: 0.453\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [71/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [71/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 71 | Epoch Time: 0m 7s | Total Time so far: 8m 49s\n",
            "\tTrain Loss: 0.765 | Train Acc: 61.95% | Train F1: 0.650\n",
            "\t Val. Loss: 1.128 |  Val. Acc: 49.47% |  Val. F1: 0.499\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [72/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [72/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 72 | Epoch Time: 0m 7s | Total Time so far: 8m 57s\n",
            "\tTrain Loss: 0.758 | Train Acc: 62.10% | Train F1: 0.651\n",
            "\t Val. Loss: 1.157 |  Val. Acc: 49.57% |  Val. F1: 0.476\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [73/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [73/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 73 | Epoch Time: 0m 7s | Total Time so far: 9m 4s\n",
            "\tTrain Loss: 0.760 | Train Acc: 62.19% | Train F1: 0.651\n",
            "\t Val. Loss: 1.237 |  Val. Acc: 46.91% |  Val. F1: 0.485\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [74/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [74/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 74 | Epoch Time: 0m 7s | Total Time so far: 9m 12s\n",
            "\tTrain Loss: 0.759 | Train Acc: 62.10% | Train F1: 0.650\n",
            "\t Val. Loss: 1.196 |  Val. Acc: 48.44% |  Val. F1: 0.475\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [75/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [75/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 75 | Epoch Time: 0m 7s | Total Time so far: 9m 19s\n",
            "\tTrain Loss: 0.746 | Train Acc: 62.93% | Train F1: 0.658\n",
            "\t Val. Loss: 1.249 |  Val. Acc: 47.98% |  Val. F1: 0.465\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [76/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [76/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 76 | Epoch Time: 0m 7s | Total Time so far: 9m 26s\n",
            "\tTrain Loss: 0.745 | Train Acc: 63.16% | Train F1: 0.661\n",
            "\t Val. Loss: 1.172 |  Val. Acc: 49.18% |  Val. F1: 0.462\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [77/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [77/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 77 | Epoch Time: 0m 7s | Total Time so far: 9m 34s\n",
            "\tTrain Loss: 0.747 | Train Acc: 62.93% | Train F1: 0.657\n",
            "\t Val. Loss: 1.223 |  Val. Acc: 49.40% |  Val. F1: 0.486\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [78/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [78/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 78 | Epoch Time: 0m 7s | Total Time so far: 9m 41s\n",
            "\tTrain Loss: 0.739 | Train Acc: 63.40% | Train F1: 0.661\n",
            "\t Val. Loss: 1.249 |  Val. Acc: 46.45% |  Val. F1: 0.462\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [79/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [79/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 79 | Epoch Time: 0m 7s | Total Time so far: 9m 48s\n",
            "\tTrain Loss: 0.725 | Train Acc: 63.95% | Train F1: 0.670\n",
            "\t Val. Loss: 1.170 |  Val. Acc: 49.96% |  Val. F1: 0.484\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [80/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [80/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 80 | Epoch Time: 0m 7s | Total Time so far: 9m 56s\n",
            "\tTrain Loss: 0.722 | Train Acc: 64.52% | Train F1: 0.673\n",
            "\t Val. Loss: 1.180 |  Val. Acc: 49.25% |  Val. F1: 0.489\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [81/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [81/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 81 | Epoch Time: 0m 7s | Total Time so far: 10m 3s\n",
            "\tTrain Loss: 0.715 | Train Acc: 64.77% | Train F1: 0.674\n",
            "\t Val. Loss: 1.176 |  Val. Acc: 49.79% |  Val. F1: 0.482\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [82/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [82/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 82 | Epoch Time: 0m 7s | Total Time so far: 10m 11s\n",
            "\tTrain Loss: 0.714 | Train Acc: 64.83% | Train F1: 0.677\n",
            "\t Val. Loss: 1.287 |  Val. Acc: 48.65% |  Val. F1: 0.460\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [83/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [83/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 83 | Epoch Time: 0m 7s | Total Time so far: 10m 18s\n",
            "\tTrain Loss: 0.707 | Train Acc: 65.23% | Train F1: 0.678\n",
            "\t Val. Loss: 1.228 |  Val. Acc: 48.90% |  Val. F1: 0.486\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [84/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [84/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 84 | Epoch Time: 0m 7s | Total Time so far: 10m 26s\n",
            "\tTrain Loss: 0.710 | Train Acc: 65.06% | Train F1: 0.679\n",
            "\t Val. Loss: 1.175 |  Val. Acc: 48.30% |  Val. F1: 0.494\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [85/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [85/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 85 | Epoch Time: 0m 7s | Total Time so far: 10m 33s\n",
            "\tTrain Loss: 0.700 | Train Acc: 65.53% | Train F1: 0.684\n",
            "\t Val. Loss: 1.385 |  Val. Acc: 48.08% |  Val. F1: 0.440\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [86/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [86/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 86 | Epoch Time: 0m 7s | Total Time so far: 10m 40s\n",
            "\tTrain Loss: 0.695 | Train Acc: 65.89% | Train F1: 0.685\n",
            "\t Val. Loss: 1.319 |  Val. Acc: 47.62% |  Val. F1: 0.471\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [87/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [87/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 87 | Epoch Time: 0m 7s | Total Time so far: 10m 48s\n",
            "\tTrain Loss: 0.690 | Train Acc: 66.22% | Train F1: 0.689\n",
            "\t Val. Loss: 1.307 |  Val. Acc: 48.08% |  Val. F1: 0.468\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [88/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [88/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 88 | Epoch Time: 0m 7s | Total Time so far: 10m 55s\n",
            "\tTrain Loss: 0.678 | Train Acc: 66.76% | Train F1: 0.695\n",
            "\t Val. Loss: 1.196 |  Val. Acc: 49.33% |  Val. F1: 0.487\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [89/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [89/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 89 | Epoch Time: 0m 7s | Total Time so far: 11m 3s\n",
            "\tTrain Loss: 0.682 | Train Acc: 66.61% | Train F1: 0.693\n",
            "\t Val. Loss: 1.240 |  Val. Acc: 49.22% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [90/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [90/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 90 | Epoch Time: 0m 7s | Total Time so far: 11m 10s\n",
            "\tTrain Loss: 0.685 | Train Acc: 65.97% | Train F1: 0.687\n",
            "\t Val. Loss: 1.289 |  Val. Acc: 49.40% |  Val. F1: 0.469\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [91/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [91/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 91 | Epoch Time: 0m 7s | Total Time so far: 11m 17s\n",
            "\tTrain Loss: 0.665 | Train Acc: 67.64% | Train F1: 0.703\n",
            "\t Val. Loss: 1.335 |  Val. Acc: 48.72% |  Val. F1: 0.467\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [92/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [92/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 92 | Epoch Time: 0m 7s | Total Time so far: 11m 25s\n",
            "\tTrain Loss: 0.664 | Train Acc: 67.71% | Train F1: 0.703\n",
            "\t Val. Loss: 1.287 |  Val. Acc: 49.22% |  Val. F1: 0.479\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [93/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [93/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 93 | Epoch Time: 0m 7s | Total Time so far: 11m 32s\n",
            "\tTrain Loss: 0.657 | Train Acc: 67.96% | Train F1: 0.707\n",
            "\t Val. Loss: 1.256 |  Val. Acc: 49.47% |  Val. F1: 0.472\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [94/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [94/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 94 | Epoch Time: 0m 7s | Total Time so far: 11m 40s\n",
            "\tTrain Loss: 0.655 | Train Acc: 67.95% | Train F1: 0.707\n",
            "\t Val. Loss: 1.271 |  Val. Acc: 48.22% |  Val. F1: 0.465\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [95/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [95/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 95 | Epoch Time: 0m 7s | Total Time so far: 11m 47s\n",
            "\tTrain Loss: 0.648 | Train Acc: 68.49% | Train F1: 0.712\n",
            "\t Val. Loss: 1.336 |  Val. Acc: 49.75% |  Val. F1: 0.446\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [96/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [96/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 96 | Epoch Time: 0m 7s | Total Time so far: 11m 54s\n",
            "\tTrain Loss: 0.640 | Train Acc: 68.66% | Train F1: 0.710\n",
            "\t Val. Loss: 1.199 |  Val. Acc: 50.67% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [97/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [97/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 97 | Epoch Time: 0m 7s | Total Time so far: 12m 2s\n",
            "\tTrain Loss: 0.639 | Train Acc: 69.14% | Train F1: 0.717\n",
            "\t Val. Loss: 1.254 |  Val. Acc: 47.41% |  Val. F1: 0.500\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [98/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [98/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 98 | Epoch Time: 0m 7s | Total Time so far: 12m 9s\n",
            "\tTrain Loss: 0.630 | Train Acc: 69.05% | Train F1: 0.719\n",
            "\t Val. Loss: 1.265 |  Val. Acc: 50.32% |  Val. F1: 0.478\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [99/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [99/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 99 | Epoch Time: 0m 7s | Total Time so far: 12m 16s\n",
            "\tTrain Loss: 0.636 | Train Acc: 69.42% | Train F1: 0.717\n",
            "\t Val. Loss: 1.310 |  Val. Acc: 48.69% |  Val. F1: 0.473\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [100/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [100/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 100 | Epoch Time: 0m 7s | Total Time so far: 12m 24s\n",
            "\tTrain Loss: 0.632 | Train Acc: 69.53% | Train F1: 0.720\n",
            "\t Val. Loss: 1.253 |  Val. Acc: 49.54% |  Val. F1: 0.481\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [101/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [101/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 101 | Epoch Time: 0m 7s | Total Time so far: 12m 31s\n",
            "\tTrain Loss: 0.625 | Train Acc: 70.17% | Train F1: 0.725\n",
            "\t Val. Loss: 1.304 |  Val. Acc: 50.39% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [102/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [102/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 102 | Epoch Time: 0m 7s | Total Time so far: 12m 39s\n",
            "\tTrain Loss: 0.614 | Train Acc: 70.27% | Train F1: 0.726\n",
            "\t Val. Loss: 1.286 |  Val. Acc: 49.15% |  Val. F1: 0.476\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [103/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [103/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 103 | Epoch Time: 0m 7s | Total Time so far: 12m 46s\n",
            "\tTrain Loss: 0.616 | Train Acc: 70.41% | Train F1: 0.728\n",
            "\t Val. Loss: 1.292 |  Val. Acc: 50.21% |  Val. F1: 0.466\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [104/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [104/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 104 | Epoch Time: 0m 7s | Total Time so far: 12m 53s\n",
            "\tTrain Loss: 0.601 | Train Acc: 71.49% | Train F1: 0.738\n",
            "\t Val. Loss: 1.437 |  Val. Acc: 48.97% |  Val. F1: 0.446\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [105/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [105/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 105 | Epoch Time: 0m 7s | Total Time so far: 13m 1s\n",
            "\tTrain Loss: 0.600 | Train Acc: 71.21% | Train F1: 0.735\n",
            "\t Val. Loss: 1.298 |  Val. Acc: 50.21% |  Val. F1: 0.479\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [106/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [106/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 106 | Epoch Time: 0m 7s | Total Time so far: 13m 8s\n",
            "\tTrain Loss: 0.592 | Train Acc: 71.52% | Train F1: 0.739\n",
            "\t Val. Loss: 1.405 |  Val. Acc: 48.72% |  Val. F1: 0.471\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [107/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [107/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 107 | Epoch Time: 0m 7s | Total Time so far: 13m 15s\n",
            "\tTrain Loss: 0.590 | Train Acc: 71.90% | Train F1: 0.740\n",
            "\t Val. Loss: 1.302 |  Val. Acc: 50.04% |  Val. F1: 0.476\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [108/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [108/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 108 | Epoch Time: 0m 7s | Total Time so far: 13m 23s\n",
            "\tTrain Loss: 0.585 | Train Acc: 72.08% | Train F1: 0.742\n",
            "\t Val. Loss: 1.342 |  Val. Acc: 49.82% |  Val. F1: 0.487\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [109/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [109/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 109 | Epoch Time: 0m 7s | Total Time so far: 13m 30s\n",
            "\tTrain Loss: 0.576 | Train Acc: 72.98% | Train F1: 0.753\n",
            "\t Val. Loss: 1.507 |  Val. Acc: 48.79% |  Val. F1: 0.457\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [110/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [110/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 110 | Epoch Time: 0m 7s | Total Time so far: 13m 38s\n",
            "\tTrain Loss: 0.576 | Train Acc: 72.74% | Train F1: 0.750\n",
            "\t Val. Loss: 1.355 |  Val. Acc: 50.32% |  Val. F1: 0.426\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [111/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [111/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 111 | Epoch Time: 0m 7s | Total Time so far: 13m 45s\n",
            "\tTrain Loss: 0.577 | Train Acc: 72.64% | Train F1: 0.747\n",
            "\t Val. Loss: 1.469 |  Val. Acc: 47.69% |  Val. F1: 0.474\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [112/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [112/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 112 | Epoch Time: 0m 7s | Total Time so far: 13m 52s\n",
            "\tTrain Loss: 0.571 | Train Acc: 72.83% | Train F1: 0.749\n",
            "\t Val. Loss: 1.267 |  Val. Acc: 50.78% |  Val. F1: 0.463\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [113/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [113/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 113 | Epoch Time: 0m 7s | Total Time so far: 14m 0s\n",
            "\tTrain Loss: 0.563 | Train Acc: 73.58% | Train F1: 0.756\n",
            "\t Val. Loss: 1.447 |  Val. Acc: 48.19% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [114/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [114/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 114 | Epoch Time: 0m 7s | Total Time so far: 14m 7s\n",
            "\tTrain Loss: 0.559 | Train Acc: 73.84% | Train F1: 0.757\n",
            "\t Val. Loss: 1.375 |  Val. Acc: 49.96% |  Val. F1: 0.470\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [115/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [115/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 115 | Epoch Time: 0m 7s | Total Time so far: 14m 14s\n",
            "\tTrain Loss: 0.556 | Train Acc: 73.67% | Train F1: 0.757\n",
            "\t Val. Loss: 1.429 |  Val. Acc: 49.01% |  Val. F1: 0.458\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [116/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [116/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 116 | Epoch Time: 0m 7s | Total Time so far: 14m 22s\n",
            "\tTrain Loss: 0.545 | Train Acc: 74.15% | Train F1: 0.760\n",
            "\t Val. Loss: 1.395 |  Val. Acc: 49.43% |  Val. F1: 0.466\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [117/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [117/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 117 | Epoch Time: 0m 7s | Total Time so far: 14m 29s\n",
            "\tTrain Loss: 0.543 | Train Acc: 74.70% | Train F1: 0.768\n",
            "\t Val. Loss: 1.579 |  Val. Acc: 48.08% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [118/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [118/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 118 | Epoch Time: 0m 7s | Total Time so far: 14m 37s\n",
            "\tTrain Loss: 0.544 | Train Acc: 74.41% | Train F1: 0.764\n",
            "\t Val. Loss: 1.607 |  Val. Acc: 48.83% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [119/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [119/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 119 | Epoch Time: 0m 7s | Total Time so far: 14m 44s\n",
            "\tTrain Loss: 0.540 | Train Acc: 74.75% | Train F1: 0.765\n",
            "\t Val. Loss: 1.608 |  Val. Acc: 48.58% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [120/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [120/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 120 | Epoch Time: 0m 7s | Total Time so far: 14m 52s\n",
            "\tTrain Loss: 0.534 | Train Acc: 74.88% | Train F1: 0.768\n",
            "\t Val. Loss: 1.463 |  Val. Acc: 49.79% |  Val. F1: 0.477\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [121/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [121/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 121 | Epoch Time: 0m 7s | Total Time so far: 14m 59s\n",
            "\tTrain Loss: 0.525 | Train Acc: 75.39% | Train F1: 0.773\n",
            "\t Val. Loss: 1.474 |  Val. Acc: 49.89% |  Val. F1: 0.464\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [122/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [122/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 122 | Epoch Time: 0m 7s | Total Time so far: 15m 6s\n",
            "\tTrain Loss: 0.520 | Train Acc: 75.86% | Train F1: 0.776\n",
            "\t Val. Loss: 1.488 |  Val. Acc: 48.76% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [123/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [123/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 123 | Epoch Time: 0m 7s | Total Time so far: 15m 14s\n",
            "\tTrain Loss: 0.520 | Train Acc: 75.74% | Train F1: 0.775\n",
            "\t Val. Loss: 1.490 |  Val. Acc: 50.82% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [124/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [124/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 124 | Epoch Time: 0m 7s | Total Time so far: 15m 21s\n",
            "\tTrain Loss: 0.505 | Train Acc: 76.46% | Train F1: 0.783\n",
            "\t Val. Loss: 1.473 |  Val. Acc: 49.29% |  Val. F1: 0.458\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [125/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [125/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 125 | Epoch Time: 0m 7s | Total Time so far: 15m 28s\n",
            "\tTrain Loss: 0.510 | Train Acc: 76.14% | Train F1: 0.779\n",
            "\t Val. Loss: 1.450 |  Val. Acc: 49.68% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [126/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [126/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 126 | Epoch Time: 0m 7s | Total Time so far: 15m 36s\n",
            "\tTrain Loss: 0.514 | Train Acc: 76.20% | Train F1: 0.779\n",
            "\t Val. Loss: 1.603 |  Val. Acc: 48.12% |  Val. F1: 0.422\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [127/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [127/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 127 | Epoch Time: 0m 7s | Total Time so far: 15m 43s\n",
            "\tTrain Loss: 0.499 | Train Acc: 76.87% | Train F1: 0.786\n",
            "\t Val. Loss: 1.548 |  Val. Acc: 50.11% |  Val. F1: 0.427\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [128/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [128/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 128 | Epoch Time: 0m 7s | Total Time so far: 15m 51s\n",
            "\tTrain Loss: 0.493 | Train Acc: 77.32% | Train F1: 0.791\n",
            "\t Val. Loss: 1.582 |  Val. Acc: 48.69% |  Val. F1: 0.442\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [129/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [129/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 129 | Epoch Time: 0m 7s | Total Time so far: 15m 58s\n",
            "\tTrain Loss: 0.488 | Train Acc: 77.64% | Train F1: 0.793\n",
            "\t Val. Loss: 1.610 |  Val. Acc: 49.18% |  Val. F1: 0.462\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [130/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [130/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 130 | Epoch Time: 0m 7s | Total Time so far: 16m 5s\n",
            "\tTrain Loss: 0.489 | Train Acc: 77.53% | Train F1: 0.791\n",
            "\t Val. Loss: 1.624 |  Val. Acc: 48.44% |  Val. F1: 0.430\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [131/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [131/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 131 | Epoch Time: 0m 7s | Total Time so far: 16m 13s\n",
            "\tTrain Loss: 0.482 | Train Acc: 77.61% | Train F1: 0.792\n",
            "\t Val. Loss: 1.627 |  Val. Acc: 49.04% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [132/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [132/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 132 | Epoch Time: 0m 7s | Total Time so far: 16m 20s\n",
            "\tTrain Loss: 0.478 | Train Acc: 78.18% | Train F1: 0.797\n",
            "\t Val. Loss: 1.537 |  Val. Acc: 50.92% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [133/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [133/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 133 | Epoch Time: 0m 7s | Total Time so far: 16m 28s\n",
            "\tTrain Loss: 0.474 | Train Acc: 78.36% | Train F1: 0.799\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 49.22% |  Val. F1: 0.452\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [134/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [134/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 134 | Epoch Time: 0m 7s | Total Time so far: 16m 35s\n",
            "\tTrain Loss: 0.468 | Train Acc: 78.59% | Train F1: 0.800\n",
            "\t Val. Loss: 1.592 |  Val. Acc: 49.47% |  Val. F1: 0.442\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [135/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [135/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 135 | Epoch Time: 0m 7s | Total Time so far: 16m 42s\n",
            "\tTrain Loss: 0.460 | Train Acc: 79.01% | Train F1: 0.805\n",
            "\t Val. Loss: 1.668 |  Val. Acc: 49.15% |  Val. F1: 0.429\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [136/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [136/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 136 | Epoch Time: 0m 7s | Total Time so far: 16m 50s\n",
            "\tTrain Loss: 0.472 | Train Acc: 78.70% | Train F1: 0.800\n",
            "\t Val. Loss: 1.609 |  Val. Acc: 48.79% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [137/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [137/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 137 | Epoch Time: 0m 7s | Total Time so far: 16m 57s\n",
            "\tTrain Loss: 0.463 | Train Acc: 79.03% | Train F1: 0.803\n",
            "\t Val. Loss: 1.613 |  Val. Acc: 48.30% |  Val. F1: 0.460\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [138/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [138/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 138 | Epoch Time: 0m 7s | Total Time so far: 17m 4s\n",
            "\tTrain Loss: 0.441 | Train Acc: 80.34% | Train F1: 0.817\n",
            "\t Val. Loss: 1.671 |  Val. Acc: 48.51% |  Val. F1: 0.435\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [139/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [139/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 139 | Epoch Time: 0m 7s | Total Time so far: 17m 12s\n",
            "\tTrain Loss: 0.448 | Train Acc: 79.51% | Train F1: 0.808\n",
            "\t Val. Loss: 1.603 |  Val. Acc: 49.01% |  Val. F1: 0.463\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [140/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [140/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 140 | Epoch Time: 0m 7s | Total Time so far: 17m 19s\n",
            "\tTrain Loss: 0.436 | Train Acc: 80.06% | Train F1: 0.815\n",
            "\t Val. Loss: 1.627 |  Val. Acc: 50.07% |  Val. F1: 0.452\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [141/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [141/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 141 | Epoch Time: 0m 7s | Total Time so far: 17m 27s\n",
            "\tTrain Loss: 0.435 | Train Acc: 80.61% | Train F1: 0.819\n",
            "\t Val. Loss: 1.591 |  Val. Acc: 50.21% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [142/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [142/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 142 | Epoch Time: 0m 7s | Total Time so far: 17m 34s\n",
            "\tTrain Loss: 0.432 | Train Acc: 80.41% | Train F1: 0.816\n",
            "\t Val. Loss: 1.689 |  Val. Acc: 48.79% |  Val. F1: 0.422\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [143/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [143/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 143 | Epoch Time: 0m 7s | Total Time so far: 17m 41s\n",
            "\tTrain Loss: 0.431 | Train Acc: 80.56% | Train F1: 0.818\n",
            "\t Val. Loss: 1.733 |  Val. Acc: 49.68% |  Val. F1: 0.429\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [144/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [144/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 144 | Epoch Time: 0m 7s | Total Time so far: 17m 49s\n",
            "\tTrain Loss: 0.414 | Train Acc: 81.13% | Train F1: 0.824\n",
            "\t Val. Loss: 1.757 |  Val. Acc: 48.37% |  Val. F1: 0.451\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [145/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [145/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 145 | Epoch Time: 0m 7s | Total Time so far: 17m 56s\n",
            "\tTrain Loss: 0.416 | Train Acc: 81.73% | Train F1: 0.828\n",
            "\t Val. Loss: 1.791 |  Val. Acc: 47.59% |  Val. F1: 0.441\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [146/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [146/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 146 | Epoch Time: 0m 7s | Total Time so far: 18m 4s\n",
            "\tTrain Loss: 0.421 | Train Acc: 81.19% | Train F1: 0.822\n",
            "\t Val. Loss: 1.691 |  Val. Acc: 48.51% |  Val. F1: 0.442\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [147/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [147/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 147 | Epoch Time: 0m 7s | Total Time so far: 18m 11s\n",
            "\tTrain Loss: 0.403 | Train Acc: 81.96% | Train F1: 0.831\n",
            "\t Val. Loss: 1.792 |  Val. Acc: 48.12% |  Val. F1: 0.429\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [148/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [148/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 148 | Epoch Time: 0m 7s | Total Time so far: 18m 19s\n",
            "\tTrain Loss: 0.404 | Train Acc: 82.22% | Train F1: 0.834\n",
            "\t Val. Loss: 1.722 |  Val. Acc: 48.30% |  Val. F1: 0.480\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [149/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [149/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 149 | Epoch Time: 0m 7s | Total Time so far: 18m 26s\n",
            "\tTrain Loss: 0.406 | Train Acc: 81.63% | Train F1: 0.828\n",
            "\t Val. Loss: 1.784 |  Val. Acc: 48.54% |  Val. F1: 0.445\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [150/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [150/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 150 | Epoch Time: 0m 7s | Total Time so far: 18m 33s\n",
            "\tTrain Loss: 0.399 | Train Acc: 82.19% | Train F1: 0.835\n",
            "\t Val. Loss: 1.756 |  Val. Acc: 48.40% |  Val. F1: 0.435\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [151/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [151/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 151 | Epoch Time: 0m 7s | Total Time so far: 18m 41s\n",
            "\tTrain Loss: 0.389 | Train Acc: 82.70% | Train F1: 0.838\n",
            "\t Val. Loss: 1.759 |  Val. Acc: 49.75% |  Val. F1: 0.441\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [152/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [152/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 152 | Epoch Time: 0m 7s | Total Time so far: 18m 48s\n",
            "\tTrain Loss: 0.396 | Train Acc: 82.41% | Train F1: 0.834\n",
            "\t Val. Loss: 1.811 |  Val. Acc: 48.58% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [153/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [153/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 153 | Epoch Time: 0m 7s | Total Time so far: 18m 56s\n",
            "\tTrain Loss: 0.389 | Train Acc: 83.02% | Train F1: 0.840\n",
            "\t Val. Loss: 1.684 |  Val. Acc: 49.47% |  Val. F1: 0.428\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [154/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [154/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 154 | Epoch Time: 0m 7s | Total Time so far: 19m 3s\n",
            "\tTrain Loss: 0.385 | Train Acc: 83.07% | Train F1: 0.840\n",
            "\t Val. Loss: 1.720 |  Val. Acc: 48.54% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [155/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [155/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 155 | Epoch Time: 0m 7s | Total Time so far: 19m 10s\n",
            "\tTrain Loss: 0.379 | Train Acc: 83.41% | Train F1: 0.843\n",
            "\t Val. Loss: 1.895 |  Val. Acc: 48.22% |  Val. F1: 0.441\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [156/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [156/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 156 | Epoch Time: 0m 7s | Total Time so far: 19m 18s\n",
            "\tTrain Loss: 0.362 | Train Acc: 83.93% | Train F1: 0.849\n",
            "\t Val. Loss: 1.706 |  Val. Acc: 50.11% |  Val. F1: 0.432\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [157/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [157/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 157 | Epoch Time: 0m 7s | Total Time so far: 19m 25s\n",
            "\tTrain Loss: 0.374 | Train Acc: 83.29% | Train F1: 0.844\n",
            "\t Val. Loss: 1.761 |  Val. Acc: 49.68% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [158/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [158/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 158 | Epoch Time: 0m 7s | Total Time so far: 19m 32s\n",
            "\tTrain Loss: 0.371 | Train Acc: 83.88% | Train F1: 0.848\n",
            "\t Val. Loss: 1.693 |  Val. Acc: 49.18% |  Val. F1: 0.450\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [159/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [159/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 159 | Epoch Time: 0m 7s | Total Time so far: 19m 40s\n",
            "\tTrain Loss: 0.358 | Train Acc: 84.35% | Train F1: 0.853\n",
            "\t Val. Loss: 1.767 |  Val. Acc: 49.43% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [160/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [160/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 160 | Epoch Time: 0m 7s | Total Time so far: 19m 47s\n",
            "\tTrain Loss: 0.363 | Train Acc: 84.14% | Train F1: 0.850\n",
            "\t Val. Loss: 1.812 |  Val. Acc: 48.90% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [161/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [161/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 161 | Epoch Time: 0m 7s | Total Time so far: 19m 55s\n",
            "\tTrain Loss: 0.357 | Train Acc: 84.30% | Train F1: 0.852\n",
            "\t Val. Loss: 1.823 |  Val. Acc: 49.18% |  Val. F1: 0.430\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [162/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [162/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 162 | Epoch Time: 0m 7s | Total Time so far: 20m 2s\n",
            "\tTrain Loss: 0.343 | Train Acc: 85.14% | Train F1: 0.860\n",
            "\t Val. Loss: 1.904 |  Val. Acc: 48.62% |  Val. F1: 0.430\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [163/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [163/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 163 | Epoch Time: 0m 7s | Total Time so far: 20m 9s\n",
            "\tTrain Loss: 0.338 | Train Acc: 85.18% | Train F1: 0.860\n",
            "\t Val. Loss: 2.000 |  Val. Acc: 49.33% |  Val. F1: 0.436\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [164/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [164/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 164 | Epoch Time: 0m 7s | Total Time so far: 20m 17s\n",
            "\tTrain Loss: 0.338 | Train Acc: 85.53% | Train F1: 0.863\n",
            "\t Val. Loss: 2.019 |  Val. Acc: 47.83% |  Val. F1: 0.416\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [165/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [165/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 165 | Epoch Time: 0m 7s | Total Time so far: 20m 24s\n",
            "\tTrain Loss: 0.345 | Train Acc: 85.20% | Train F1: 0.858\n",
            "\t Val. Loss: 1.836 |  Val. Acc: 50.21% |  Val. F1: 0.421\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [166/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [166/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 166 | Epoch Time: 0m 7s | Total Time so far: 20m 32s\n",
            "\tTrain Loss: 0.331 | Train Acc: 85.51% | Train F1: 0.863\n",
            "\t Val. Loss: 1.946 |  Val. Acc: 49.11% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [167/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [167/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 167 | Epoch Time: 0m 7s | Total Time so far: 20m 39s\n",
            "\tTrain Loss: 0.329 | Train Acc: 85.82% | Train F1: 0.866\n",
            "\t Val. Loss: 1.898 |  Val. Acc: 48.08% |  Val. F1: 0.453\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [168/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [168/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 168 | Epoch Time: 0m 7s | Total Time so far: 20m 46s\n",
            "\tTrain Loss: 0.330 | Train Acc: 85.73% | Train F1: 0.864\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 48.33% |  Val. F1: 0.434\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [169/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [169/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 169 | Epoch Time: 0m 7s | Total Time so far: 20m 54s\n",
            "\tTrain Loss: 0.319 | Train Acc: 86.09% | Train F1: 0.869\n",
            "\t Val. Loss: 2.095 |  Val. Acc: 48.62% |  Val. F1: 0.406\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [170/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [170/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 170 | Epoch Time: 0m 7s | Total Time so far: 21m 1s\n",
            "\tTrain Loss: 0.312 | Train Acc: 86.79% | Train F1: 0.874\n",
            "\t Val. Loss: 2.065 |  Val. Acc: 48.76% |  Val. F1: 0.427\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [171/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [171/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 171 | Epoch Time: 0m 7s | Total Time so far: 21m 9s\n",
            "\tTrain Loss: 0.306 | Train Acc: 86.80% | Train F1: 0.875\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 48.83% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [172/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [172/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 172 | Epoch Time: 0m 7s | Total Time so far: 21m 16s\n",
            "\tTrain Loss: 0.307 | Train Acc: 87.06% | Train F1: 0.878\n",
            "\t Val. Loss: 1.833 |  Val. Acc: 49.89% |  Val. F1: 0.443\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [173/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [173/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 173 | Epoch Time: 0m 7s | Total Time so far: 21m 23s\n",
            "\tTrain Loss: 0.313 | Train Acc: 86.57% | Train F1: 0.871\n",
            "\t Val. Loss: 2.043 |  Val. Acc: 49.01% |  Val. F1: 0.431\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [174/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [174/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 174 | Epoch Time: 0m 7s | Total Time so far: 21m 31s\n",
            "\tTrain Loss: 0.300 | Train Acc: 87.16% | Train F1: 0.879\n",
            "\t Val. Loss: 2.040 |  Val. Acc: 50.21% |  Val. F1: 0.412\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [175/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [175/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 175 | Epoch Time: 0m 7s | Total Time so far: 21m 38s\n",
            "\tTrain Loss: 0.298 | Train Acc: 87.16% | Train F1: 0.878\n",
            "\t Val. Loss: 1.965 |  Val. Acc: 50.36% |  Val. F1: 0.426\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [176/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [176/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 176 | Epoch Time: 0m 7s | Total Time so far: 21m 45s\n",
            "\tTrain Loss: 0.288 | Train Acc: 87.79% | Train F1: 0.883\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 48.12% |  Val. F1: 0.436\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [177/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [177/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 177 | Epoch Time: 0m 7s | Total Time so far: 21m 53s\n",
            "\tTrain Loss: 0.301 | Train Acc: 87.51% | Train F1: 0.880\n",
            "\t Val. Loss: 2.006 |  Val. Acc: 49.18% |  Val. F1: 0.440\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [178/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [178/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 178 | Epoch Time: 0m 7s | Total Time so far: 22m 0s\n",
            "\tTrain Loss: 0.289 | Train Acc: 88.03% | Train F1: 0.884\n",
            "\t Val. Loss: 2.095 |  Val. Acc: 48.54% |  Val. F1: 0.439\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [179/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [179/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 179 | Epoch Time: 0m 7s | Total Time so far: 22m 8s\n",
            "\tTrain Loss: 0.284 | Train Acc: 88.07% | Train F1: 0.885\n",
            "\t Val. Loss: 1.970 |  Val. Acc: 49.96% |  Val. F1: 0.441\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [180/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [180/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 180 | Epoch Time: 0m 7s | Total Time so far: 22m 15s\n",
            "\tTrain Loss: 0.278 | Train Acc: 88.25% | Train F1: 0.887\n",
            "\t Val. Loss: 2.055 |  Val. Acc: 49.79% |  Val. F1: 0.431\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [181/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [181/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 181 | Epoch Time: 0m 7s | Total Time so far: 22m 23s\n",
            "\tTrain Loss: 0.277 | Train Acc: 88.45% | Train F1: 0.890\n",
            "\t Val. Loss: 2.088 |  Val. Acc: 48.76% |  Val. F1: 0.439\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [182/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [182/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 182 | Epoch Time: 0m 7s | Total Time so far: 22m 30s\n",
            "\tTrain Loss: 0.273 | Train Acc: 88.39% | Train F1: 0.888\n",
            "\t Val. Loss: 1.869 |  Val. Acc: 50.57% |  Val. F1: 0.456\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [183/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [183/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 183 | Epoch Time: 0m 7s | Total Time so far: 22m 37s\n",
            "\tTrain Loss: 0.276 | Train Acc: 88.32% | Train F1: 0.888\n",
            "\t Val. Loss: 2.188 |  Val. Acc: 48.97% |  Val. F1: 0.441\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [184/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [184/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 184 | Epoch Time: 0m 7s | Total Time so far: 22m 45s\n",
            "\tTrain Loss: 0.265 | Train Acc: 89.00% | Train F1: 0.895\n",
            "\t Val. Loss: 2.105 |  Val. Acc: 48.83% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [185/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [185/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 185 | Epoch Time: 0m 7s | Total Time so far: 22m 52s\n",
            "\tTrain Loss: 0.267 | Train Acc: 89.09% | Train F1: 0.895\n",
            "\t Val. Loss: 2.128 |  Val. Acc: 49.40% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [186/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [186/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 186 | Epoch Time: 0m 7s | Total Time so far: 22m 59s\n",
            "\tTrain Loss: 0.263 | Train Acc: 88.93% | Train F1: 0.893\n",
            "\t Val. Loss: 2.049 |  Val. Acc: 48.58% |  Val. F1: 0.440\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [187/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [187/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 187 | Epoch Time: 0m 7s | Total Time so far: 23m 7s\n",
            "\tTrain Loss: 0.261 | Train Acc: 88.92% | Train F1: 0.893\n",
            "\t Val. Loss: 2.206 |  Val. Acc: 48.51% |  Val. F1: 0.400\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [188/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [188/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 188 | Epoch Time: 0m 7s | Total Time so far: 23m 14s\n",
            "\tTrain Loss: 0.255 | Train Acc: 89.55% | Train F1: 0.899\n",
            "\t Val. Loss: 2.140 |  Val. Acc: 49.86% |  Val. F1: 0.439\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [189/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [189/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 189 | Epoch Time: 0m 7s | Total Time so far: 23m 22s\n",
            "\tTrain Loss: 0.249 | Train Acc: 89.98% | Train F1: 0.903\n",
            "\t Val. Loss: 2.103 |  Val. Acc: 48.58% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [190/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [190/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 190 | Epoch Time: 0m 7s | Total Time so far: 23m 29s\n",
            "\tTrain Loss: 0.246 | Train Acc: 89.79% | Train F1: 0.902\n",
            "\t Val. Loss: 1.958 |  Val. Acc: 48.62% |  Val. F1: 0.447\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [191/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [191/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 191 | Epoch Time: 0m 7s | Total Time so far: 23m 36s\n",
            "\tTrain Loss: 0.243 | Train Acc: 90.02% | Train F1: 0.903\n",
            "\t Val. Loss: 2.131 |  Val. Acc: 49.93% |  Val. F1: 0.443\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [192/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [192/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 192 | Epoch Time: 0m 7s | Total Time so far: 23m 44s\n",
            "\tTrain Loss: 0.244 | Train Acc: 89.65% | Train F1: 0.901\n",
            "\t Val. Loss: 2.125 |  Val. Acc: 49.25% |  Val. F1: 0.444\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [193/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [193/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 193 | Epoch Time: 0m 7s | Total Time so far: 23m 51s\n",
            "\tTrain Loss: 0.242 | Train Acc: 89.99% | Train F1: 0.902\n",
            "\t Val. Loss: 2.114 |  Val. Acc: 49.01% |  Val. F1: 0.438\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [194/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [194/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 194 | Epoch Time: 0m 7s | Total Time so far: 23m 58s\n",
            "\tTrain Loss: 0.239 | Train Acc: 90.30% | Train F1: 0.906\n",
            "\t Val. Loss: 2.176 |  Val. Acc: 49.79% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [195/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [195/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 195 | Epoch Time: 0m 7s | Total Time so far: 24m 6s\n",
            "\tTrain Loss: 0.252 | Train Acc: 89.66% | Train F1: 0.897\n",
            "\t Val. Loss: 2.193 |  Val. Acc: 49.18% |  Val. F1: 0.429\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [196/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [196/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 196 | Epoch Time: 0m 7s | Total Time so far: 24m 13s\n",
            "\tTrain Loss: 0.234 | Train Acc: 90.53% | Train F1: 0.908\n",
            "\t Val. Loss: 2.271 |  Val. Acc: 49.36% |  Val. F1: 0.421\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [197/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [197/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 197 | Epoch Time: 0m 7s | Total Time so far: 24m 21s\n",
            "\tTrain Loss: 0.222 | Train Acc: 91.06% | Train F1: 0.913\n",
            "\t Val. Loss: 2.261 |  Val. Acc: 49.18% |  Val. F1: 0.428\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [198/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [198/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 198 | Epoch Time: 0m 7s | Total Time so far: 24m 28s\n",
            "\tTrain Loss: 0.228 | Train Acc: 90.74% | Train F1: 0.909\n",
            "\t Val. Loss: 2.128 |  Val. Acc: 48.90% |  Val. F1: 0.449\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [199/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [199/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 199 | Epoch Time: 0m 7s | Total Time so far: 24m 35s\n",
            "\tTrain Loss: 0.220 | Train Acc: 91.12% | Train F1: 0.913\n",
            "\t Val. Loss: 2.144 |  Val. Acc: 49.08% |  Val. F1: 0.455\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Training (intermediate metrics):\n",
            "Epoch [200/200]\n",
            "\n",
            "Validation (intermediate metrics):\n",
            "Epoch [200/200]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Epoch: 200 | Epoch Time: 0m 7s | Total Time so far: 24m 43s\n",
            "\tTrain Loss: 0.221 | Train Acc: 91.12% | Train F1: 0.912\n",
            "\t Val. Loss: 2.091 |  Val. Acc: 50.00% |  Val. F1: 0.438\n",
            "---------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFVYQc9gO8WP",
        "outputId": "36f8a484-ad67-466a-8908-c9389c43485a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Network': {'seed': 1,\n",
              "  'total_param_num': 18486203,\n",
              "  'optimiser': 'Adam',\n",
              "  'loss_function': 'CrossEntropyLoss',\n",
              "  'optimiser_params': {'lr': 9e-05, 'weight_decay': 0.0001},\n",
              "  'vocab_size': 75574,\n",
              "  'PAD_IDX': 1,\n",
              "  'UNK_IDX': 0,\n",
              "  'classes': ['neutral', 'negative', 'positive'],\n",
              "  'SPLIT_RATIO': 0.9,\n",
              "  'MAX_VOCAB_SIZE': 100000,\n",
              "  'HIDDEN_DIM': 300,\n",
              "  'EMBEDDING_DIM': 200,\n",
              "  'conv_out_ch': 200,\n",
              "  'MODEL_MODE': 'RNN',\n",
              "  'num_epoch': 200},\n",
              " 'display_stats_freq': 200,\n",
              " 'network_save_freq': 1,\n",
              " 'postreply_data_path': './',\n",
              " 'final_data_post_reply_file_name': 'final_data_post_reply.csv',\n",
              " 'training_post_reply_file_name': 'obtained_train_clean.csv',\n",
              " 'final_test_post_reply_file_name': 'test_w_text.csv',\n",
              " 'reply_data_format': 'csv',\n",
              " 'pretrained_embedding': 'glove.twitter.27B.200d',\n",
              " 'tokenizer': 'spacy',\n",
              " 'network_output_path': './models/',\n",
              " 'trained_model_name': 'LSTM_model_obt_cl.pth',\n",
              " 'total_train_tweets': 24064,\n",
              " 'total_valid_tweets': 2816}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import ParamSpecArgs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "class Prediction:\n",
        "    '''\n",
        "    This class represents prediction (testing) process similar to the Training class.\n",
        "    '''\n",
        "    def __init__(self, params, classes, model_mode='RNN', cfg_path_RNN=None, cfg_path_CNN=None): #cfg_path\n",
        "        self.params = params\n",
        "        #if cfg_path_CNN:\n",
        "            #self.params_RNN = read_config(cfg_path_RNN)\n",
        "            #self.params_CNN = read_config(cfg_path_CNN)\n",
        "        #self.cfg_path = cfg_path\n",
        "        self.setup_cuda()\n",
        "        self.model_mode = model_mode\n",
        "        self.classes = classes\n",
        "\n",
        "    def setup_cuda(self, cuda_device_id=0):\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cudnn.fastest = True\n",
        "            torch.cuda.set_device(cuda_device_id)\n",
        "            self.device = torch.device('cuda')\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "    def setup_model(self, model, vocab_size, embeddings, embedding_dim,\n",
        "                    hidden_dim, pad_idx, unk_idx, model_file_name=None, epoch=19,\n",
        "                    conv_out_ch=200, filter_sizes=[3,4,5], model_c =CNN1d, model_r=biLSTM):\n",
        "        if model_file_name == None:\n",
        "            model_file_name = self.params['trained_model_name']\n",
        "        if self.model_mode == \"RNN\":\n",
        "            self.model_p = model(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 hidden_dim=hidden_dim, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "        elif self.model_mode == \"CNN\":\n",
        "            self.model_p = model(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 conv_out_ch=conv_out_ch, filter_sizes=filter_sizes, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "        elif self.model_mode == \"ensemble\":\n",
        "            model_file_name_c = self.params_CNN['trained_model_name']\n",
        "            model_file_name_r = self.params_RNN['trained_model_name']\n",
        "            self.model_cnn = model_c(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 conv_out_ch=conv_out_ch, filter_sizes=filter_sizes, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "            self.model_rnn = model_r(vocab_size=vocab_size, embeddings=embeddings, embedding_dim=embedding_dim,\n",
        "                                 hidden_dim=hidden_dim, pad_idx=pad_idx, unk_idx=unk_idx).to(self.device)\n",
        "\n",
        "        # Loads model from model_file_name and default network_output_path\n",
        "        if self.model_mode == \"ensemble\":\n",
        "            # self.model_cnn.load_state_dict(torch.load(self.params_CNN['network_output_path'] + \"/\" + model_file_name_c))\n",
        "            self.model_cnn.load_state_dict(\n",
        "                torch.load(self.params_CNN['network_output_path'] + model_file_name_c)) #\"/epoch\" + str(19) + \"_\" + model_file_name_c))\n",
        "            # self.model_rnn.load_state_dict(torch.load(self.params_RNN['network_output_path'] + \"/\" + model_file_name_r))\n",
        "            self.model_rnn.load_state_dict(\n",
        "                torch.load(self.params_RNN['network_output_path'] + model_file_name_r)) #\"/epoch\" + str(43) + \"_\" + model_file_name_r))\n",
        "        else:\n",
        "            # self.model_p.load_state_dict(torch.load(self.params['network_output_path'] + \"/\" + model_file_name))\n",
        "            self.model_p.load_state_dict(torch.load(self.params['network_output_path'] + model_file_name)) #+ \"/epoch\" + str(epoch) + \"_\" + model_file_name))\n",
        "\n",
        "\n",
        "    def predict(self, test_loader, batch_size):\n",
        "        # Reads params to check if any params have been changed by user\n",
        "        #self.params = read_config(self.cfg_path)\n",
        "        self.model_p.eval()\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            # initializing the caches\n",
        "            logits_cache = torch.from_numpy(np.zeros((len(test_loader) * batch_size, 3)))\n",
        "            max_preds_cache = torch.from_numpy(np.zeros((len(test_loader) * batch_size, 1)))\n",
        "            labels_cache = torch.from_numpy(np.zeros(len(test_loader) * batch_size))\n",
        "\n",
        "            for idx, batch in enumerate(test_loader):\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    message, message_lengths = batch.text\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    message = batch.text\n",
        "                label = batch.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                if self.model_mode == \"RNN\":\n",
        "                    output = self.model_p(message, message_lengths).squeeze(1)\n",
        "                if self.model_mode == \"CNN\":\n",
        "                    output = self.model_p(message).squeeze(1)\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        # average=None gives individual scores for each class\n",
        "        # here we only care about the average of positive class and negative class\n",
        "        final_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_f1_score = (final_f1_score[1] + final_f1_score[2]) / 2\n",
        "        final_precision = (final_precision[1] + final_precision[2]) / 2\n",
        "        final_recall = (final_recall[1] + final_recall[2]) / 2\n",
        "        confusion_matrix = metrics.confusion_matrix(labels_cache, max_preds_cache, labels=[0,1,2])\n",
        "\n",
        "        end_time = time.time()\n",
        "        test_mins, test_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "        #for p,l in zip(max_preds_cache,labels_cache):\n",
        "          #print(l.item())\n",
        "\n",
        "        # Print the final evaluation metrics\n",
        "        print('\\n----------------------------------------------------------------------')\n",
        "        print(f'Testing | Testing Time: {test_mins}m {test_secs}s')\n",
        "        print(f'\\tAcc: {final_accuracy * 100:.2f}% | F1 score: {final_f1_score:.3f} | '\n",
        "              f'Recall: {final_recall:.3f} | Precision: {final_precision:.3f}')\n",
        "        print('----------------------------------------------------------------------\\n')\n",
        "        print(confusion_matrix)\n",
        "        self.plot_confusion_matrix(confusion_matrix, target_names=self.classes,title='Confusion matrix, without normalization')\n",
        "\n",
        "        return final_accuracy, final_f1_score\n",
        "\n",
        "\n",
        "    def predict_ensemble(self, test_iterator_RNN, test_iterator_CNN, batch_size):\n",
        "        \"prediction with ensembling CNN and RNN outputs by normal averaging\"\n",
        "\n",
        "        # Reads params to check if any params have been changed by user\n",
        "        #self.params = read_config(self.cfg_path)\n",
        "        self.model_cnn.eval()\n",
        "        self.model_rnn.eval()\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            # initializing the caches\n",
        "            logits_cache = torch.from_numpy(np.zeros((len(test_iterator_RNN) * batch_size, 3)))\n",
        "            max_preds_cache = torch.from_numpy(np.zeros((len(test_iterator_RNN) * batch_size, 1)))\n",
        "            labels_cache = torch.from_numpy(np.zeros(len(test_iterator_RNN) * batch_size))\n",
        "\n",
        "            for idx, (batch_RNN, batch_CNN) in enumerate(zip(test_iterator_RNN, test_iterator_CNN)):\n",
        "\n",
        "                # RNN part\n",
        "                message, message_lengths = batch_RNN.text\n",
        "                label = batch_RNN.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                output_RNN = self.model_rnn(message, message_lengths).squeeze(1)\n",
        "\n",
        "                #CNN part\n",
        "                message = batch_CNN.text\n",
        "                label = batch_CNN.label\n",
        "                message = message.long()\n",
        "                label = label.long()\n",
        "                message = message.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                output_CNN = self.model_cnn(message).squeeze(1)\n",
        "\n",
        "                output = (output_CNN + output_RNN) / 2\n",
        "                max_preds = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "                # saving the logits and labels of this batch\n",
        "                for i, batch_vector in enumerate(max_preds):\n",
        "                    max_preds_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, batch_vector in enumerate(output):\n",
        "                    logits_cache[idx * batch_size + i] = batch_vector\n",
        "                for i, value in enumerate(label):\n",
        "                    labels_cache[idx * batch_size + i] = value\n",
        "\n",
        "        '''Metrics calculation over the whole set'''\n",
        "        max_preds_cache = max_preds_cache.cpu()\n",
        "        labels_cache = labels_cache.cpu()\n",
        "\n",
        "        # average=None gives individual scores for each class\n",
        "        # here we only care about the average of positive class and negative class\n",
        "        final_accuracy = metrics.accuracy_score(labels_cache, max_preds_cache)\n",
        "        # final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_precision = metrics.precision_score(labels_cache, max_preds_cache, average='macro')\n",
        "        # final_recall = metrics.recall_score(labels_cache, max_preds_cache, average='macro')\n",
        "\n",
        "        final_f1_score = metrics.f1_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_precision = metrics.precision_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_recall = metrics.recall_score(labels_cache, max_preds_cache, average=None)\n",
        "        final_f1_score = (final_f1_score[1] + final_f1_score[2]) / 2\n",
        "        final_precision = (final_precision[1] + final_precision[2]) / 2\n",
        "        final_recall = (final_recall[1] + final_recall[2]) / 2\n",
        "        confusion_matrix = metrics.confusion_matrix(labels_cache, max_preds_cache, labels=[0,1,2])\n",
        "\n",
        "        end_time = time.time()\n",
        "        test_mins, test_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "        # Print the final evaluation metrics\n",
        "        print('\\n----------------------------------------------------------------------')\n",
        "        print(f'Testing | Testing Time: {test_mins}m {test_secs}s')\n",
        "        print(f'\\tAcc: {final_accuracy * 100:.2f}% | F1 score: {final_f1_score:.3f} | '\n",
        "              f'Recall: {final_recall:.3f} | Precision: {final_precision:.3f}')\n",
        "        print('----------------------------------------------------------------------\\n')\n",
        "        print(confusion_matrix)\n",
        "        # self.plot_confusion_matrix(confusion_matrix, target_names=self.classes,\n",
        "        #                       title='Confusion matrix, without normalization')\n",
        "        return final_accuracy, final_f1_score\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(self, cm, target_names,\n",
        "                              title='Confusion matrix', cmap=None, normalize=False):\n",
        "        \"\"\"\n",
        "        given a sklearn confusion matrix (cm), make a nice plot\n",
        "        ---------\n",
        "        cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "        target_names: given classification classes such as [0, 1, 2]\n",
        "                      the class names, for example: ['high', 'medium', 'low']\n",
        "        cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                      plt.get_cmap('jet') or plt.cm.Blues\n",
        "        normalize:    If False, plot the raw numbers\n",
        "                      If True, plot the proportions\n",
        "        \"\"\"\n",
        "        accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "        misclass = 1 - accuracy\n",
        "\n",
        "        if cmap is None:\n",
        "            cmap = plt.get_cmap('Blues')\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "\n",
        "        if target_names is not None:\n",
        "            tick_marks = np.arange(len(target_names))\n",
        "            plt.xticks(tick_marks, target_names, rotation=45)\n",
        "            plt.yticks(tick_marks, target_names)\n",
        "\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            if normalize:\n",
        "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "            else:\n",
        "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label\\naccuracy={:0.2f}%; misclass={:0.2f}%'.format(accuracy*100, misclass*100))\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def manual_predict(self, labels, vocab_idx, phrase, min_len=4,\n",
        "                       tokenizer=spacy.load(\"en_core_web_sm\"), mode=None, prediction_mode='Manualpart1'):\n",
        "        '''\n",
        "        Manually predicts the polarity of the given sentence.\n",
        "        Possible polarities: 1.neutral, 2.positive, 3.negative\n",
        "        '''\n",
        "        #self.params = read_config(self.cfg_path)\n",
        "        self.model_p.eval()\n",
        "\n",
        "        tokenized = [tok.text for tok in tokenizer.tokenizer(phrase)]\n",
        "        if len(tokenized) < min_len:\n",
        "            tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "        indexed = [vocab_idx[t] for t in tokenized]\n",
        "        tensor = torch.LongTensor(indexed).to(self.device)\n",
        "        tensor = tensor.unsqueeze(1)\n",
        "        preds = self.model_p(tensor, torch.Tensor([tensor.shape[0]]))\n",
        "        max_preds = preds.argmax(dim=1)\n",
        "        if mode == Mode.REPLYPREDICTION:\n",
        "            return labels[max_preds.item()]\n",
        "\n",
        "        print('\\n\\t', '\"' + phrase + '\"')\n",
        "        print('-----------------------------------------')\n",
        "        if prediction_mode == 'Manualpart1':\n",
        "            print(f'\\t This is a {labels[max_preds.item()]} phrase!')\n",
        "        elif prediction_mode == 'Manualpart2':\n",
        "            print(f'\\t This phrase is likely to get {labels[max_preds.item()]} replies!')\n",
        "        print('-----------------------------------------')\n"
      ],
      "metadata": {
        "id": "2QRrf3AvSEBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_test_postreply():\n",
        "    '''Main function for testing of the second part of the project\n",
        "    Sentiment analysis of the Post-Replies.\n",
        "    '''\n",
        "    EXPERIMENT_NAME = 'new_october_CNN'\n",
        "    BATCH_SIZE = 1281\n",
        "\n",
        "    #params = open_experiment(EXPERIMENT_NAME)\n",
        "    #cfg_path = params['cfg_path']\n",
        "    vocab_size = params['Network']['vocab_size']\n",
        "    PAD_IDX = params['Network']['PAD_IDX']\n",
        "    UNK_IDX = params['Network']['UNK_IDX']\n",
        "    classes = params['Network']['classes']\n",
        "    MAX_VOCAB_SIZE = params['Network']['MAX_VOCAB_SIZE']\n",
        "    SPLIT_RATIO = params['Network']['SPLIT_RATIO']\n",
        "    EMBEDDING_DIM = params['Network']['EMBEDDING_DIM']\n",
        "    HIDDEN_DIM = params['Network']['HIDDEN_DIM']\n",
        "    conv_out_ch = params['Network']['conv_out_ch']\n",
        "    MODEL_MODE = params['Network']['MODEL_MODE']\n",
        "    pretrained_embeddings = torch.zeros((vocab_size, EMBEDDING_DIM))\n",
        "\n",
        "    # Prepare data\n",
        "    data_handler_test = data_provider_PostReply(params=params, batch_size=BATCH_SIZE, split_ratio=SPLIT_RATIO,\n",
        "                                         max_vocab_size=MAX_VOCAB_SIZE, mode=Mode.TEST, model_mode=MODEL_MODE)\n",
        "    test_iterator = data_handler_test.data_loader()\n",
        "    # Initialize predictor\n",
        "    predictor = Prediction(params, model_mode=MODEL_MODE, classes=classes) #cfg_path\n",
        "\n",
        "    if MODEL_MODE == \"RNN\":\n",
        "        MODEL = biLSTM\n",
        "    elif MODEL_MODE == \"CNN\":\n",
        "        MODEL = CNN1d\n",
        "\n",
        "    predictor.setup_model(model=MODEL, vocab_size=vocab_size, embeddings=pretrained_embeddings,\n",
        "                          embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX,\n",
        "                          conv_out_ch=conv_out_ch, filter_sizes=[3, 4, 5])\n",
        "    predictor.predict(test_iterator, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "s2GhLgkuxJ9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params={'Network': {'seed': 1,\n",
        "  'total_param_num': 18486203,\n",
        "  'optimiser': 'Adam',\n",
        "  'loss_function': 'CrossEntropyLoss',\n",
        "  'optimiser_params': {'lr': 9e-05, 'weight_decay': 0.0001},\n",
        "  'vocab_size': 78461,\n",
        "  'PAD_IDX': 1,\n",
        "  'UNK_IDX': 0,\n",
        "  'classes': ['neutral', 'negative', 'positive'],\n",
        "  'SPLIT_RATIO': 0.9,\n",
        "  'MAX_VOCAB_SIZE': 100000,\n",
        "  'HIDDEN_DIM': 300,\n",
        "  'EMBEDDING_DIM': 200,\n",
        "  'conv_out_ch': 200,\n",
        "  'MODEL_MODE': 'RNN',\n",
        "  'num_epoch': 200},\n",
        " 'display_stats_freq': 200,\n",
        " 'network_save_freq': 1,\n",
        " 'postreply_data_path': './',\n",
        " 'final_data_post_reply_file_name': 'final_data_post_reply.csv',\n",
        " 'training_post_reply_file_name': 'provided_train.csv',\n",
        " 'final_test_post_reply_file_name': 'test_w_text.csv',\n",
        " 'reply_data_format': 'csv',\n",
        " 'pretrained_embedding': 'glove.twitter.27B.200d',\n",
        " 'tokenizer': 'spacy',\n",
        " 'network_output_path': './models/',\n",
        " 'trained_model_name': 'LSTM_model_prv.pth',\n",
        " 'total_train_tweets': 24064,\n",
        " 'total_valid_tweets': 2816}"
      ],
      "metadata": {
        "id": "8fqE38-lqKKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_test_postreply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "SSg3llgUhBiN",
        "outputId": "047cdb03-4e21-4776-864b-43f7fe6fc98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Testing | Testing Time: 0m 0s\n",
            "\tAcc: 48.71% | F1 score: 0.552 | Recall: 0.562 | Precision: 0.547\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[[122 124 130]\n",
            " [174 240  82]\n",
            " [ 67  80 262]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcJD5D5UrPiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}